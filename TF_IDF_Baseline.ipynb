{"cells":[{"cell_type":"markdown","source":["# Many thanks to:\n","\n","\"Automatic Extractive Text Summarization using TF-IDF\n","\n","In the recent years, information grows rapidly along with the development of social media. With the increasing amount of information, it takes more effort and time to review the entire text document and understand its contents...\"\n","\n","https://medium.com/voice-tech-podcast/automatic-extractive-text-summarization-using-tfidf-3fc9a7b26f5"],"metadata":{"id":"0bmlM0oilPuM"}},{"cell_type":"markdown","source":["# **Important libraries**"],"metadata":{"id":"gZV9pkf3kv4p"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNELa3CsAnAM","outputId":"ddf354e5-1acd-426e-ce9f-e4fbdac62e70"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["!pip install datasets\n","!pip install rouge\n","from rouge import Rouge\n","import nltk\n","import os\n","import re\n","import math\n","import operator\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","Stopwords = set(stopwords.words('english'))\n","wordlemmatizer = WordNetLemmatizer()"]},{"cell_type":"markdown","source":["# **Load Datset**"],"metadata":{"id":"0hqRGHyJk_F_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHgVcWuFZlST","outputId":"e8c2cf57-f1f6-4ac1-ff17-fb7e950c637e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for scientific_papers contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/scientific_papers\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['article', 'abstract', 'section_names'],\n","    num_rows: 10\n","})"]},"metadata":{},"execution_count":9}],"source":["from datasets import load_dataset\n","test_dataset = load_dataset(\"scientific_papers\", \"arxiv\", split=\"test[0:10]\")\n","test_dataset"]},{"cell_type":"code","source":["import pandas as pd\n","test_df = pd.DataFrame(test_dataset)\n","test_df.drop(columns=['section_names'], inplace=True)\n","test_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"rWPErcRdj75S","outputId":"79a3385a-71a1-4156-8590-2307b5fe6cc8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             article  \\\n","0  for about 20 years the problem of properties o...   \n","1  it is believed that the direct detection of gr...   \n","2  as a common quantum phenomenon , the tunneling...   \n","3  for the hybrid monte carlo algorithm ( hmc)@xc...   \n","4  recently it was discovered that feynman integr...   \n","5  one of the main goals of the search for period...   \n","6  this review focuses specifically on what we ha...   \n","7  single - transverse spin asymmetries ( ssas ) ...   \n","8  kingman s coalescent is a random tree introduc...   \n","9  rapid progress in the design and manufacture o...   \n","\n","                                            abstract  \n","0   the short - term periodicities of the daily s...  \n","1   we study the detectability of circular polari...  \n","2   starting from the wkb approximation , a new b...  \n","3   we study a novel class of numerical integrato...  \n","4   new methods for obtaining functional equation...  \n","5   in the hierarchical search for periodic sourc...  \n","6   i summarize what we have learned about the na...  \n","7   we present a phenomenological study of the si...  \n","8   kingman s coalescent is a random tree that ar...  \n","9   we discuss several novel types of multi - com...  "],"text/html":["\n","  <div id=\"df-f403ebd1-2ec5-4afe-a3e9-8b6e9e09abd5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>abstract</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>for about 20 years the problem of properties o...</td>\n","      <td>the short - term periodicities of the daily s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>it is believed that the direct detection of gr...</td>\n","      <td>we study the detectability of circular polari...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>as a common quantum phenomenon , the tunneling...</td>\n","      <td>starting from the wkb approximation , a new b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>for the hybrid monte carlo algorithm ( hmc)@xc...</td>\n","      <td>we study a novel class of numerical integrato...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>recently it was discovered that feynman integr...</td>\n","      <td>new methods for obtaining functional equation...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>one of the main goals of the search for period...</td>\n","      <td>in the hierarchical search for periodic sourc...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>this review focuses specifically on what we ha...</td>\n","      <td>i summarize what we have learned about the na...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>single - transverse spin asymmetries ( ssas ) ...</td>\n","      <td>we present a phenomenological study of the si...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>kingman s coalescent is a random tree introduc...</td>\n","      <td>kingman s coalescent is a random tree that ar...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>rapid progress in the design and manufacture o...</td>\n","      <td>we discuss several novel types of multi - com...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f403ebd1-2ec5-4afe-a3e9-8b6e9e09abd5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f403ebd1-2ec5-4afe-a3e9-8b6e9e09abd5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f403ebd1-2ec5-4afe-a3e9-8b6e9e09abd5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-78c98681-fb60-4e98-9a37-aafbd96c6a93\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78c98681-fb60-4e98-9a37-aafbd96c6a93')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-78c98681-fb60-4e98-9a37-aafbd96c6a93 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_c6283064-bc51-4f0b-b00f-eccf06a2f5eb\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_c6283064-bc51-4f0b-b00f-eccf06a2f5eb button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('test_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"kingman s coalescent is a random tree introduced by @xcite as the genealogy arising in large population genetic models .\\nit has infinitely many leaves and is usually constructed from leaves to the root as follows : given that there are @xmath7 lines in the tree , after some exponential time with rate @xmath8 , two lines are chosen uniformly and merged to one line , leaving the tree with @xmath9 lines . due to the quadratic rate @xmath10 the tree immediately comes down from infinitely to finitely many leaves @xcite . since the seminal paper by @xcite this random tree has been generalized to other infinite trees arising in population genetics models .    for the kingman\\ncoalescent some laws of large numbers and central limit theorems have been proved .\\nthey are nicely summarized in @xcite , chapter  4.2 ; see also proposition  [ p:11 ] below . for @xmath11\\nlet @xmath12 denote the number of lines time @xmath13 in the past .\\nthen , since the kingman coalescent immediately comes down from infinity , @xmath12 is finite .\\nfurthermore it is approximately @xmath14 .\\nequivalently , the time @xmath0 it takes the coalescent to go from infinitely many lines to @xmath1 lines is approximately @xmath15 for large @xmath1 .\\ngoing to the fine structure , at time @xmath0 the infinite population is decomposed in @xmath1 families ( whose joint distribution is exchangeable ) and every leaf in the tree belongs to exactly one of the @xmath1 families whose frequencies are denoted by @xmath16 .\\nit is known that for large @xmath1 a randomly chosen @xmath3 is approximately exponentially distributed with mean @xmath17 .\\nthis translates into several laws of large numbers ; see e.g.  ( 35 ) in @xcite .\\nin particular the probability of picking ( from the initial infinite population ) two leaves that belong to the same family , given by @xmath18 , is approximately @xmath15 .    the main goal of the present paper is to study the corresponding large deviations results . to the best of our knowledge , except for @xcite , cf .\\nremark  [ rem : angel ] , results in this direction are not present in the literature .\\nwe formulate our results in the next section .\\ntheorem  [ t1 ] gives a full large deviation principle for the distributions of @xmath19 .\\nthe proof , given in section  [ sec : proofs1 ] , is an application of the grtner - ellis theorem . as a byproduct\\n, we derive a large deviation principle for the distributions of @xmath20 in corollary  [ cor : tnt ] .\\nlarge deviations of @xmath21 are considered in theorem  [ t2 ] and exact rate functions for downwards and upwards deviations are given . the proof is given in section  [ sec : proof - theorem - reft2 ] . for the upward deviations we use a variant of cramr s theorem for heavy - tailed random variables\\n; see e.g.  @xcite . for the downward deviations we use a connection to self - normalized large deviations ; see @xcite .\\nthis connection was pointed out to us by alain rouault and nina gantert .\\nsince the rate function for downward deviations is hard to treat analytically we provide in theorem  [ t3 ] a simple lower bound .\\nthe proof of that bound is given in section  [ sec : proof - theorem3 ] .\\nthe kingman coalescent can be seen as a discrete graph , more precisely a discrete tree with infinitely many leaves .\\nlet @xmath22 be independent exponentially distributed variables with mean @xmath23 .\\nthen the kingman coalescent tree can be constructed from the root to the leaves as follows .    1 .\\nstart the tree with two lines from the root .\\n2 .   for @xmath24\\nthe tree stays with @xmath7 lines for the amount of time @xmath25 .\\nafter that time one of the @xmath7 lines is randomly chosen .\\nthis line splits in two so that the number of lines jumps from @xmath7 to @xmath26 .\\n3 .   stop upon reaching infinitely many lines , which happens after ( the almost surely finite ) time @xmath27 .\\nthe random variable @xmath28 is the total tree height .\\nalternatively , @xmath28 is the time to the most recent common ancestor ( mrca ) of the infinite population ( of leaves ) . counted from the top of the tree at time @xmath29 a random number @xmath12 of active lines in the kingman tree is present , i.e.@xmath30 at time @xmath0 every leaf belongs to one of @xmath1 disjoint families and all members of each such family stem from the same line at time @xmath0 .\\nlet us denote the frequencies of these families ( which exist due to exchangeability by definetti s theorem ) by @xmath16 .\\nthe following results are well known ( see @xcite for   and and @xcite for ; proofs can also be found in @xcite . )     + let [ p:11 ] @xmath31 , @xmath32 and @xmath33 be as above .\\nthen @xmath34    we [ rem : interllnfe ] note that the left hand side of has the interpretation of a _\\nhomozygosity by descent _ in the following sense : when picking two leaves from the tree at time @xmath35 , the probability that both share a common ancestor at time @xmath0 is @xmath36 .\\nthen , the law of large number states that the homozygosity by descent at time @xmath0 is approximately @xmath15 for large @xmath1 .    in the present paper\\nwe are interested in large deviations results corresponding to the statements of proposition  [ p:11 ] .\\nwe start with large deviations connected with .\\nfirst we introduce some notation . for @xmath37 let @xmath38 denote the distribution of @xmath19 ,\\ni.e.  @xmath39 .\\nfurthermore we denote by @xmath40 the borel @xmath41-algebra on @xmath42 and for @xmath43 we denote by @xmath44 the _ interior _ and by @xmath45 the _ closure _ of @xmath46 . for @xmath47 ,\\nlet @xmath48 be the unique solution of the equation @xmath49 , where the continuous and increasing function @xmath50 is defined by ( see figure  [ fig : t1 ] for a plot ) @xmath51      2 & : \\\\ ; t=0 , \\\\\\\\[2ex ]      \\\\displaystyle\\\\frac{2}{\\\\sqrt{|t|}}\\\\arctan\\\\sqrt{|t| } & : \\\\ ; t < 0 .\\n\\\\end{cases}\\\\end{aligned}\\\\ ] ] the proof of the following theorem is given in section  [ sec : proof - theorem - reft1 ] .    the sequence [ t1 ] @xmath52 satisfies a large deviation principle with scale @xmath1 and good rate function @xmath53 given by @xmath54        \\\\infty & : \\\\\\n; x\\\\leq 0 .\\n\\\\end{cases }    \\\\end{aligned}\\\\ ] ] in other words , for any @xmath55 we have @xmath56     and @xmath53 from and , respectively.,title=\\\"fig:\\\",width=226 ]   and @xmath53 from and , respectively.,title=\\\"fig:\\\",width=226 ]    both , the function @xmath57 from and @xmath53 from are plotted in figure  [ fig : t1 ] .\\nthe minimum of the rate function is attained at @xmath58 .\\nthis fact is clear from the law of large numbers , .\\nin addition , @xmath59 for @xmath60 because @xmath61 almost surely .\\nlet us now have a closer look at the behaviour of @xmath62 for @xmath63 near @xmath35 and for large @xmath63 .\\nsince @xmath64 , we have that @xmath65 , and hence , @xmath66 . in this case , @xmath67 where the last equality follows from @xmath68 .\\nto understand the behaviour for large @xmath63 , note that since @xmath69 for @xmath70 we have @xmath71 and in particular @xmath72 .\\nit follows @xmath73    note that and are equivalent .\\nindeed , @xmath74 ( this also holds with @xmath75 replaced by @xmath76 ) by construction , and @xmath77 as @xmath78 and @xmath79 as @xmath80 .\\nhence , theorem  [ t1 ] translates into a large deviation principle for @xmath20 . in the following\\nwe denote by @xmath81 the distribution of @xmath82 , i.e.  @xmath83 .\\nthe proof of the next result is given in section  [ sec : proof - coroll - refc ] ; see figure  [ fig : cor1 ] for a plot of the rate function @xmath84 .    for @xmath85\\nthe family @xmath86 [ cor : tnt ] satisfies a large deviation principle with scale @xmath87 and good rate function @xmath84 given by @xmath88 \\\\displaystyle        \\\\frac{\\\\pi^2}{2 } & : \\\\ ,   x=0 , \\\\\\\\[1.5ex ]        \\\\infty & : \\\\ , x<0 ,      \\\\end{cases }    \\\\end{aligned}\\\\ ] ] with @xmath53 from  .\\nin particular , for @xmath89 we have @xmath90     from corollary  [ cor : tnt ] .\\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\\\"fig:\\\",width=226 ]   from corollary  [ cor : tnt ] .\\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\\\"fig:\\\",width=226 ]    the distributions @xmath91 ( as well as @xmath92 ) have been described explicitely in the literature .\\n@xcite , section 6 , gives @xmath93 in principle , this formula must also give the large deviations for the measures @xmath81 , but this does not seem straight - forward .    although [ rem : angel ] the main goal of  @xcite was the analysis of spatial @xmath94-coalescents , they also provide some large deviations bounds on kingman s coalescent .\\nthese bounds are mainly based on markov inequality .\\nprecisely , in lemma 2.2 in @xcite it is shown that for @xmath95 @xmath96 and therefore @xmath97 in the neighbourhood of @xmath98 the last inequality translates easily into a bound for the rate function @xmath84 from ; see figure  [ fig : cor1 ] .\\nnamely , for @xmath99 we have @xmath100    next , we state some large deviations results connected to  . for @xmath101 we know from   that @xmath102 holds almost surely .\\nthe proof of this result is based on the well - known fact ( see e.g.  section  5 in @xcite ) that the distribution of @xmath103 can be derived using uniform order statistics : let @xmath104 be independent and uniformly distributed on @xmath105 $ ] , and @xmath106 be their order statistics .\\nadditionally , let @xmath107 be independent exponentially distributed random variables with mean @xmath23 . then , @xmath108 here the second equality in distribution is one of the well known representations of uniform spacings ; see e.g.  section  4.1 in @xcite .\\nit follows @xmath109 we will use this representation to obtain large deviations results for @xmath103 . in particular\\nwe show that upwards large deviations of @xmath103 are on the scale @xmath6 while downwards large deviations are on the scale @xmath1 . the proof is given in section  [ sec : proof - theorem - reft2 ] .    for [ t2 ]\\neach @xmath110 , we have @xmath111 furthermore @xmath112 and for each @xmath113 , we have @xmath114 the function @xmath115 is positive for @xmath116 and is given by @xmath117 here @xmath118 is a function of the form @xmath119 with @xmath120 where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution .\\nthough the rate function in   is exact it is hard to treat analytically . for this reason we provide in theorem  [ t3 ] a much simpler lower bound for downwards large deviations of @xmath103 . for the proof we use the following lemma which provides another representation of @xmath103 in terms of exponential random variables ( see section  [ sec : proofs2 ] for proofs ) .\\nlet [ l : wn ] @xmath122 be independent exponentially distributed random variables with mean @xmath23 .\\nthen , @xmath123    for [ t3 ] @xmath124 we have @xmath125    the main point in the proof of lemma  [ l : wn ] is that @xmath103 does not depend on the order of the @xmath126 and hence we can as well order them according to their size .\\nlet us briefly explain how we will use in the proof of in . since @xmath103 is minimal if @xmath127 ( whence @xmath128 ) , we have to look for possibilities that all @xmath126 s are of about the same size in order to obtain a large deviations result for @xmath103 .\\nlet @xmath129 denote the above exponential random variables ordered in increasing order , i.e.  @xmath130 is the @xmath4th smallest value .\\nusing `` competing exponential clocks '' arguments ( see also the proof of the lemma ) one can see that @xmath131 is exponentially distributed with mean @xmath132 . hence , one way of obtaining similar values for all @xmath126 s arises if @xmath133 is particularly large , which then leads to a large deviations result for @xmath103 .     from in theorem  [ t2 ] and the lower bound from in theorem  [ t3].,width=226 ]    \\\\1 .\\nlet us give some heuristics about the rates arising in theorem  [ t2 ] . for , we have to ask ourselves about the easiest way @xmath103\\nbecomes too large . from\\n, we see that this is the case if one of the @xmath126 s is too large , making this kind of deviations a local property in the sense that only a single of the @xmath126 s has to show some untypical behavior .\\nthis is different when looking at , i.e.  too small values of @xmath103 .\\nfirst , observe that @xmath103 is small only if all ( or many ) families have about equal sizes ( extreme case @xmath134 gives the minimal value @xmath128 ) .\\nhence , such downward deviations require to study a global property of the random variable @xmath103 , which is significantly harder .\\nfor the proof of we will interpret @xmath103 as a self - normalised sum and use from @xcite a result on large deviations result for such sums .    \\\\2 . from\\n, we see that in fact @xmath103 is a function of uniform order statistics , which , for instance , have been studied in detail ( although no large deviations results were given ) in @xcite .\\nhence , theorem  [ t2 ] may as well be interpreted as a large deviations result for uniform order statistics .    \\\\3 .\\nas stated in remark  [ rem : interllnfe ] , @xmath135 can be interpreted as homozygosity at time @xmath0 . using a poisson process along the tree with intensity @xmath136 , we can ask for the probability of picking two leaves from the tree which are not separated by a poisson mark , denoted by _ homozygosity in state _ , abbreviated by @xmath137 . this quantity is closely related to the poisson - dirichlet distribution and some large deviations ( in the limit of large @xmath138 )\\nwere derived in @xcite .\\nit is shown there in theorem  5.1 that @xmath139 and that @xmath140 for @xmath141 . however , a large deviation principle for the quantity @xmath142 ( noting that @xmath143 ) , which corresponds to the results from theorem  [ t2 ] , could not be obtained by @xcite . at least , it was shown that its scale can not be larger than @xmath144 .\\nthe proof of theorem  [ t1 ] is an application of the grtner - ellis theorem ; see for instance section  2.3 in @xcite .\\nlet @xmath145 $ ] and @xmath146 . to show that the sequence @xmath147 satisfies a large deviation principle with scale @xmath1 and a good rate function we need to check the following three conditions .    1\\n.   @xmath148 exists for all @xmath149 as a limit in @xmath150 .\\nfurthermore @xmath151 is lower - semicontinuous , @xmath152 , where @xmath153 .\\n@xmath94 is differentiable on @xmath154 .\\n3 .   @xmath94 is _ steep _ , i.e.  @xmath155 whenever @xmath156 and @xmath157 .    then the good rate function is given by @xmath158    we proceed in three steps .\\nfirst , we compute @xmath159 .\\nsecond , we check the further assumptions of the grtner - ellis theorem and obtain @xmath53 as the fenchel - legendre transform of @xmath94 . in the third step , for the rate function @xmath53 from\\nwe obtain its simplified form given in theorem  [ t1 ] .\\nthe limit of @xmath160 : * we will show that @xmath161 for this , recall from that @xmath162 where @xmath163 is exponentially distributed with rate @xmath164 as well as independent of @xmath165 for all @xmath166 .\\nfurthermore recall that the moment generating function of an exponentially distributed random variable @xmath167 with rate @xmath168 is given by @xmath169 =    \\\\begin{cases }      \\\\frac{\\\\lambda}{\\\\lambda - t } , & \\\\text{if $ t<\\\\lambda$},\\\\\\\\ \\\\infty ,      & \\\\text{if $ t\\\\geq \\\\lambda$. }    \\\\end{cases}\\\\end{aligned}\\\\ ] ] hence , for each @xmath170 and @xmath171 we obtain by the monotone convergence theorem @xmath172    = \\\\mathbf{e}\\\\left[e^{t n^2 \\\\sum_{k = n+1}^\\\\infty s_k/\\\\binom k2}\\\\right ]    = \\\\prod_{k = n+1}^\\\\infty \\\\mathbf{e}\\\\left[e^{tn^2 s_k/\\\\binom k 2}\\\\right].\\\\ ] ] we have to consider two cases @xmath173 and @xmath174 separately .\\nfirst suppose that @xmath175 . then there exists @xmath176 so that for all @xmath177 we have @xmath178 consequently , using , we obtain @xmath179 = \\\\infty$ ] for each @xmath177 .\\nhence , @xmath180 and @xmath181 for @xmath1 large enough .\\nthus , we have @xmath182 now suppose that @xmath183 . for @xmath184 and @xmath185\\nwe have @xmath186 . furthermore using and\\nwe can write @xmath187 using this we can rewrite @xmath188 for @xmath189 as @xmath190 and by the dominated convergence theorem we obtain @xmath191 hence , ge1 is shown with @xmath94 as in .\\nmoreover , we have @xmath192 $ ] , @xmath193 and @xmath94 is lower - semi - continuous .    * step 2 .\\nfurther assumptions of the grtner - ellis theorem : * we proceed by checking the assumptions ge2 and ge3 . for differentiability of @xmath94 for @xmath194\\nconsider for @xmath195 the function @xmath196 we have @xmath197 for @xmath198 and the derivative @xmath199 exists for each @xmath200 and is continuous in @xmath149 .\\nhence , we can interchange differentiation and integration and obtain @xmath201 furthermore , for a sequence @xmath202 with @xmath203 we obtain @xmath204 i.e.  condition ge3 is also satisfied .    * step 3 .\\nproperties of @xmath205 : * applying the grtner - ellis theorem reveals that the sequence of distributions of @xmath206 satisfies a large deviation principle with good rate function @xmath207= \\\\sup_{t \\\\leq      1 } \\\\left [ \\\\frac t2 x + \\\\int_1^\\\\infty      \\\\log\\\\left(1-\\\\frac{t}{y^2}\\\\right ) \\\\,\\\\emph dy \\\\right].\\\\end{aligned}\\\\ ] ] in order to compute that supremum , we write for @xmath208 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 - t}dy \\\\\\\\ & = x +    \\\\frac{1}{\\\\sqrt{t}}\\\\int_1^\\\\infty \\\\frac{1}{y+\\\\sqrt{t } } -    \\\\frac{1}{y-\\\\sqrt{t } } dy \\\\\\\\ & = x - \\\\frac{1}{\\\\sqrt{t } } \\\\log    \\\\frac{1+\\\\sqrt{t}}{1-\\\\sqrt{t}}\\\\end{aligned}\\\\ ] ] while for @xmath210 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 + |t|}dy \\\\\\\\ & = x -    \\\\frac{2}{\\\\sqrt{|t|}}\\\\arctan\\\\sqrt{|t|}.\\\\end{aligned}\\\\ ] ] it is easy to see that the second derivative is negative throughout , such that the supremum is attained at @xmath211 given by the solution of @xmath212 for @xmath57 as in  .\\nfinally we note that for @xmath213 the range of @xmath214 is @xmath215 and for @xmath216 $ ] the range of @xmath217 is @xmath218 $ ] .\\nhence , the scale function @xmath53 is of the form given in  .      the proof is based on the fact that @xmath219 .\\nthus , for @xmath220 we have @xmath221 and for @xmath222 @xmath223 the value @xmath224 follows from  . since the rate function @xmath53 attains its minimum at @xmath58 , is decreasing below and increasing above @xmath98 , the result follows .\\nwhen looking at , note that @xmath103 does not depend on the order of the @xmath126 s .\\ntherefore , it is possible to order them according to their size . precisely , let @xmath225 be their order statistics .\\nthen it is well - known that @xmath226 indeed , the smallest of @xmath1 independent exponentially distributed mean @xmath23 random variables is exponentially distributed with mean @xmath227 ( as does @xmath228 ) , and the second smallest then has the same distribution as @xmath229 etc .\\nnow , we obtain as follows @xmath230      we start by proving  .\\nlet @xmath110 and let @xmath231 be independent exponential random variables with mean @xmath23 . in what follows we set @xmath232 according to , it suffices to show that @xmath233 to this end we will show that for all @xmath234 , @xmath235 as well as @xmath236 and obtain by letting @xmath237 .\\nfor   we have @xmath238 we consider the two terms on the right hand side of the last display separately and start with the first one .\\nobserve that @xmath239 = \\\\infty$ ] for @xmath168 , @xmath240 = 2 $ ] and @xmath241 for @xmath242 .\\nwe use a variant of cramr s theorem for heavy - tailed random variables from @xcite .\\nin particular , we refer to the statement around equation ( 1.2 ) there ( the assumption there is fulfilled with @xmath243 replaced by @xmath244 and @xmath245 , @xmath246 and @xmath247 ) .\\nwe obtain @xmath248 for the second term on the right hand side of by the ( classical ) cramr theorem we obtain @xmath249 where @xmath250 is the fenchel - legendre transform of the function @xmath251 $ ] . now , using , and we obtain @xmath252 which shows . for the proof of\\nwe write @xmath253 again we consider both terms in the last line separately . for the first term , as in\\nwe obtain @xmath254 for the second term , we use the same argument as for and get @xmath255 combining   and   with   now gives   which proves  .    since the minimum of @xmath103 is @xmath23 ( when @xmath256 for all @xmath7 ) the assertion @xmath257 is clear .\\nit remains to prove , show that the rate function is of the form   and justify the positivity of @xmath115 for @xmath258 .    for @xmath259\\nusing we obtain @xmath260 furthermore , for @xmath258 we have @xmath261/\\\\sqrt{\\\\mathbf e[r_1 ^ 2]}$ ] .\\nthus , we can use theorem  1.1 from @xcite and obtain @xmath262.\\\\end{aligned}\\\\ ] ] now we have @xmath263 & = \\\\int_0^\\\\infty \\\\exp\\\\bigl(-y + t(c    y - \\\\frac1{2\\\\sqrt x}(y^2+c^2))\\\\bigr ) \\\\ , dy \\\\\\\\ \\\\intertext{and elementary integration yields } & = \\\\frac{\\\\sqrt{2\\\\pi}x^{1/4}}{\\\\sqrt{t } }      \\\\exp\\\\left(\\\\frac{(tc-1)^2x - t^2c^2}{2t\\\\sqrt{x}}\\\\right )      \\\\phi\\\\left(\\\\frac{(tc-1)x^{1/4}}{\\\\sqrt t}\\\\right),\\\\end{aligned}\\\\ ] ] where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution . taking @xmath264 of the last term we obtain .\\nnow we fix @xmath258 and show that @xmath115 is positive . in the sequel we write\\n@xmath265 we have @xmath266 \\\\\\\\ & \\\\ge   \\\\mathbf    e\\\\left [ \\\\inf_{t \\\\ge 0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] \\\\\\\\    & = \\\\mathbf e\\\\left[\\\\mathbbm 1_{\\\\{h(r_1,c ) < 0\\\\ } } \\\\inf_{t \\\\ge        0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] +    \\\\mathbf e\\\\left [ \\\\mathbbm 1_{\\\\{h(r_1,c ) \\\\ge 0\\\\ } }   \\\\inf_{t \\\\ge        0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] \\\\\\\\    & = \\\\mathbf p \\\\bigl(h(r_1,c ) \\\\ge 0\\\\bigr).\\\\end{aligned}\\\\ ] ] the function @xmath267 is non - negative on the interval @xmath268 $ ] where @xmath269 are the zeros of the function .\\nit follows @xmath270 =    \\\\mathbf p \\\\left ( r_1 \\\\le r_1 \\\\le r_2 \\\\right ) =    e^{-c(\\\\sqrt{x}-\\\\sqrt{x-1 } ) } - e^{-c(\\\\sqrt{x}+\\\\sqrt{x-1})}.\\\\end{aligned}\\\\ ] ] finally , by elementary calculation we obtain @xmath271 this expression ( and therefore also @xmath115 ) is positive for @xmath258 .\\nthus , the proof of theorem  [ t2 ] is concluded .\\nwe prove the inequality using lemma  [ l : wn ] .\\nlet @xmath272 and set @xmath273 . for @xmath11\\nwe have @xmath274 now @xmath275 , and conditioning in the second factor in the curly braces can be removed by using the fact that conditioned on @xmath276 the exponential random variable @xmath277 has the same distribution as @xmath278 .\\nafter some elementary calculations we see that the last line of the above display equals @xmath279 from the strong law of large numbers and with lemma  [ l : wn ] we know that @xmath280{n\\\\to\\\\infty } 2 \\\\quad \\\\text{almost surely.}\\\\end{aligned}\\\\ ] ] it follows that almost surely @xmath281{n\\\\to\\\\infty } \\\\frac{2 + 2y+y^2}{1 + 2y+y^2 } = x.\\\\end{aligned}\\\\ ] ] thus , @xmath282 the rest follows by letting @xmath283 .\\nwe thank shui feng for pointing out connections to @xcite and nina gantert and alain rouault for pointing out the reference @xcite and fruitful email discussion that led to the exact rate function in .\\nthis research was supported by the dfg through grants pf-672/6 - 1 to ad and pp .\\nevans , s. ( 2000 ) .\\nkingman s coalescent as a random metric space . in _\\nstochastic models : proceedings of the international conference on stochastic models in honour of professor donald a. dawson , ottawa , canada , june 10 - 13 , 1998 ( l.g gorostiza and b.g .\\nivanoff eds . )\\n_ , canad .\",\n          \"it is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy .\\nthe interferometer detectors are now under operation and awaiting the first signal of gws  @xcite .\\nit is also known that pulsar timing arrays ( ptas ) can be used as a detector for gws @xcite .\\nthese detectors are used to search for very low frequency ( @xmath0 ) gravitational waves , where the lower limit of the observable frequencies is determined by the inverse of total observation time @xmath1 .\\nindeed , the total observation time has a crucial role in ptas , because ptas are most sensitive near the lower edge of observable frequencies @xcite . taking into account its sensitivity ,\\nthe first direct detection of the gravitational waves might be achieved by ptas .\\nthe main target of ptas is the stochastic gravitational wave background ( sgwb ) generated by a large number of unresolved sources with the astrophysical origin or the cosmological origin in the early universe .\\nthe promising sources are super massive black hole binaries  @xcite , cosmic ( super)string  @xcite , and inflation  @xcite .\\nprevious studies have assumed that the sgwb is isotropic and unpolarized  @xcite .\\nthese assumptions are reasonable for the primary detection of the sgwb , but the deviation from the isotropy and the polarizations should have rich information of sources of gravitational waves .\\nrecently , the cross - correlation formalism has been generalized to deal with anisotropy in the sgwb @xcite .\\nresult of this work enables us to consider arbitrary levels of anisotropy , and a bayesian approach was performed by using this formalism @xcite . on the other hand , for the anisotropy of the sgwb , the cross - correlation formalism has been also developed in the case of interferometer detectors  @xcite .\\nas to the polarization , there are works including the ones motivated by the modified gravity  @xcite\\n. we can envisage supermassive black hole binaries emit circularly polarized sgwb due to the chern - simons term  @xcite .\\nthere may also exist cosmological sgwb with circular polarization in the presence of parity violating term in gravity sector  @xcite .    in this paper\\n, we investigate the detectability of circular polarization in the sgwb by ptas .\\nwe characterize sgwb by the so called stokes @xmath2 parameter  @xcite and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb .\\nwe also discuss a method to separate the intensity ( @xmath3 mode ) and circular polarization ( @xmath2 mode ) of the sgwb .\\nthe paper is organized as follows . in section [ sec :\\nstokes parameters for a plane gravitational wave ] , we introduce the stokes parameters for monochromatic plane gravitational waves , and clarify the physical meaning of the stokes parameters @xmath3 and @xmath2 . in section [ sec : formulation ] , we formulate the cross - correlation formalism for anisotropic circularly polarized sgwb with ptas .\\nthe basic framework is essentially a combination of the formalism of @xcite , and the polarization decomposition formula of the sgwb derived in @xcite . in section [ sec : the generalized overlap reduction function for circular polarization ] , we calculate the generalized orfs for the @xmath2 mode .\\nthe results for @xmath3 mode are consistent with the previous work  @xcite . in section [ sec : separation method ] , we give a method for separation between the @xmath3 mode and @xmath2 mode of the sgwb .\\nthe final section is devoted to the conclusion . in appendixes , we present analytic results for the generalized overlap reduction functions . in this paper\\n, we will use the gravitational units @xmath4 .\\nlet us consider the stokes parameters for plane waves traveling in the direction @xmath5 , which can be described by @xmath6 \\\\\\n, \\\\\\\\ & & h_{xy}(t , z)=h_{yx}(t , z)={\\\\rm re}[b_{\\\\times}\\\\mathrm{e}^{-iw(t - z ) } ] \\\\ .\\\\end{aligned}\\\\ ] ] for an idealized monochromatic plane wave , complex amplitudes @xmath7 and @xmath8 are constants .\\npolarization of the plane gws is characterized by the tensor , ( see @xcite and also electromagnetic case @xcite ) @xmath9 where @xmath10 take @xmath11 .\\nany @xmath12 hermitian matrix can be expanded by the pauli and the unit matrices with real coefficients .\\nhence , the @xmath13 hermitian matrix @xmath14 can be written as @xmath15 where @xmath16 by analogy with electromagnetic cases , @xmath17 and @xmath2 are called stokes parameters . comparing with , we can read off the stokes parameters as @xmath18= b_{+}^{\\\\ast}b_{\\\\times}+ b_{\\\\times}^{\\\\ast}b_{+},\\\\\\\\ v&=&-2{\\\\rm i m } [ b_{+}^{\\\\ast}b_{\\\\times}]=i ( b_{+}^{\\\\ast}b_{\\\\times}- b_{\\\\times}^{\\\\ast}b_{+}).\\\\label{stv}\\\\end{aligned}\\\\ ] ] apparently , the real parameter @xmath3 is the intensity of gws . in order to reveal the physical meaning of the real parameter @xmath2 , we define the circular polarization bases @xcite @xmath19 from the relation @xmath20 we see @xmath21\\nthus , we can rewrite the stokes parameters - as @xmath22 from the above expression , we see that the real parameter @xmath2 characterizes the asymmetry of circular polarization amplitudes .\\nthe other parameters @xmath23 and @xmath24 have additional information about linear polarizations by analogy with the electromagnetic cases .\\nalternatively , we can also define the tensor @xmath25 in circular polarization bases @xmath26 where @xmath27 .\\nnote that the stokes parameters satisfy a relation @xmath28    next , we consider the transformation of the stokes parameters under rotations around the @xmath5 axis . the rotation around the @xmath5 axis is given by @xmath29 where @xmath30 is the angle of the rotation .\\nthe gws traveling in the direction @xmath5 @xmath31 transform as @xmath32 where we took the transverse traceless gauge @xmath33 after a short calculation , we obtain @xmath34 using and , the four stokes parameters ( [ sti])-([stv ] ) transform as @xmath35 as you can see , the parameters @xmath23 and @xmath24 depend on the rotation angle @xmath30 .\\nthis reflects the fact that @xmath23 and @xmath24 parameters characterize linear polarizations .\\nnote that this transformation is similar to the transformation of electromagnetic case except for the angle @xmath36 and can be rewritten as @xmath37\\nin this section , we study anisotropic distribution of sgwb and focus on the detectability of circular polarizations with pulsar timing arrays .\\nwe combine the analysis of @xcite and that of @xcite . in sec.[subsec : the spectral ] , we derive the power spectral density for anisotropic circularly polarized sgwb @xmath38 .\\nthen we also derive the dimensionless density parameter @xmath39 which is expressed by the frequency spectrum of intensity @xmath40  @xcite . in sec.[subsec : the signal ] , we extend the generalized orfs to cases with circular polarizations characterized by the parameter @xmath2 . for simplicity ,\\nwe consider specific anisotropic patterns with @xmath41 expressed by the spherical harmonics @xmath42 .      in the transverse traceless gauge , metric perturbations @xmath43 with a given propagation direction @xmath44\\ncan be expanded as @xcite @xmath45 where the fourier amplitude satisfies @xmath46 as a consequence of the reality of @xmath43 , @xmath47 , @xmath48 is the frequency of the gws , @xmath49 are spatial indices , @xmath50 label polarizations .\\nnote that the fourier amplitude @xmath51 satisfies the relation @xmath52 where @xmath53 was defined by .\\nthe polarized tensors @xmath54 are defined by @xmath55 where @xmath56 and @xmath57 are unit orthogonal vectors perpendicular to @xmath58 .\\nthe polarization tensors satisfy @xmath59 with polar coordinates , the direction @xmath44 can be represented by @xmath60 and the polarization basis vectors read @xmath61    we assume the fourier amplitudes @xmath62 are random variables , which is stationary and gaussian .\\nhowever , they are not isotropic and unpolarized .\\nthe ensemble average of fourier amplitudes can be written as @xcite @xmath63 where @xmath64 here , the bracket @xmath65 represents an ensemble average , and @xmath66 is the dirac delta function on the two - sphere .\\nthe gw power spectral density @xmath38 is a hermitian matrix , and satisfies @xmath67 because of the relation @xmath46 .\\ntherefore , we have the relations @xmath68 note that the stokes parameters are not exactly the same as the expression of , but they have the relation and characterize the same polarization .\\nwe further assume that the sgwbs satisfy @xmath69 we also assume the directional dependence of the sgwb is frequency independent @xcite .\\nthis implies the gw power spectral density is factorized into two parts , one of which depends on the direction while the other depends on the frequency .\\nbecause of the transformations - , the parameters @xmath3 and @xmath2 have spin 0 and the parameters @xmath70 have spin @xmath71  @xcite . to analyze the sgwb on the sky , it is convenient to expand the stokes parameters by spherical harmonics @xmath72\\n. however , since @xmath70 parameters have spin @xmath71 , they have to be expanded by the spin - weighted harmonics @xmath73 @xcite .\\nthus , we obtain @xmath74 in this paper , we study specific anisotropic patterns with @xmath41 for simplicity .\\ntherefore , we can neglect @xmath23 and @xmath24 from now on .\\nthus , the gw power spectral density becomes @xmath75 where @xmath76 so , we focus on the parameters @xmath3 and @xmath2 . in what follows , we will use the following shorthand notation @xmath77    next , we consider the dimensionless density parameter  @xcite @xmath78 where @xmath79 is the critical density , @xmath80 is the present value of the hubble parameter , @xmath81 is the energy density of gravitational waves , and @xmath82 is the energy density in the frequency range @xmath48 to @xmath83 .\\nthe bracket @xmath65 represents the ensemble average .\\nhowever , actually , we take a spatial average over the wave lengths @xmath84 of gws or a temporal average over the periods @xmath85 of gws . here\\n, we assumed the ergodicity , namely , the ensemble average can be replaced by the temporal average .\\nusing , , , as well as @xmath46 and @xmath86 , we get @xmath87 then we define @xmath88 hence , the dimensionless quantity @xmath39 in is given by @xmath89 where the spherical harmonics are orthogonal and normalized as @xmath90 using @xmath91 , we obtain @xmath92 without loss of generality , we normalize the monopole moment as @xmath93 so , becomes @xmath94      the time of arrival of radio pulses from the pulsar is affected by gws .\\nconsider a pulsar with frequency @xmath95 located in the direction @xmath96 . to detect the sgwb ,\\nlet us consider the redshift of the pulse from a pulsar @xcite @xmath97 where @xmath98 is a frequency detected at the earth and @xmath96 is the direction to the pulsar .\\nthe unit vector @xmath44 represents the direction of propagation of gravitational plane waves .\\nwe also defined the difference between the metric perturbations at the pulsar @xmath99 and at the earth @xmath100 as @xmath101 the gravitational plane waves at each point is defined as @xmath102 for the sgwb , the redshift have to be integrated over the direction of propagation of the gravitational waves @xmath44 : @xmath103 we choose a coordinate system @xmath104 and assume that the amplitudes of the metric perturbation at the pulsar and the earth are the same .\\nthen becomes @xmath105 and therefore , reads @xmath106 where we have defined the pattern functions for pulsars @xmath107 note that our convention for the fourier transformation is @xmath108 therefore , the fourier transformation of can be written as @xmath109    in the actual signals from a pulsar , there exist noises .\\nhence , we need to use the correlation analysis .\\nwe consider the signals from two pulsars @xmath110 where @xmath111 labels the pulsar . here\\n, @xmath112 denotes the signal from the pulsar and @xmath113 denotes the noise intrinsic to the measurement .\\nwe assume the noises are stationary , gaussian and are not correlated between the two pulsars .\\nto correlate the signals of two measurements , we define @xmath114 where @xmath1 is the total observation time and @xmath115 is a real filter function which should be optimal to maximize signal - to - noise ratio . in the case of interferometer\\n, the optimal filter function falls to zero for large @xmath116 compered to the travel time of the light between the detecters .\\nsince the signals of two detectors are expected to correlate due to the same effect of the gravitational waves , the optimal filter function should behave this way .\\nthen , typically one of the detectors is very close to the other compared to the total observation time @xmath1 .\\ntherefore , the total observation time @xmath1 can be extended to @xmath117 @xcite .\\nin contrast , in the case of pta , it is invalid that @xmath1 is very large compered to the travel time of the light between the pulsars .\\nnevertheless , we can assume that one of the two @xmath1 can be expanded to @xmath117 , because in situations @xmath118 and @xmath119 it is known that we can ignore the effect of the distance @xmath120 of pulsars .\\nin this case , it is clear that any locations of the pulsars are optimal and optimal filter function should behave like as the interferometer case @xcite .    using these assumptions @xmath118 and @xmath119 , we can rewrite as @xmath121 where @xmath122 note that @xmath123 satisfies @xmath124 , because @xmath125 is real .\\nmoreover , to deal with the unphysical region @xmath126 we require @xmath127 .\\nthus , @xmath123 becomes real .\\ntaking the ensemble average , using @xmath128 , @xmath118 , and assuming the noises in the two measurements are not correlated , we get @xmath129\\\\ , \\\\label{s2}\\\\end{aligned}\\\\ ] ] where we have defined @xmath130 the functions @xmath131 and @xmath132 are called the generalized orfs , which describe the angular sensitivity of the pulsars for the sgwb . note that , as we already mentioned , we consider the cases of @xmath41 for simplicity\\n. then we have assumed @xmath118 and @xmath119 , this assumption implies that approximately becomes @xmath133 due to the rapid oscillation of the phase factor .\\ntherefore , the distance @xmath120 of the pulsars does not appear in the generalized orfs , and hence the generalized orfs do not depend on the frequency .    as you can see from ,\\nthe correlation of the two measurements involve both the total intensity and the circular polarization .\\nhowever , the degeneracy can be disentangled by using separation method , which will be discussed in the section [ sec : separation method ] .\\nin this section , we consider the generalized orfs for circular polarizations : @xmath134 where we defined @xmath135 in the above , we have used and the fact that the generalized orfs do not depend on frequency . for computation of the generalized orfs for circular polarizations ,\\nit is convenient to use the computational frame @xcite defined by @xmath136 where @xmath137 is the angular separation between the two pulsars . using - , , and\\n, one can easily show that @xmath138 we therefore get @xmath139 the explicit form of the spherical harmonics reads @xmath140 where @xmath141 is the normalization factor .\\nthe associated legendre functions are given by @xmath142 and @xmath143 with the legendre functions @xmath144\\\\ .\\\\label{pl}\\\\end{aligned}\\\\ ] ] using the spherical harmonics , becomes @xmath145 where we have used the fact that the function of @xmath146 is odd parity in the case of @xmath147 and is even parity in the case of @xmath148 .\\nnote that the generalized orfs for circular polarizations are real functions . in the case of @xmath149 and/or @xmath150 ,\\nthe integrand in vanishes .\\ntherefore , we can not detect circular polarizations for these cases .\\nthis fact for @xmath151 implies that we do not need to consider auto - correlation for a single pulsar .\\nthis is the reason why we neglected auto - correlation term in .    integrating ,\\nwe get the following form for @xmath152 : @xmath153 for @xmath154 , we have obtained @xmath155 \\\\ , \\\\\\\\ \\\\gamma^{v}_{1 - 1}&=&\\\\gamma^{v}_{11 } \\\\ , \\\\end{aligned}\\\\ ] ] recall that @xmath156 .\\nthe derivation of this formula for @xmath154 can be found in appendix [ sec : angular integral of the generalized overlap reduction function for dipole circular polarization ] .    for @xmath157 , we derived the following : @xmath158\\\\ , \\\\\\\\ \\\\gamma^{v}_{2 - 1}&=&\\\\gamma^{v}_{21}\\\\ , \\\\\\\\\\n\\\\gamma^{v}_{22}&=&-\\\\frac{\\\\sqrt{30\\\\pi}}{6}(1-\\\\cos\\\\xi)\\\\left[2-\\\\cos\\\\xi+6\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{2 - 2}&=&-\\\\gamma^{v}_{22}\\\\ , \\\\end{aligned}\\\\ ] ] for @xmath159 , the results are @xmath160\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 1}&=&\\\\gamma^{v}_{31}\\\\ , \\\\\\\\ \\\\gamma^{v}_{32}&=&\\\\frac{\\\\sqrt{210\\\\pi}}{24}(1-\\\\cos\\\\xi)\\\\left[8 - 5\\\\cos\\\\xi-\\\\cos^2\\\\xi+24\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 2}&=&-\\\\gamma^{v}_{3 - 2}\\\\ , \\\\\\\\ \\\\gamma^{v}_{33}&=&-\\\\frac{\\\\sqrt{35\\\\pi}}{16}\\\\sin\\\\xi\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\left[11 - 6\\\\cos\\\\xi-\\\\cos^2\\\\xi+32\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 3}&=&\\\\gamma^{v}_{33}\\\\ .\\\\end{aligned}\\\\ ] ] in fig .\\n[ gv ] , we plotted these generalized orfs as a function of the angular separation between the two pulsars @xmath137 .\\nit is apparent that considering the @xmath2 mode does not make sense when we only consider the isotropic ( @xmath152 ) orf . on the other hand ,\\nwhen we consider anisotropic ( @xmath161 ) orfs , it is worth taking into account polarizations .\\nthe polarizations of the sgwb would give us rich information both of super massive black hole binaries and of inflation in the early universe .\\nas a function of the angular separation between the two pulsars @xmath137 . in fig .\\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 . in fig .\\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( d ) @xmath159    using the same procedure described in the above to derive the generalized orfs for circular polarizations , we can also derive the generalized orfs for the intensity @xmath166 where @xmath167 the angular integral in this case was performed in @xcite .\\nthe results are summarized in appendix [ sec : the generalized overlap reduction function for intensity ] .\\nin this section , we separate the @xmath3 mode and @xmath2 mode of the sgwb with correlation analysis @xcite . to this aim ,\\nwe use four pulsars ( actually we need at least three pulsars ) , and define correlations of @xmath168 @xmath169 where @xmath170 label the pulsars . comparing with , we obtain @xmath171 \\\\ ,\\n\\\\label{1c12}\\\\\\\\ & & c_{34}(f)=\\\\sum_{lm}^{l=3}\\\\left[c_{lm}^{i}i(f)\\\\gamma_{lm,34}^{i}+c_{lm}^{v}v(f)\\\\gamma_{lm,34}^{v}\\\\right ] \\\\ .\\\\label{1c34}\\\\end{aligned}\\\\ ] ] if the @xmath3 mode and @xmath2 mode of the sgwb are dominated by a certain @xmath172 and @xmath173 , and become @xmath174 \\\\ , \\\\label{2c12 } \\\\\\\\ & & c_{34}(f)=\\\\left[c _ { l m}^{i}i(f)\\\\gamma _ { l m,34}^{i}+c _ { l ' m'}^{v}v(f)\\\\gamma _ { l ' m',34}^{v}\\\\right ] \\\\ .\\\\label{2c34}\\\\end{aligned}\\\\ ] ] to separate the intensity and the circular polarization , we take the following linear combinations @xmath175 where we defined coefficients @xmath176 as you can see , @xmath177 contains only @xmath40 , and @xmath178 contains only @xmath179 .\\nfor the signal @xmath180 , the formulas corresponding to and are given by @xmath181 \\\\ , \\\\label{sp}\\\\end{aligned}\\\\ ] ] where @xmath182 denotes @xmath3 and @xmath2 .\\nwe assume @xmath183 and that the noise in the four pulsars are not correlated .\\nwe also assume that the ensemble average of fourier amplitudes of the noises @xmath184 is of the form @xmath185 where @xmath186 is the noise power spectral density .\\nthe reality of @xmath187 gives rise to @xmath188 and therefore we obtain @xmath189 . without loss of generality\\n, we can assume @xmath190 then we obtain corresponding noises @xmath191 : @xmath192\\\\ , \\\\label{np}\\\\end{aligned}\\\\ ] ] where @xmath193^{1/2 } \\\\label{sn12 } \\\\ , \\\\quad s_{n,34}(f ) \\\\equiv [ s_{n,3}(f)s_{n,4}(f)]^{1/2 } \\\\label{sn34 } \\\\ .\\\\end{aligned}\\\\ ] ] using the inner product @xmath194 \\\\ , \\\\end{aligned}\\\\ ] ] we can rewrite , as @xmath195 therefore , the optimal filter function can be chosen as @xmath196 using , we get optimal signal - to - noise ratio @xmath197^{1/2}\\\\ .\\\\label{snr}\\\\end{aligned}\\\\ ] ] plugging , , and into , we obtain @xmath198^{1/2}\\\\ , \\\\\\\\\\n{ \\\\rm snr}_{v}&=&\\\\left[t\\\\int_{-\\\\infty}^{\\\\infty}df\\\\,\\\\,\\\\frac{\\\\left(c^{v}_{{l}'{m}'}\\\\right)^{2}v^{2}(f)\\\\left(\\\\gamma_{{l}'{m}',34}^{v}\\\\gamma^{i}_{{l}{m},12}-\\\\gamma_{{l}'{m}',12}^{v}\\\\gamma^{i}_{{l}{m},34}\\\\right)^2}{\\\\left(\\\\gamma^{i}_{{l}{m},12}\\\\right)^2s^{2}_{n,34}(f)+\\\\left(\\\\gamma^{i}_{{l}{m},34}\\\\right)^2s^{2}_{n,12}(f)}\\\\right]^{1/2}\\\\ .\\\\end{aligned}\\\\ ] ] if we assume all of the noise power spectral densities are the same , becomes @xmath199 thus , the compiled orfs can be defined as @xmath200^{1/2}}\\\\ , \\\\\\\\ \\\\gamma_{12:34}^{v}&\\\\equiv&\\\\frac{\\\\gamma_{{l}'{m}',34}^{v}\\\\gamma^{i}_{{l}{m},12}-\\\\gamma_{{l}'{m}',12}^{v}\\\\gamma^{i}_{{l}{m},34}}{\\\\left[\\\\left(\\\\gamma^{i}_{{l}{m},12}\\\\right)^2+\\\\left(\\\\gamma^{i}_{{l}{m},34}\\\\right)^2\\\\right]^{1/2}}\\\\ .\\\\end{aligned}\\\\ ] ] this compiled orfs @xmath201 and @xmath202 describe the angular sensitivity of the four pulsars for the pure @xmath3 and @xmath2 mode of the sgwb , respectively .\\nnote that , to do this separation , we must know a priori the coefficients @xmath203 and @xmath204 .\\nif we do not assume , the generalized orfs depend on the frequency . in this case\\n, it seems difficult to calculate these coefficients .\\nwe next consider the case that @xmath3 mode and/or @xmath2 mode dominant in two or more @xmath205 . in this case , if we have a priori knowledge of the values of @xmath206 in each of @xmath205 for coefficients\\n@xmath203 and @xmath204 , we can separate @xmath3 mode and @xmath2 mode . for example , assume that @xmath3 mode is dominated by @xmath207 , while @xmath2 mode is dominated by @xmath208 , then and become @xmath209\\\\ , \\\\label{3c12}\\\\\\\\ & & c_{34}(f)=\\\\left[c^{i}_{00}i(f)\\\\left(\\\\gamma_{00,34}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)+c_{11}^{v}v(f)\\\\gamma_{11,34}^{v}\\\\right]\\\\ .\\\\label{3c34}\\\\end{aligned}\\\\ ] ] thus , we can separate @xmath3 mode and @xmath2 mode by using linear combinations @xmath210\\\\ , \\\\\\\\\\nd_{v}&\\\\equiv&a_{v}c_{34}(f)+b_{v}c_{12}(f ) \\\\nonumber\\\\\\\\ & = & c_{11}^{v}v(f)\\\\left[\\\\gamma_{11,34}^{v}\\\\left(\\\\gamma_{00,12}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)-\\\\gamma_{11,12}^{v}\\\\left(\\\\gamma_{00,34}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)\\\\right]\\\\ , \\\\end{aligned}\\\\ ] ] where @xmath211 as in the previous calculations , we can get the compiled orfs @xmath212^{1/2}}\\\\ , \\\\label{gi1234}\\\\\\\\ \\\\gamma_{12:34}^{v}&\\\\equiv&\\\\frac{\\\\gamma_{11,34}^{v}\\\\left(\\\\gamma_{00,12}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)-\\\\gamma_{11,12}^{v}\\\\left(\\\\gamma_{00,34}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)}{\\\\left[\\\\left(\\\\gamma_{00,12}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)^2+\\\\left(\\\\gamma_{00,34}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)^2\\\\right]^{1/2}}\\\\ .\\\\label{gv1234}\\\\end{aligned}\\\\ ] ]    [ cols=\\\"^,^ \\\" , ]     in fig .\\n[ cg ] we show some compiled orfs @xmath213 ( left panels ) and @xmath214 ( right panels ) as a function of the two angular separations @xmath137 and @xmath215 for two pulsar pairs , respectively .\\nwe used the expressions of @xmath2 mode and @xmath3 mode ( see appendix [ sec : the generalized overlap reduction function for intensity ] ) , and we assumed @xmath216 for simplicity . in fig .\\n[ cg](a ) and [ cg](b ) , the @xmath3 mode is dominated by @xmath217 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](c ) and [ cg](d ) , the @xmath3 mode is dominated by @xmath219 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath207 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath220 and @xmath2 mode is dominated by @xmath218 . by definition , in the case of @xmath221 ,\\nthe compiled orfs are zero .\\nwe have studied the detectability of the stochastic gravitational waves with ptas . in most of the previous works ,\\nthe isotropy of sgwb has been assumed for the analysis .\\nrecently , however , a stochastic gravitational wave background with anisotropy have been considered .\\nthe information of the anisotropic pattern of the distribution should contain important information of the sources such as supermassive black hole binaries and the sources in the early universe .\\nit is also intriguing to take into account the polarization of sgwb in the pta analysis .\\ntherefore , we extended the correlation analysis to circularly polarized sgwb and calculated generalized overlap reduction functions for them .\\nit turned out that the circular polarization can not be detected for an isotropic background .\\nhowever , when the distribution has anisotropy , we have shown that there is a chance to observe circular polarizations in the sgwb .\\nwe also discussed how to separate polarized modes from unpolarized modes of gravitational waves .\\nif we have a priori knowledge of the abundance ratio for each mode in each of @xmath205 , we can separate @xmath3 mode and @xmath2 mode in general .\\nthis would be possible if we start from fundamental theory and calculate the spectrum of sgwb .\\nin particular , in the case that the signal of lowest @xmath222 is dominant , we performed the separation of @xmath3 mode and @xmath2 mode explicitly .\\nthis work was supported by grants - in - aid for scientific research ( c ) no.25400251 and \\\" mext grant - in - aid for scientific research on innovative areas no.26104708 and `` cosmic acceleration''(no.15h05895 ) .\\nin this appendix , we perform angular integration of the generalized orf for dipole ( @xmath154 ) circular polarization ( see @xcite ) : @xmath223 where we have defined @xmath224 .\\nit is obvious that in the case of @xmath225 , integrand of the generalized orf is zero , because of @xmath226 , then we obtain @xmath227 then , using - , we calculate @xmath228 and we find @xmath229    therefore we only have to consider the dipole generalized orf in the case of @xmath154 , @xmath230 : @xmath231 where @xmath232 first , to calculate @xmath233 , we use contour integral in the complex plane . defining @xmath234 and substituting @xmath235 into , we can rewrite @xmath233 as @xmath236 } \\\\ , \\\\end{aligned}\\\\ ] ] where @xmath237 denotes a unit circle .\\nwe can factorize the denominator of the integrand and get @xmath238 where @xmath239 hereafter , the upper sign applies when @xmath240 and the lower one applies when @xmath241 .\\nnote that we only consider the region @xmath242 , so we have used the relation @xmath243 in above expression . in the region\\n@xmath244 , @xmath245 is inside the unit circle @xmath237 except for @xmath246 and @xmath247 is outside the unit circle @xmath237 .\\nnow , we can perform the integral using the residue theorem @xmath248 where @xmath249 the residues inside the unit circle @xmath237 can be evaluated as @xmath250\\\\right\\\\ }             = \\\\frac{i(z_{+}+z_{-})}{2\\\\sqrt{1-x^2}\\\\sin\\\\xi } \\\\ , \\\\end{aligned}\\\\ ] ] @xmath251 thus , we obtain @xmath252 next , we consider @xmath253 defined in\\n. using , we can calculate @xmath253 as @xmath254    similarly , we can evaluate @xmath255 given in . to calculate @xmath255 in the complex plane , we again substitute into and obtain @xmath256 we use the residue theorem @xmath257 where @xmath258 the residues inside the unit circle @xmath237 can be calculated as @xmath259\\\\right\\\\ }        = \\\\frac{i(z_{+}^2+z_{-}^2)}{4\\\\sqrt{1-x^2}\\\\sin\\\\xi } \\\\ , \\\\end{aligned}\\\\ ] ] @xmath260 therefore , @xmath255 becomes @xmath261 substituting to , we can calculate @xmath262 : @xmath263    finally , substituting and into , we get the generalized orf for @xmath264 @xmath265\\\\ .\\\\end{aligned}\\\\ ] ]     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . fig . [ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) . the black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( d ) @xmath159\\nin this appendix , we show orfs for the intensity @xcite .\\nthe following form for @xmath152 was derived in @xcite , and our expressions are identical to their expressions : @xmath271\\\\ , \\\\end{aligned}\\\\ ] ] for , @xmath154 , we calculated as @xmath272\\\\ , \\\\\\\\ \\\\gamma^{i}_{11}&=&\\\\frac{\\\\sqrt{6\\\\pi}}{12}\\\\sin\\\\xi\\\\left[1 + 3(1-\\\\cos\\\\xi)\\\\left\\\\{1+\\\\frac{4}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right\\\\}\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{1 - 1}&=&-\\\\gamma^{i}_{11}\\\\ , \\\\end{aligned}\\\\ ] ] for @xmath157 , we obtain @xmath273\\\\ , \\\\\\\\ \\\\gamma^{i}_{21}&=&-\\\\frac{\\\\sqrt{30\\\\pi}}{60}\\\\sin\\\\xi\\\\left[21 - 15\\\\cos\\\\xi-5\\\\cos^2\\\\xi+60\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 1}&=&-\\\\gamma^{i}_{2 - 1}\\\\ , \\\\\\\\ \\\\gamma^{i}_{22}&=&\\\\frac{\\\\sqrt{30\\\\pi}}{24}(1-\\\\cos\\\\xi)\\\\left[9 - 4\\\\cos\\\\xi-\\\\cos^2\\\\xi+24\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 2}&=&\\\\gamma^{i}_{22}\\\\ ,\\n\\\\end{aligned}\\\\ ] ] for @xmath159 , it is straightforward to reach the following @xmath274\\\\ , \\\\\\\\ \\\\gamma^{i}_{31}&=&\\\\frac{\\\\sqrt{21\\\\pi}}{48}\\\\sin\\\\xi(1-\\\\cos\\\\xi)\\\\left[34 + 15\\\\cos\\\\xi+5\\\\cos^2\\\\xi+\\\\frac{96}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 1}&=&-\\\\gamma^{i}_{31}\\\\ , \\\\\\\\ \\\\gamma^{i}_{32}&=&-\\\\frac{\\\\sqrt{210\\\\pi}}{48}(1-\\\\cos\\\\xi)\\\\left[17 - 9\\\\cos\\\\xi-3\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+48\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 2}&=&\\\\gamma^{i}_{32}\\\\ , \\\\\\\\ \\\\gamma^{i}_{33}&=&\\\\frac{\\\\sqrt{35\\\\pi}}{48}\\\\frac{(1-\\\\cos\\\\xi)^2}{\\\\sin\\\\xi}\\\\left[34 - 17\\\\cos\\\\xi-4\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+96\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 3}&=&-\\\\gamma^{i}_{33}\\\\ .\\\\end{aligned}\\\\ ] ] these are plotted in fig .\\nthe generalized orfs of total intensity are different from that of circular polarization in that the value for @xmath149 is non - trivial .\\nthen the @xmath3 mode orfs for @xmath275 have value even in the case of @xmath151 .\\nthis implies that we can consider auto - correlation for a single pulsar .\\n99 j.  aasi _ et al .\\n_ [ ligo scientific collaboration ] , class .\\ngrav .   * 32 * , 074001 ( 2015 ) doi:10.1088/0264 - 9381/32/7/074001 [ arxiv:1411.4547 [ gr - qc ] ] .\\nf.  acernese _ et al . _\\n[ virgo collaboration ] , class .\\ngrav .   * 32 * , no . 2 , 024001 ( 2015 ) doi:10.1088/0264 - 9381/32/2/024001 [ arxiv:1408.3978 [ gr - qc ] ] . k.  somiya [ kagra collaboration ] , class .\\n* 29 * , 124007 ( 2012 ) doi:10.1088/0264 - 9381/29/12/124007 [ arxiv:1111.7185 [ gr - qc ] ] .\\ns.  l.  detweiler , astrophys .\\nj.   * 234 * , 1100 ( 1979 ) .\\ndoi:10.1086/157593 romani , r. w. ( 1989 ) .\\ntiming a millisecond pulsar array . timing neutron stars , 113 - 117 .\\nl.  lentati _ et al .\\n_ , mon .  not .\\nsoc .   * 453 * , 2576 ( 2015 ) [ arxiv:1504.03692 [ astro-ph.co ] ] .\\nz.  arzoumanian _ et al .\\n_ [ nanograv collaboration ] , arxiv:1508.03024 [ astro-ph.ga ] . e.  s.  phinney , astro - ph/0108028 . a.  vilenkin , phys .\\nrept .   * 121 * , 263 ( 1985 ) .\\ns.  kuroyanagi , k.  miyamoto , t.  sekiguchi , k.  takahashi and j.  silk , phys .\\nd * 87 * , no . 2 , 023522 ( 2013 ) [ phys .\\nd * 87 * , no .\\n6 , 069903 ( 2013 ) ] [ arxiv:1210.2829 [ astro-ph.co ] ] .\\nm.  maggiore , gr - qc/0008027 .\\nl.  p.  grishchuk , phys .\\n* 48 * , 1235 ( 2005 ) doi:10.1070/pu2005v048n12abeh005795 [ gr - qc/0504018 ] .\\nb.  allen and j.  d.  romano , phys .\\nd * 59 * , 102001 ( 1999 ) [ gr - qc/9710117 ] .\\nc.  m.  f.  mingarelli , t.  sidery , i.  mandel and a.  vecchio , phys .\\nd * 88 * , no . 6 , 062005 ( 2013 ) [ arxiv:1306.5394 [ astro-ph.he ] ] .\\ns.  r.  taylor and j.  r.  gair , phys .\\nd * 88 * , 084001 ( 2013 ) [ arxiv:1306.5395 [ gr - qc ] ] .\\nn.  seto and a.  taruya , phys .\\nlett .   * 99 * , 121101 ( 2007 ) doi:10.1103/physrevlett.99.121101 [ arxiv:0707.0535 [ astro - ph ] ] . n.  seto and a.  taruya , phys .  rev .\\nd * 77 * , 103001 ( 2008 ) [ arxiv:0801.4185 [ astro - ph ] ] . s.  j.  chamberlin and x.  siemens , phys .\\nd * 85 * , 082001 ( 2012 ) doi:10.1103/physrevd.85.082001 [ arxiv:1111.5661 [ astro-ph.he ] ] . j.  r.  gair , j.  d.  romano and s.  r.  taylor , phys .  rev .\\nd * 92 * , no .\\n10 , 102003 ( 2015 ) doi:10.1103/physrevd.92.102003 [ arxiv:1506.08668 [ gr - qc ] ] .\\nr.  jackiw and s.  y.  pi , phys .\\nd * 68 * , 104012 ( 2003 ) doi:10.1103/physrevd.68.104012 [ gr - qc/0308071 ] . m.  satoh , s.  kanno and j.  soda , phys .\\nd * 77 * , 023526 ( 2008 ) doi:10.1103/physrevd.77.023526 [ arxiv:0706.3585 [ astro - ph ] ] . c.  r.  contaldi , j.  magueijo and l.  smolin , phys .\\n* 101 * ( 2008 ) 141101 doi:10.1103/physrevlett.101.141101 [ arxiv:0806.3082 [ astro - ph ] ] .\\nt.  takahashi and j.  soda , phys .\\nlett .   * 102 * , 231301 ( 2009 ) doi:10.1103/physrevlett.102.231301 [ arxiv:0904.0554 [ hep - th ] ] .\\nj.  l.  cook and l.  sorbo , phys .\\nd * 85 * , 023534 ( 2012 ) [ phys .\\nd * 86 * , 069901 ( 2012 ) ] doi:10.1103/physrevd.86.069901 , 10.1103/physrevd.85.023534 [ arxiv:1109.0022 [ astro-ph.co ] ] .\\ni.  obata , t.  miura and j.  soda , phys .\\nd * 92 * , no .\\n6 , 063516 ( 2015 ) doi:10.1103/physrevd.92.063516 [ arxiv:1412.7620 [ hep - ph ] ] .\\na. p. lightman , w. h. press , r. h. price , and s. a. teukolski , problem book in relativity and gravitation , 2nd ed .\\n( princeton university press , 1979 ) .\\nm. maggiore , gravitational waves , vol . 1 : theory and experiments ( oxford university press , 2008 )\\n. g. b. rybicki , a. p. lightman , radiative processes in astrophysics ( wiley - interscience , 1979 ) .\\nl. d. landau and e. m. lifshitz , the classical theory ( pergamon press , 1975 ) . c. misner , k. thorne and j. wheeler , gravitation , ( freeman 1973 ) .\\nb.  allen and a.  c.  ottewill , phys .\\nd * 56 * , 545 ( 1997 ) doi:10.1103/physrevd.56.545 [ gr - qc/9607068 ] .\\nu.  seljak and m.  zaldarriaga , phys .\\nlett .   * 78 * , 2054 ( 1997 ) doi:10.1103/physrevlett.78.2054 [ astro - ph/9609169 ] .\\nj. n. goldberg et al .\\n, journal of mathematical physics * 8 * , 2155 , 1967 . m.  anholm , s.  ballmer , j.  d.  e.  creighton , l.  r.  price and x.  siemens , phys .\\nd * 79 * , 084030 ( 2009 ) doi:10.1103/physrevd.79.084030 [ arxiv:0809.0701 [ gr - qc ] ] . l.  g.  book and e.  e.  flanagan , phys .\\nd * 83 * , 024024 ( 2011 ) doi:10.1103/physrevd.83.024024 [ arxiv:1009.4192 [ astro-ph.co ] ] . f.  a.  jenet and j.  d.  romano , am .\\nj.  phys .\\n* 83 * , 635 ( 2015 ) doi:10.1119/1.4916358 [ arxiv:1412.1142 [ gr - qc ] ] .\\nr.  w.  hellings and g.  s.  downs , astrophys .\\nj.   * 265 * , l39 ( 1983 ) . doi:10.1086/183954\",\n          \"one of the main goals of the search for periodic isolated sources of gravitational waves ( g.w . ) is to perform all sky surveys , based on `` blind searches '' , where the source parameters are unknown . in this case\\nhierarchical procedures are applied , based on a sequence of increasing resolution steps . in this paper\\nwe study in details the problem of sensitivity loss due to discretization of parameters and to the needs to limit the computing cost , with hough procedures .\\nin particular , we propose and study the characteristics of a frequency hough procedure , designed mainly to reduce the discretization problem , and we compare it with the sky hough procedure , which is actually used in the virgo collaboration .\\n+ the paper is organized as follows : in sect .\\n2 we present the basic scheme of the rome hierarchical procedure , based on the main idea of coincidences among subsets of data ; in sect .\\n3 we discuss the limits due to digitization of the sky hough procedure ; in sects . 4 , 5 we present the new frequency hough procedure , discussing details its implementation and its basic characteristics ; in sect .\\n6 we present the study of amplitude losses due to digitization , and thus efficiencies , for both the procedures .\\nconclusions and comments are given in sect .\\nhierarchical procedures , based on hough transform algorithms , are applied by various groups in the g.w . community .\\nsee , for example , references @xcite .\\nthere are various ways of implementing the hierarchical procedure and the hough transform .\\nthe hough transform is a linear transform that is used to recognize the parameters of the analytical description of a curve from the position of some points on it .\\nit operates on an `` image '' of points , in our case the peakmap in the time - frequency plane . for each peak of this map\\nwe increase a set of bins of a multi - dimensional histogram ( in our case a two - dimensional histogram ) defined on the parameters space , called the hough map . in the old procedure ,\\nthe parameter space was the position of the source , i.e. the celestial sphere , and we fixed the spin down value for each hough map . in the new one ,\\nthe parameter space is the plane @xmath0 , and for each hough map , we fix the position of the source . the mapping ( i.e. which points of the hough map must be increased for a certain point in the peakmap ) can be done in different ways : we use always what we call the `` biunivocal mapping '' , i.e. a mapping in which every point in the hough map derive from a single point of the peakmap at a given time .\\nit is easy to demonstrate that in this case the mapping is also uniform , i.e. in the case of uniformly distributed random dots in the peakmap , the expected value of the hough map @xmath1 is a constant ( for all parameter value ) .\\nthis value , depending on the number n of the spectra of the peakmap and on the mapping , defines the `` noise '' of the map .\\nit is binomially distributed with parameters n and @xmath2 .\\nwe will refer here to the rome scheme , presently used in virgo data .\\n[ fig : schema ] shows the basic scheme of the rome hierarchical procedure .\\ndetails on the main aspects of the procedure are given in references @xcite .\\nafter data cleaning ( short time domain disturbances removal ) and `` short ffts data base '' ( sfdb ) creation , peakmaps are computed , using a very refined auto - regressive algorithm to equalize the spectral data by an appropriate follow - up of the noise .\\npeakmaps are frequency vs time maps , obtained from equalized spectra by selecting all the local maxima above a chosen threshold .\\nan accurate cleaning of peakmaps , by removing known noise lines and the more persistent lines , is needed and its implementation is critical for the next step analysis . on the cleaned peakmaps ,\\nmethods of peaks detection are applied .\\nthat is , transformation from the input plane to the hough plane , thresholding and first order candidates selection .\\ncandidate parameters are defined by source frequency , celestial coordinates , first spin - down parameter .\\nthe need for coincidences among candidates obtained in different subsets of data ( two in the scheme of fig .\\n[ fig : schema ] ) has been discussed in references @xcite .\\nthis method is very efficient to reduce the number of spurious candidates at a fixed threshold .\\nthus , for a given false alarm probability , we can lower the threshold -with respect to the choice of not doing coincidences- gaining in detection efficiency .\\nthe method has a better efficiency when the data sets have similar sensitivities .\\nafter the coincidence , the survived candidates are analyzed coherently with longer ffts on corrected data .\\nthen the spectral filtering is used to take into account the spread of the power in five bands , as explained in reference @xcite .\\nfinally , second order candidates are produced .\\nas stated before , the sky hough method shows amplitude losses , and thus loss of sensitivity , which are due to digitization of parameters .\\nthis effect shows up mainly for the complexity of the transform together with the need of reducing the computing cost :    * the method is based on a transform between the time - frequency peakmap and the celestial sphere .\\nit is not simple for the non linearity of the mapping ; * to reduce the computational effort , we need to use `` look - up tables '' which introduce further digitization errors ; * to reduce the computational effort , fast algorithms have been developed , which require the use of a rectangular grid to map the sky . compared to the `` optimal '' ( see later ) grid , the rectangular one has over - resolution in some regions of the sky .\\nthis leads also to a higher number of candidates .\\n* the use of the celestial map as the space to spot the candidates is very prone to artifacts , see @xcite : some regions are always `` privileged '' , that is they have a higher candidates number with respect to the expectation . the problem arises because each hough map is constructed over the whole sky .    hence , it seemed important the study of alternative procedures .\\ngiven the observation that most of the problems are related to the complexity of the transformation , we exploit the possibility of the use of a different but simpler transformation . a part the simplicity of the transformation we obviously need to study a procedure which is less , or equivalently , computationally expensive .\\ntherefore we studied a procedure which has a better , or equivalent , sensitivity , at the same computational cost of the sky hough .\\nthe transformation we propose transforms the * time - observed frequency * plane into the * source frequency - spin down * plane . let\\ns go into details . if @xmath3 is the frequency ( doppler corrected for a given sky direction ) , @xmath4 the source intrinsic frequency , @xmath5 the first spin - down parameter , @xmath6 the time at the detector and @xmath7 a reference time , we have that @xmath8 a straight line in the hough plane .\\nwe then get the following : @xmath9 each point in the input plane @xmath10 , that is a peak in the doppler shifted peakmap , is transformed into a straight line in the hough @xmath11 plane , with slope @xmath12 .\\nthe slope depends on the choice of the reference time .\\nif we choose @xmath7 equal to the beginning time of the data we analyze , then the slope is always negative and inversely proportional to the time gap .\\n+ this is the choice we have done here . in addition , considering the width @xmath13 of the frequency bins in the input plane we notice that each peak is transformed into a stripe among two parallel straight lines    @xmath14    it is a linear transformation .\\nnow the input plane is obtained from the original peakmap by correcting it for the doppler shift due to the earth revolution and rotation , for each point in the sky grid we need to analyze .\\nthus `` time '' is the time at the detector and `` frequency '' the observed frequency , after the doppler correction .\\nbut , as each sfdb is short enough to not be affected by a time - varying doppler shift , then the doppler effect removal from the original peakmap , obtained from the collection of all the sfdb data , reduces to a very simple `` shifting '' procedure of the peakmap bins . in the analysis scheme , this bins shift is part of the hough procedure . + in the following , we give details on the construction of the map .\\nthe frequency hough map is constructed using the `` direct differential method '' , as is done with the sky hough . with this method , instead of building directly the hough map , one builds a map that , if `` integrated '' ( i.e. summed over bins from left to right ) , gives the hough map .\\nthis is important to minimize the number of floating point operations .\\nas already explained , for each sky position , the input peakmap is got from the original one by shifting bins to correct for the doppler effect .\\nthe sky is sampled with a non uniform covering grid , which will be later discussed . here\\nwe explain in detail the technique , by giving the sequence of operations :    * for each point in the sky grid , for each coordinate in the input plane @xmath10 and for each spin - down value @xmath15 ,    the map is incremented by 1 in the point @xmath16 and decremented by 1 in the point @xmath17 .    hence ,\\nfor each sky position , a differential map is constructed .\\nthe sum of the bins along the frequency direction is then performed to construct the final integral map .\\nthis two dimensional histogram is the frequency hough map . in the algorithm implementation\\nwe plan to divide the input peakmap into 10 hz bands , thus constructing , for each position in the sky , a different hough map every 10 hz .\\n+ in case there is the need to exploit higher order one spin down parameters , one ( or more ) loop(s ) has ( have ) to be added to the sequence of operations , to scan the discrete set of values of the new parameter(s ) .\\nthis clearly influences the computing cost , but does not change the basics of the method .\\nlet s first discuss two peculiar aspects of this new method , which are the basis of its appeal .      from the given analysis scheme , it is easy to see that the frequency resolution for the estimation of the source frequency @xmath4 can be enhanced , with respect to the binning frequency @xmath13 , without relevantly affecting the computational effort .\\nin fact , the use of a resolution @xmath18 with @xmath19 , affects only the size of the hough map .\\nthis has a computational cost only when summing over the bins to construct the integral map from the differential one .\\nbut we notice that the total cost of the construction of the hough map is due to the construction of the differential map , dominated by the number of peaks in the peakmap and to the construction of the integral map , dominated by the number of bins .\\nthe former , in all practical cases , is the one which dominates .\\n+ the possibility to enhance the frequency resolution results to be , as will be shown in the next sections , a very important peculiarity of the new method .\\nit which enhances considerably the efficiency , by reducing the digitalization effect .\\nthe same in the sky hough procedure would have a relevant computational cost .\\nregarding the increasing of the spin down resolution , it would cost for both the procedures : the better the resolution in the spin down estimation the higher is the number of loops of the procedures .      here\\nwe describe how we construct the grid on the sky .\\nsuppose two sources , at the same frequency @xmath4 and same latitude @xmath20 .\\ntheir angular delay @xmath21 with respect to the detector rotation produces a time delay @xmath22 .\\nthe two sources will then have the same frequency variation at the detector , which is the classical equation due to the doppler effect , @xmath23 but with time delay @xmath24 .\\nthe observed frequency difference has thus a maximum value which is given by @xmath25 thus the angular resolution is , in radians : @xmath26 where @xmath27 is the number of points in the doppler band for a signal of max frequency @xmath4 : @xmath28 and @xmath29 .\\n+ we now repeat the same reasoning , supposing the two sources , at the same frequency @xmath4 and same longitude @xmath30 .\\nthe two sources will have the same frequency variation at the detector , now given by @xmath31 , but with an angular delay @xmath32 .\\nthe observed frequency difference has a maximum value which is : @xmath33 we obtain for the angular resolution , in radians : @xmath34 using eqs .\\n[ gammalong ] and [ gammalat ] we get : @xmath35 @xmath36 using these equations we construct the grid on the sky , which we call the `` optimal '' grid .\\nthe points of the grid are not uniformly distributed . with a simulation\\n, we have estimated the the number of points in the grid @xmath37 , which is , in the high frequency limit : @xmath38 @xmath39 is an extra resolution factor , which can be greater than 1 , to enhance the efficiency , but even less than 1 , to save computing cost , obviously worsening the efficiency .\\nfig.[fig : gridsim1 ] shows the optimal sky grid , for @xmath40 ( which corresponds to a source frequency @xmath41 hz ) .\\nas already said , the grid used in the sky hough method , is not optimal , but rectangular , to use fastest computing algorithms .\\nthe number of points in this rectangular grid is : @xmath42 which is , asymptotically , a factor @xmath43 higher then the number of points of the optimal grid . in fact\\nthis grid has to be over resolved to maintain the same sensitivity of the corresponding optimal grid .\\nfurther , we note that this over resolution produces a higher number of candidates from certain sky positions .    ,\\nx - axis : ecliptical longitude , degrees , from 0 to 400 ; y - axis : ecliptical latitude , degrees , from -100 to 100 ; the number of points in the map is @xmath37=2902.,width=453 ]          the sensitivity of the sky hough procedure is affected by artifacts , i.e. an excess of candidates in some places of the sky map , which are due to local spectral disturbances . the effect ca nt be eliminated because each map is constructed over the whole sky , and hence the threshold for candidate selection has to be the same for the whole sky . using the frequency hough procedure\\nthis effect disappears because each map is constructed for only one position in the sky .\\nso , because of the adaptivity of the threshold , if a sky region gives an excess of candidates , the threshold is raised and then there is a loss in sensitivity only for that sky region .\\nwe are now ready to enter into details by studying the efficiency of both the methods , by the use of simulations .\\nfigure [ fig : gridsim2 ] is an example of how a frequency hough map looks like , having injected into white noise three signals , at different frequencies and spin - down .      to study the efficiency of the methods , as a function of the frequency over resolution factor\\n, we have simulated a signal in the absence of noise .\\nthe reason for this is that we were interested in studying only the losses due to the discretization errors .\\nthe parameters chosen for the simulation are similar to actual situations ( detector parameters , source expected parameters ) .\\nthe parameters of the simulation are shown in table [ tab : par ] .\\n[ fig : freqloss ] shows the amplitude loss versus the frequency over resolution factor @xmath45 .\\nthe loss was calculated as the average value of all the peaks found in the 500 spectra ( it is important to remember that our procedure considers peaks only the maxima above threshold ) .\\nthe result is clear : using @xmath46 the amplitude loss is 3.6 @xmath47 ( the efficiency @xmath48 ) , while with @xmath49 , which is the only practically possible choice of the sky hough , the amplitude loss is 11.6 @xmath47 ( the efficiency @xmath50 ) . from the figure ,\\nwe notice that there is no further gain of increasing the over resolution factor over 10 .\\nthus , we fixed to 10 the over resolution factor for the frequency hough .\\nin next simulations , results with @xmath46 are thus for the frequency hough , results with @xmath49 are for the sky hough .\\nonce we have fixed the frequency over resolution factor we wanted to quantify how the increasing of the spin down resolution from the nominal one would affect the sensitivity .\\nthe results are in fig .\\n[ fig : freqloss1 ] , which shows the loss in amplitude vs the spin down over resolution factor , for both the cases @xmath49 , sky hough , and @xmath46,frequency hough .\\nit can be noticed that , in the case of the frequency hough , even for the worst analyzed situation , which corresponds to the nominal spin down step @xmath51 the loss is quite small .\\nis is 3.6 @xmath47 ( the efficiency @xmath48 ) .\\nthe situation is worst for the sky hough , where the loss in amplitude at the nominal spin down step is 11.6 @xmath47 ( the efficiency @xmath50 ) .\\nthe improvement obtained by a better spin down resolution is not so important , as can be seen from the figure .\\nit seems reasonable , given the observation that increasing the spin down resolution has a computational cost for both the methods , to use the nominal @xmath52 resolution ( x - axis equal to 1 in the figure ) .      to study the loss due to the sky grid resolution\\n, we have simulated 50 signals , randomly distributed over the sky .\\nwe have then looked for results using the optimal grid , again registering the average value of all the detected peaks . in what follows ,\\nwe suppose to use the optimal grid for both the procedures , sky and frequency hough .\\nfig.[fig : loss_spinres ] shows the amplitude losses , as a function of the over resolution sky map factor @xmath39 , in the two cases of @xmath46 ( left ) , frequency hough , and @xmath49 ( right ) , sky hough .\\nthe amplitude loss , for @xmath44 , is @xmath53 for the frequency hough , and @xmath54 , for the sky hough .\\nagain , a better efficiency for the new procedure .\\nwe notice that the use of an over resolution for the sky map , would have an impact on the computing cost , with both the procedures .    .\\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\\\"fig:\\\",width=302 ] .\\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\\\"fig:\\\",width=302 ]        + we see that the ratio of the amplitude efficiencies is @xmath57 which in power is 1.317 . from this\\n, we can compute the gain in computing cost for the same sensitivity .\\nlet us firstly recall that the @xmath58 sensitivity in the hierarchical search is proportional to @xmath59 , and the computing cost to @xmath60 .\\nthus , the `` equivalent fft '' length factor is @xmath61=1.734 and the gain in computing cost is @xmath62=5.2 ( that is , the ratio of computing costs needed to have the same @xmath58 sensitivity ) .      * the * adaptivity * , that is the weight of peaks to consider the noise level and the gain due to the antenna pattern toward a direction , is , with this approach , immediate and very simple , as each hough map is done for a single sky position .\\nit has been shown , with the sky hough , that the adaptivity of the procedure is a very important task for the analysis ; * this new procedure is appropriate also for all those situations in which the * source position * is known and we should estimate only source frequency and spin down ; * with a proper choice of parameters , it is also possible to detect and hence remove * spurious signals * , with a constant or linearly varying frequency .    on the latter point , we are now working to study the efficiency of this method in terms of rejection of spurious lines in the peakmap . we know that this is a very critical task for the analysis , since the presence of spurious lines highly affects the sensitivity of the search .\\nwe expect this new method to be much more insensitive to the presence of spurious lines , since in the chosen hough plane spurious lines and g.w .\\nsignals should have a very different and well separable behavior .\\nb. krisnan , a. sintes , m. a. papa , b .\\nf. schutz , s. frasca , c. palomba , _\\nphys.rev.d70:082001_ , 2004 .\\n`` the hough transform search for continuous gravitational waves '' a. sintes , b. krisnan , _\\nphys.conf.ser.32:206-211_ , 2006 .\\n`` improved hough search for gravitational wave pulsars ''\\np. astone , s. frasca , c. palomba,_cqg 22:s1197-s1210_,2005 `` the short fft database and the peakmap for the hierarchical search of periodic sources '' s. frasca , p. astone , c. palomba,_cqg 22:s1013-s1019 _ , 2005 `` evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources '' c. palomba , p. astone , s. frasca , _\\ncqg 22:s1255-s1264_,2005 `` adaptive hough transform for the search of periodic sources '' f. acernese et al ( virgo coll . ) _ cqg 24:s491-s499 _ , 2007 `` coincidence analysis between periodic source candidates in c6 and c7 virgo data '' f. acernese et al ( virgo coll . ) _ proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin , 2006 ) edited by h. kleinert , r.t .\\njantzen and r. ruffini , world scientific , singapore _ , 2008 `` first coincidence search among periodic gravitational wave source candidates using virgo data '' p. astone , s. frasca , c. palomba_proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin 2006 ) edited by h. kleinert , r.t . jantzen and r. ruffini , world scientific , singapore _ , 2008 `` incoherent strategies for the network detection of periodic gravitational waves '' c. palomba , s. frasca , _\\ncqg 21:s1645-s1654 _ , 2004 `` spectral filtering for hierarchical search of periodic sources ''\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" kingman s coalescent is a random tree that arises from classical population genetic models such as the moran model . \\n the individuals alive in these models correspond to the leaves in the tree and the following two laws of large numbers concerning the structure of the tree - top are well - known : ( i ) the ( shortest ) distance , denoted by @xmath0 , from the tree - top to the level when there are @xmath1 lines in the tree satisfies @xmath2 almost surely ; ( ii ) at time @xmath0 , the population is naturally partitioned in exactly @xmath1 families where individuals belong to the same family if they have a common ancestor at time @xmath0 in the past . if @xmath3 denotes the size of the @xmath4th family , then @xmath5 almost surely . for both laws of large numbers \\n we prove corresponding large deviations results . for ( i ) , the rate of the large deviations is @xmath1 and we can give the rate function explicitly . for ( ii ) , the rate is @xmath1 for downwards deviations and @xmath6 for upwards deviations . for both cases \\n we give the exact rate function .    \\n =     =    =     = \",\n          \" we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries , cosmic strings , and inflation in the early universe with pulsar timing arrays . \\n we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background . \\n we find that the circular polarization can not be detected for an isotropic background . however , there is a chance to observe the circular polarization for an anisotropic gravitational wave background . \\n we also show how to separate polarized gravitational waves from unpolarized gravitational waves . \",\n          \" in the hierarchical search for periodic sources of gravitational waves , the candidate selection , in the incoherent step , can be performed with hough transform procedures . in this paper \\n we analyze the problem of sensitivity loss due to discretization of the parameters space vs computing cost , comparing the properties of the sky hough procedure with those of a new frequency hough , which is based on a transformation from the _ time - observed frequency _ plane to the _ source frequency - spin down _ plane . \\n results on simulated peakmaps suggest various advantages in favor of the use of the frequency hough . the ones which show up to really make the difference are 1 ) the possibility to enhance the frequency resolution without relevantly affecting the computing cost . \\n this reduces the digitization effects ; 2 ) the excess of candidates due to local disturbances in some places of the sky map . \\n they do not affect the new analysis because each map is constructed for only one position in the sky . \\n + pacs . \\n numbers : 04.80nn,07.05kf,97.60jd \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"62dOP5-aQeWL"},"source":["# **Pre-processing**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sahMZyRFauZ2"},"outputs":[],"source":["def remove_special_characters(text):\n","  # remove non-alphanumeric characters and digits\n","  text = re.sub(r'[^a-zA-Z\\s]', ' ', str(text))\n","  return text\n"]},{"cell_type":"code","source":["def truncate(tokenized_words):\n","  max_length = 512\n","  if len(tokenized_words) > max_length:\n","    print(f\"{len(tokenized_words)} > {max_length} Truncating...\")\n","    text = tokenized_words[:max_length]\n","  return text"],"metadata":{"id":"DYMBuT-kkYji"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZzzL-xcSPwh"},"outputs":[],"source":["def preprocess(text):\n","  text = [word for word in text if word.lower() not in Stopwords] # remove stopwords\n","  text = [word for word in text if len(word) > 1] # remove one letter words\n","  text = [word.lower() for word in text] # convert to lowercase\n","  text = [wordlemmatizer.lemmatize(word) for word in text] # lemmatize\n","  return text"]},{"cell_type":"markdown","metadata":{"id":"spi05CIJQ66_"},"source":["# **POS Tagging**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qxdDQv-dPLdy"},"outputs":[],"source":["# POS-Tagging verbs and nouns.\n","def pos_tagging(text):\n","    pos_tag = nltk.pos_tag(text.split())\n","    pos_tagged_noun_verb = []\n","    for word,tag in pos_tag:\n","        if tag == \"NN\" or tag == \"NNP\" or tag == \"NNS\" or tag == \"VB\" or tag == \"VBD\" or tag == \"VBG\" or tag == \"VBN\" or tag == \"VBP\" or tag == \"VBZ\":\n","             pos_tagged_noun_verb.append(word)\n","    return pos_tagged_noun_verb"]},{"cell_type":"markdown","metadata":{"id":"JV9QD5mOYbK8"},"source":["# **Count word frequency**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1deQ0F5tPJgq"},"outputs":[],"source":["# Counts word frequency in a document\n","def freq(words):\n","    words = [word.lower() for word in words]\n","    dict_freq = {}\n","    words_unique = []\n","    for word in words:\n","       if word not in words_unique:\n","           words_unique.append(word)\n","    for word in words_unique:\n","       dict_freq[word] = words.count(word)\n","    return dict_freq"]},{"cell_type":"markdown","metadata":{"id":"lQiD0LqpTL-b"},"source":["# **TF-IDF**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zs8w-szPPuk"},"outputs":[],"source":["# TF(w) = (Number of times term w appears in a document) / (Total number of terms in the document)\n","def tf_score(word,sentence):\n","    freq_sum = 0\n","    word_frequency_in_sentence = 0\n","    len_sentence = len(sentence)\n","    for word_in_sentence in sentence.split():\n","        if word == word_in_sentence:\n","            word_frequency_in_sentence = word_frequency_in_sentence + 1\n","    tf =  word_frequency_in_sentence/ len_sentence\n","    return tf\n","\n","# IDF(w) = log_e(Total number of documents / Number of documents with term w in it)\n","def idf_score(no_of_sentences,word,sentences):\n","    no_of_sentence_containing_word = 0\n","    for sentence in sentences:\n","        sentence = remove_special_characters(str(sentence))\n","        sentence = sentence.split()\n","        sentence = preprocess(sentence)\n","        if word in sentence:\n","            no_of_sentence_containing_word = no_of_sentence_containing_word + 1\n","    idf = math.log10(no_of_sentences/no_of_sentence_containing_word)\n","    return idf\n","# TFIDF = TF * IDF\n","def tf_idf_score(tf,idf):\n","    return tf*idf\n","\n","# This method calls the TF_score, IDF_score, and returns the value of the TF_IDF_score.\n","def word_tfidf(dict_freq,word,sentences,sentence):\n","    word_tfidf = []\n","    tf = tf_score(word,sentence)\n","    idf = idf_score(len(sentences),word,sentences)\n","    tf_idf = tf_idf_score(tf,idf)\n","    return tf_idf"]},{"cell_type":"markdown","metadata":{"id":"6FmKj1WpZBWj"},"source":["# **Calculate sentence score**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20E2DocaNO63"},"outputs":[],"source":["# The score for each sentence decides its importance\n","# The score is calculated by passing a POS-Tagged sentence for verbs and nouns to the TF-IDF algorithm.\n","def sentence_importance(sentence,dict_freq,sentences):\n","     sentence_score = 0\n","     sentence = remove_special_characters(sentence)\n","     no_of_sentences = len(sentences)\n","     pos_tagged_sentence = []\n","     pos_tagged_sentence = pos_tagging(sentence)\n","     pos_tagged_sentence = preprocess(pos_tagged_sentence)\n","     for word in pos_tagged_sentence:\n","                sentence_score = sentence_score + word_tfidf(dict_freq,word,sentences,sentence)\n","     return sentence_score"]},{"cell_type":"markdown","metadata":{"id":"khWdO2SX4kbF"},"source":["# **Generate summary**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NwWBBjWCTfYl"},"outputs":[],"source":["def generate_summary(word_freq,tokenized_sentence):# Sorts the dictionary of sentences in a descending order with respect to the sentence score (importance).\n","    c = 1\n","    sentence_with_importance = {}\n","    for sent in tokenized_sentence:\n","      sentenceimp = sentence_importance(sent,word_freq,tokenized_sentence)\n","      sentence_with_importance[c] = sentenceimp\n","      c = c+1\n","    sentence_with_importance = sorted(sentence_with_importance.items(), key=operator.itemgetter(1),reverse=True)\n","\n","    # Limit the generated summary to be in the range of 150 words.\n","    max_word_length = 150\n","    summary = []\n","    word_count = 0\n","\n","    for word_prob in sentence_with_importance:\n","      sentence_index = word_prob[0]\n","      sentence = tokenized_sentence[sentence_index - 1]\n","      words = sentence.split()\n","\n","      if word_count + len(words) <= max_word_length:\n","          summary.append(sentence)\n","          word_count += len(words)\n","      else:\n","          break\n","\n","    # Print the summary.\n","\n","    summary = \" \".join(summary)\n","    print(\"\\n\")\n","    print(\"Summary:\")\n","    print(summary)\n","\n","    return summary\n","#print(len(summary.split()))\n","#outF = open('summary.txt',\"w\")\n","#outF.write(summary)"]},{"cell_type":"markdown","source":["# **Model Evaluation**"],"metadata":{"id":"-D6NdNEFkcow"}},{"cell_type":"code","source":["def get_rouge_scores3(actual_summary, predicted_summary):\n","    rouge = Rouge()\n","    scores = rouge.get_scores(predicted_summary, actual_summary)[0]  # Access the first item in the list of scores\n","    rouge_1_f = scores['rouge-1']['f']\n","    rouge_2_f = scores['rouge-2']['f']\n","    rouge_L_f = scores['rouge-l']['f']\n","\n","    # Calculate precision, recall, and F1 scores\n","    precision = (scores['rouge-1']['p'] + scores['rouge-2']['p'] + scores['rouge-l']['p']) / 3\n","    recall = (scores['rouge-1']['r'] + scores['rouge-2']['r'] + scores['rouge-l']['r']) / 3\n","    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0  # Avoid division by zero\n","    return [rouge_1_f, rouge_2_f, rouge_L_f, precision, recall, f1]\n"],"metadata":{"id":"RgtzMeaM_pTi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lists to calculate peroformance scores\n","rouge1_scores = []\n","rouge2_scores = []\n","rougeL_scores = []\n","precision_scores = []\n","recall_scores = []\n","f1_scores = []\n","pred_summary_list = []\n","\n","# Extract the 'Article' and 'Abstract' from the DataFrame\n","for index, row in test_df.iterrows():\n","   article = row[\"article\"]\n","   actual_abstract = row[\"abstract\"]\n","   print(f\"Article {index+1}:\")\n","\n","   # Pre-processing and summary generation\n","   tokenized_sentence = sent_tokenize(article)\n","   article_text = remove_special_characters(article)\n","   tokenized_words = word_tokenize(article)\n","   tokenized_words = truncate(tokenized_words)\n","   tokenized_words = preprocess(tokenized_words)\n","   word_freq = freq(tokenized_words)\n","   abstract = generate_summary(word_freq,tokenized_sentence)\n","\n","   # Calculate ROUGE scores\n","   rouge_scores = get_rouge_scores3(actual_abstract, abstract)\n","   metrics = [\"ROUGE-1 F1\", \"ROUGE-2 F1\", \"ROUGE-L F1\", \"Precision\", \"Recall\", \"F1 Score\"]\n","   print(\"\\n\")\n","   print(\"ROUGE Scores:\")\n","   for i in range(len(metrics)):\n","      print(metrics[i] + \":\", rouge_scores[i])\n","   print(\"=\"*40)\n","   print(\"\\n\")\n","\n","   # Append scores to lists\n","   rouge1_scores.append(rouge_scores[0])\n","   rouge2_scores.append(rouge_scores[1])\n","   rougeL_scores.append(rouge_scores[2])\n","   precision_scores.append(rouge_scores[3])\n","   recall_scores.append(rouge_scores[4])\n","   f1_scores.append(rouge_scores[5])\n","   pred_summary_list.append(abstract)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inkhq4uFCewu","outputId":"6e7b6037-252e-4727-b81c-bd662b32e0de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Article 1:\n","6230 > 512 Truncating...\n","\n","\n","Summary:\n","let the set of values of the independent variable of the autocorrelation function be called @xmath26 and it can be divided into the sums of disjoint sets : @xmath27 where + @xmath28 + @xmath29 @xmath30 @xmath31 + @xmath32 + @xmath33 @xmath34 @xmath35 @xmath36 @xmath37 @xmath38\n","@xmath39 @xmath40    well , the set @xmath41 contains all integer values of @xmath23 from the interval of @xmath42 for which the autocorrelation function and the cosinus function with the period @xmath43 $ ] are positive . first of them was discovered by @xcite in the occurence rate of gamma - ray flares detected by the gamma - ray spectrometer aboard the _ solar maximum mission ( smm ) . @xcite concluded that the region of larger wavelet power shifts from 475-day ( 1.3-year ) period to 620-day ( 1.7-year ) period and then back to 475-day ( 1.3-year ) .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.22459892548257038\n","ROUGE-2 F1: 0.062068960563852964\n","ROUGE-L F1: 0.18181817681946882\n","Precision: 0.15623409669211197\n","Recall: 0.15654908394859174\n","F1 Score: 0.15639143171692002\n","========================================\n","\n","\n","Article 2:\n","9077 > 512 Truncating...\n","\n","\n","Summary:\n","the following form for @xmath152 was derived in @xcite , and our expressions are identical to their expressions : @xmath271\\ , \\end{aligned}\\ ] ] for , @xmath154 , we calculated as @xmath272\\ , \\\\ \\gamma^{i}_{11}&=&\\frac{\\sqrt{6\\pi}}{12}\\sin\\xi\\left[1 + 3(1-\\cos\\xi)\\left\\{1+\\frac{4}{1+\\cos\\xi}\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right\\}\\right]\\ , \\\\ \\gamma^{i}_{1 - 1}&=&-\\gamma^{i}_{11}\\ , \\end{aligned}\\ ] ] for @xmath157 , we obtain @xmath273\\ , \\\\ \\gamma^{i}_{21}&=&-\\frac{\\sqrt{30\\pi}}{60}\\sin\\xi\\left[21 - 15\\cos\\xi-5\\cos^2\\xi+60\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{2 - 1}&=&-\\gamma^{i}_{2 - 1}\\ , \\\\ \\gamma^{i}_{22}&=&\\frac{\\sqrt{30\\pi}}{24}(1-\\cos\\xi)\\left[9 - 4\\cos\\xi-\\cos^2\\xi+24\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{2 - 2}&=&\\gamma^{i}_{22}\\ ,\n","\\end{aligned}\\ ] ] for @xmath159 , it is straightforward to reach the following @xmath274\\ , \\\\ \\gamma^{i}_{31}&=&\\frac{\\sqrt{21\\pi}}{48}\\sin\\xi(1-\\cos\\xi)\\left[34 + 15\\cos\\xi+5\\cos^2\\xi+\\frac{96}{1+\\cos\\xi}\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 1}&=&-\\gamma^{i}_{31}\\ , \\\\ \\gamma^{i}_{32}&=&-\\frac{\\sqrt{210\\pi}}{48}(1-\\cos\\xi)\\left[17 - 9\\cos\\xi-3\\cos^2\\xi-\\cos^3\\xi+48\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 2}&=&\\gamma^{i}_{32}\\ , \\\\ \\gamma^{i}_{33}&=&\\frac{\\sqrt{35\\pi}}{48}\\frac{(1-\\cos\\xi)^2}{\\sin\\xi}\\left[34 - 17\\cos\\xi-4\\cos^2\\xi-\\cos^3\\xi+96\\left(\\frac{1-\\cos\\xi}{1+\\cos\\xi}\\right)\\log\\left(\\sin\\frac{\\xi}{2}\\right)\\right]\\ , \\\\ \\gamma^{i}_{3 - 3}&=&-\\gamma^{i}_{33}\\ .\\end{aligned}\\ ] ] these are plotted in fig .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.14285713785714302\n","ROUGE-2 F1: 0.011111106141360247\n","ROUGE-L F1: 0.12698412198412717\n","Precision: 0.09338351606392843\n","Recall: 0.09396315420411805\n","F1 Score: 0.0936724384530919\n","========================================\n","\n","\n","Article 3:\n","2726 > 512 Truncating...\n","\n","\n","Summary:\n","the @xmath0 decay half - life is related to the decay width @xmath20 by @xcite @xmath21 the decay width @xmath20 is calculated as  @xcite @xmath22 where @xmath23 is the assaults frequency of @xmath0 particle on the barrier , @xmath24 the spectroscopic or preformation factor and @xmath25 the penetrability with @xmath1 the @xmath0 decay q - value . the paper is organized as follows . in sec .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.28571428078925454\n","ROUGE-2 F1: 0.0588235245198966\n","ROUGE-L F1: 0.22448979099333624\n","Precision: 0.21678695535952955\n","Recall: 0.1686091686091686\n","F1 Score: 0.18968674584517614\n","========================================\n","\n","\n","Article 4:\n","4104 > 512 Truncating...\n","\n","\n","Summary:\n","\\end{aligned}\\ ] ] the second derivative of the fermion action is @xmath104 \\xi + } \\nonumber \\\\ & & { 2 \\operatorname{re } \\chi^\\dagger \\frac{\\partial d}{\\partial q_\\mu(n ) } ( d^\\dagger d)^{-1 } \\frac{\\partial d^\\dagger}{\\partial q_\\nu(m ) } \\chi \\ , , } \\nonumber \\\\ & & { = 2 \\operatorname{re } \\left [ z_{1,m,\\nu}^\\dagger \\frac{\\partial d}{\\partial q_{\\mu}(n ) } \\xi +   \\chi^\\dagger\n","\\frac{\\partial d}{\\partial q_{\\mu}(n ) } d^{-1 } w_{2,m,\\nu } -   \\chi^\\dagger   \\frac{\\partial^2 d}{\\partial q_{\\nu}(m ) \\partial q_{\\mu}(n ) } \\xi +   \\chi^\\dagger\n","\\frac{\\partial d}{\\partial q_{\\mu}(n ) } d^{-1 } z_{1,m,\\nu}\\right ] } \\nonumber \\\\ & & { = 2 \\textrm{re } \\left [ z_{1,m,\\nu}^\\dagger w_{2,n,\\mu } +   w_{1,n,\\mu}^\\dagger z_{2,m,\\nu } -   \\chi^\\dagger   \\frac{\\partial^2 d}{\\partial q_{\\nu}(m ) \\partial q_{\\mu}(n ) } \\xi \\right ] } \\end{aligned}\\ ] ] in terms of the vectors @xmath105 and @xmath92 defined in .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.14035087219452158\n","ROUGE-2 F1: 0.01219511696311923\n","ROUGE-L F1: 0.10526315289627601\n","Precision: 0.08720930232558138\n","Recall: 0.0847332743884468\n","F1 Score: 0.08595346056106433\n","========================================\n","\n","\n","Article 5:\n","5023 > 512 Truncating...\n","\n","\n","Summary:\n","( [ 4prop_relation ] ) over a common denominator and then equating to zero the coefficients in front of different products of @xmath48 , @xmath84 yields system of equations : @xmath85 solving this system for @xmath45 , @xmath46 , @xmath70,@xmath86 , @xmath87 , @xmath88 we have @xmath89 where @xmath90 is a solution of the equation @xmath91 with @xmath92    eqs . in sec . in sec . in sec . ( [ 3prop_relation ] ) over a common denominator and then equating to zero the coefficients in front of various products of @xmath65 , @xmath66 , @xmath67 , @xmath68 yields the following system of equations : @xmath69 solving these equations for @xmath45 , @xmath46 , @xmath70 , @xmath71 , @xmath72 we have @xmath73 where @xmath74 is solution of the equation @xmath75 here @xmath76    let us now turn to the derivation of algebraic relation for the product of four propagators .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.17721518487662247\n","ROUGE-2 F1: 0.017391299351230165\n","ROUGE-L F1: 0.11392404563611623\n","Precision: 0.10551948051948051\n","Recall: 0.10029992327544117\n","F1 Score: 0.10284351820116816\n","========================================\n","\n","\n","Article 6:\n","4226 > 512 Truncating...\n","\n","\n","Summary:\n","fig. fig. community . `` improved hough search for gravitational wave pulsars ''\n","p. astone , s. frasca , c. palomba,_cqg 22:s1197-s1210_,2005 `` the short fft database and the peakmap for the hierarchical search of periodic sources '' s. frasca , p. astone , c. palomba,_cqg 22:s1013-s1019 _ , 2005 `` evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources '' c. palomba , p. astone , s. frasca , _\n","cqg 22:s1255-s1264_,2005 `` adaptive hough transform for the search of periodic sources '' f. acernese et al ( virgo coll . ) let\n","s go into details .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.18072288721948043\n","ROUGE-2 F1: 0.05761316436518857\n","ROUGE-L F1: 0.1686746944483961\n","Precision: 0.21230446702144815\n","Recall: 0.09968713685527845\n","F1 Score: 0.1356704744356924\n","========================================\n","\n","\n","Article 7:\n","3392 > 512 Truncating...\n","\n","\n","Summary:\n","it is typical to subdivide cc  sne into at least five major categories ( see @xcite for a thorough review ) : ii - plateau ( ii - p ; hydrogen in spectrum and plateau in optical light curve ) , ii - linear ( ii - l ; hydrogen in spectrum , no plateau in optical light curve ) , iin ( hydrogen in spectrum and spectral and photometric evidence for interaction between sn ejecta and a dense circumstellar medium [ csm ] ) , iib ( hydrogen in spectrum initially , but transforms into a hydrogen - deficient spectrum at later times ) , and ib / c ( no evidence for hydrogen in spectrum at any time ) , where the ordering is a roughly increasing one in terms of inferred degree of envelope stripping prior to explosion ( i.e.\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.24999999548156962\n","ROUGE-2 F1: 0.0641399371958966\n","ROUGE-L F1: 0.1896551678953628\n","Precision: 0.24383903133903137\n","Recall: 0.12806629405371836\n","F1 Score: 0.16793285256811233\n","========================================\n","\n","\n","Article 8:\n","5305 > 512 Truncating...\n","\n","\n","Summary:\n","fiz . rev . rev . lett . lett . lett . lett . lett . 30 - dec . one finds  @xcite : @xmath43 & = & \\vert \\vec s_\\perp\\vert   \\sum_{ab } x_a\\,\\frac{-1}{m_p}\\,gt_{f\\,a}(x_a)\\,x_bf_b(x_b ) \\,h_{ab\\to cd}^{\\rm sivers}(\\hat{s},\\hat{t},\\hat{u})\\ , \\end{aligned}\\ ] ] where @xmath44 is the proton mass , @xmath45 is the strong coupling constant and the @xmath46 are the qiu - sterman matrix elements or quark - gluon correlation functions @xcite , defined as @xmath47 with the quark fields @xmath48 ( for flavor @xmath49 ) and the gluon field strength tensor @xmath50 . gsi - pax collab\n",", p.  lenisa and f.  rathmann ( spokespersons ) _ et al . f.  videbaek [ brahms collaboration ] , aip conf . thesis , columbia u. , arxiv : hep - ex/0601009 . c. aidala\n","_ et al .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.09333332846133359\n","ROUGE-2 F1: 0.0\n","ROUGE-L F1: 0.06666666179466703\n","Precision: 0.04597701149425287\n","Recall: 0.06349206349206349\n","F1 Score: 0.05333333333333333\n","========================================\n","\n","\n","Article 9:\n","4981 > 512 Truncating...\n","\n","\n","Summary:\n","properties of @xmath205 : * applying the grtner - ellis theorem reveals that the sequence of distributions of @xmath206 satisfies a large deviation principle with good rate function @xmath207= \\sup_{t \\leq      1 } \\left [ \\frac t2 x + \\int_1^\\infty      \\log\\left(1-\\frac{t}{y^2}\\right ) \\,\\emph dy \\right].\\end{aligned}\\ ] ] in order to compute that supremum , we write for @xmath208 @xmath209 & = x -    2\\int_1^\\infty \\frac{1}{y^2 - t}dy \\\\ & = x +    \\frac{1}{\\sqrt{t}}\\int_1^\\infty \\frac{1}{y+\\sqrt{t } } -    \\frac{1}{y-\\sqrt{t } } dy \\\\ & = x - \\frac{1}{\\sqrt{t } } \\log    \\frac{1+\\sqrt{t}}{1-\\sqrt{t}}\\end{aligned}\\ ] ] while for @xmath210 @xmath209 & = x -    2\\int_1^\\infty \\frac{1}{y^2 + |t|}dy \\\\ & = x -    \\frac{2}{\\sqrt{|t|}}\\arctan\\sqrt{|t|}.\\end{aligned}\\ ] ] it is easy to see that the second derivative is negative throughout , such that the supremum is attained at @xmath211 given by the solution of @xmath212 for @xmath57 as in  .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.23157894238836577\n","ROUGE-2 F1: 0.007042248630483461\n","ROUGE-L F1: 0.1999999950199447\n","Precision: 0.15631287337109603\n","Recall: 0.13735852112818644\n","F1 Score: 0.14622401447141076\n","========================================\n","\n","\n","Article 10:\n","9419 > 512 Truncating...\n","\n","\n","Summary:\n","introducing the effect of diffraction in a slab waveguide geometry\n",", we obtain @xmath73 { \\displaystyle   \\qquad\\qquad\\qquad\\qquad      + \\chi_{2}a_{2 } a_{1}^{\\ast}e^{-i\\delta k_{2}z } = 0 ,     } \\\\*[9pt ] { \\displaystyle       4\n","i k_{1 } \\frac{\\partial a_{2}}{\\partial z }       + \\frac{\\partial^{2 } a_{2}}{\\partial x^{2 } }       + \\chi_{4 } a_{3 } a_{1}^{\\ast } e^{-i\\delta k_{3}z }     } \\\\*[9pt ] { \\displaystyle   \\qquad\\qquad\\qquad\\qquad      + \\chi_{5 } a_{1}^{2 } e^{i\\delta k_{2}z }       = 0 ,     } \\\\*[9pt ] { \\displaystyle       6 i k_{1}\\frac{\\partial a_{3}}{\\partial z }       + \\frac{\\partial^{2 } a_{3}}{\\partial x^{2 } }       + \\chi_{3}a_{2}a_{1}e^{i\\delta k_{3}z }       = 0 ,     } \\end{array}\\ ] ] where @xmath74 , @xmath75 , and @xmath76 , and the nonlinear coupling coefficients @xmath77 are proportional to the elements of the second - order susceptibility tensor which we assume to satisfy the following relations ( no dispersion ) , @xmath78 , @xmath79 , and @xmath80 .\n","\n","\n","ROUGE Scores:\n","ROUGE-1 F1: 0.1666666618055557\n","ROUGE-2 F1: 0.02116401637692222\n","ROUGE-L F1: 0.13636363150252542\n","Precision: 0.09242803979646085\n","Recall: 0.1301010101010101\n","F1 Score: 0.10807560940664926\n","========================================\n","\n","\n"]}]},{"cell_type":"code","source":["# Add predicted summaries to test_data DataFrame\n","test_df[\"pred_summary\"] = pred_summary_list\n","\n","# Add scores to test_data DataFrame\n","scores = [rouge1_scores, rouge2_scores, rougeL_scores, precision_scores, recall_scores, f1_scores]\n","for i in range(len(metrics)):\n","  test_df[metrics[i]] = scores[i]\n","\n","test_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"EHOGKjGWCTrY","outputId":"7e52c956-da4d-4b84-fb4b-74cc6e360cfe"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             article  \\\n","0  for about 20 years the problem of properties o...   \n","1  it is believed that the direct detection of gr...   \n","2  as a common quantum phenomenon , the tunneling...   \n","3  for the hybrid monte carlo algorithm ( hmc)@xc...   \n","4  recently it was discovered that feynman integr...   \n","5  one of the main goals of the search for period...   \n","6  this review focuses specifically on what we ha...   \n","7  single - transverse spin asymmetries ( ssas ) ...   \n","8  kingman s coalescent is a random tree introduc...   \n","9  rapid progress in the design and manufacture o...   \n","\n","                                            abstract  \\\n","0   the short - term periodicities of the daily s...   \n","1   we study the detectability of circular polari...   \n","2   starting from the wkb approximation , a new b...   \n","3   we study a novel class of numerical integrato...   \n","4   new methods for obtaining functional equation...   \n","5   in the hierarchical search for periodic sourc...   \n","6   i summarize what we have learned about the na...   \n","7   we present a phenomenological study of the si...   \n","8   kingman s coalescent is a random tree that ar...   \n","9   we discuss several novel types of multi - com...   \n","\n","                                        pred_summary  ROUGE-1 F1  ROUGE-2 F1  \\\n","0  let the set of values of the independent varia...    0.224599    0.062069   \n","1  the following form for @xmath152 was derived i...    0.142857    0.011111   \n","2  the @xmath0 decay half - life is related to th...    0.285714    0.058824   \n","3  \\end{aligned}\\ ] ] the second derivative of th...    0.140351    0.012195   \n","4  ( [ 4prop_relation ] ) over a common denominat...    0.177215    0.017391   \n","5  fig. fig. community . `` improved hough search...    0.180723    0.057613   \n","6  it is typical to subdivide cc  sne into at lea...    0.250000    0.064140   \n","7  fiz . rev . rev . lett . lett . lett . lett . ...    0.093333    0.000000   \n","8  properties of @xmath205 : * applying the grtne...    0.231579    0.007042   \n","9  introducing the effect of diffraction in a sla...    0.166667    0.021164   \n","\n","   ROUGE-L F1  Precision    Recall  F1 Score  \n","0    0.181818   0.156234  0.156549  0.156391  \n","1    0.126984   0.093384  0.093963  0.093672  \n","2    0.224490   0.216787  0.168609  0.189687  \n","3    0.105263   0.087209  0.084733  0.085953  \n","4    0.113924   0.105519  0.100300  0.102844  \n","5    0.168675   0.212304  0.099687  0.135670  \n","6    0.189655   0.243839  0.128066  0.167933  \n","7    0.066667   0.045977  0.063492  0.053333  \n","8    0.200000   0.156313  0.137359  0.146224  \n","9    0.136364   0.092428  0.130101  0.108076  "],"text/html":["\n","  <div id=\"df-d15c0b02-d069-4ba2-847c-d6108aeac688\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article</th>\n","      <th>abstract</th>\n","      <th>pred_summary</th>\n","      <th>ROUGE-1 F1</th>\n","      <th>ROUGE-2 F1</th>\n","      <th>ROUGE-L F1</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>for about 20 years the problem of properties o...</td>\n","      <td>the short - term periodicities of the daily s...</td>\n","      <td>let the set of values of the independent varia...</td>\n","      <td>0.224599</td>\n","      <td>0.062069</td>\n","      <td>0.181818</td>\n","      <td>0.156234</td>\n","      <td>0.156549</td>\n","      <td>0.156391</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>it is believed that the direct detection of gr...</td>\n","      <td>we study the detectability of circular polari...</td>\n","      <td>the following form for @xmath152 was derived i...</td>\n","      <td>0.142857</td>\n","      <td>0.011111</td>\n","      <td>0.126984</td>\n","      <td>0.093384</td>\n","      <td>0.093963</td>\n","      <td>0.093672</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>as a common quantum phenomenon , the tunneling...</td>\n","      <td>starting from the wkb approximation , a new b...</td>\n","      <td>the @xmath0 decay half - life is related to th...</td>\n","      <td>0.285714</td>\n","      <td>0.058824</td>\n","      <td>0.224490</td>\n","      <td>0.216787</td>\n","      <td>0.168609</td>\n","      <td>0.189687</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>for the hybrid monte carlo algorithm ( hmc)@xc...</td>\n","      <td>we study a novel class of numerical integrato...</td>\n","      <td>\\end{aligned}\\ ] ] the second derivative of th...</td>\n","      <td>0.140351</td>\n","      <td>0.012195</td>\n","      <td>0.105263</td>\n","      <td>0.087209</td>\n","      <td>0.084733</td>\n","      <td>0.085953</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>recently it was discovered that feynman integr...</td>\n","      <td>new methods for obtaining functional equation...</td>\n","      <td>( [ 4prop_relation ] ) over a common denominat...</td>\n","      <td>0.177215</td>\n","      <td>0.017391</td>\n","      <td>0.113924</td>\n","      <td>0.105519</td>\n","      <td>0.100300</td>\n","      <td>0.102844</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>one of the main goals of the search for period...</td>\n","      <td>in the hierarchical search for periodic sourc...</td>\n","      <td>fig. fig. community . `` improved hough search...</td>\n","      <td>0.180723</td>\n","      <td>0.057613</td>\n","      <td>0.168675</td>\n","      <td>0.212304</td>\n","      <td>0.099687</td>\n","      <td>0.135670</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>this review focuses specifically on what we ha...</td>\n","      <td>i summarize what we have learned about the na...</td>\n","      <td>it is typical to subdivide cc  sne into at lea...</td>\n","      <td>0.250000</td>\n","      <td>0.064140</td>\n","      <td>0.189655</td>\n","      <td>0.243839</td>\n","      <td>0.128066</td>\n","      <td>0.167933</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>single - transverse spin asymmetries ( ssas ) ...</td>\n","      <td>we present a phenomenological study of the si...</td>\n","      <td>fiz . rev . rev . lett . lett . lett . lett . ...</td>\n","      <td>0.093333</td>\n","      <td>0.000000</td>\n","      <td>0.066667</td>\n","      <td>0.045977</td>\n","      <td>0.063492</td>\n","      <td>0.053333</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>kingman s coalescent is a random tree introduc...</td>\n","      <td>kingman s coalescent is a random tree that ar...</td>\n","      <td>properties of @xmath205 : * applying the grtne...</td>\n","      <td>0.231579</td>\n","      <td>0.007042</td>\n","      <td>0.200000</td>\n","      <td>0.156313</td>\n","      <td>0.137359</td>\n","      <td>0.146224</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>rapid progress in the design and manufacture o...</td>\n","      <td>we discuss several novel types of multi - com...</td>\n","      <td>introducing the effect of diffraction in a sla...</td>\n","      <td>0.166667</td>\n","      <td>0.021164</td>\n","      <td>0.136364</td>\n","      <td>0.092428</td>\n","      <td>0.130101</td>\n","      <td>0.108076</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d15c0b02-d069-4ba2-847c-d6108aeac688')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d15c0b02-d069-4ba2-847c-d6108aeac688 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d15c0b02-d069-4ba2-847c-d6108aeac688');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3cb0a212-a7b5-48a7-801e-ea57283a5584\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cb0a212-a7b5-48a7-801e-ea57283a5584')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3cb0a212-a7b5-48a7-801e-ea57283a5584 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_b1dd0e06-0c7a-40a1-81c7-004c3c00c2c8\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_b1dd0e06-0c7a-40a1-81c7-004c3c00c2c8 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('test_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"test_df","summary":"{\n  \"name\": \"test_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"kingman s coalescent is a random tree introduced by @xcite as the genealogy arising in large population genetic models .\\nit has infinitely many leaves and is usually constructed from leaves to the root as follows : given that there are @xmath7 lines in the tree , after some exponential time with rate @xmath8 , two lines are chosen uniformly and merged to one line , leaving the tree with @xmath9 lines . due to the quadratic rate @xmath10 the tree immediately comes down from infinitely to finitely many leaves @xcite . since the seminal paper by @xcite this random tree has been generalized to other infinite trees arising in population genetics models .    for the kingman\\ncoalescent some laws of large numbers and central limit theorems have been proved .\\nthey are nicely summarized in @xcite , chapter  4.2 ; see also proposition  [ p:11 ] below . for @xmath11\\nlet @xmath12 denote the number of lines time @xmath13 in the past .\\nthen , since the kingman coalescent immediately comes down from infinity , @xmath12 is finite .\\nfurthermore it is approximately @xmath14 .\\nequivalently , the time @xmath0 it takes the coalescent to go from infinitely many lines to @xmath1 lines is approximately @xmath15 for large @xmath1 .\\ngoing to the fine structure , at time @xmath0 the infinite population is decomposed in @xmath1 families ( whose joint distribution is exchangeable ) and every leaf in the tree belongs to exactly one of the @xmath1 families whose frequencies are denoted by @xmath16 .\\nit is known that for large @xmath1 a randomly chosen @xmath3 is approximately exponentially distributed with mean @xmath17 .\\nthis translates into several laws of large numbers ; see e.g.  ( 35 ) in @xcite .\\nin particular the probability of picking ( from the initial infinite population ) two leaves that belong to the same family , given by @xmath18 , is approximately @xmath15 .    the main goal of the present paper is to study the corresponding large deviations results . to the best of our knowledge , except for @xcite , cf .\\nremark  [ rem : angel ] , results in this direction are not present in the literature .\\nwe formulate our results in the next section .\\ntheorem  [ t1 ] gives a full large deviation principle for the distributions of @xmath19 .\\nthe proof , given in section  [ sec : proofs1 ] , is an application of the grtner - ellis theorem . as a byproduct\\n, we derive a large deviation principle for the distributions of @xmath20 in corollary  [ cor : tnt ] .\\nlarge deviations of @xmath21 are considered in theorem  [ t2 ] and exact rate functions for downwards and upwards deviations are given . the proof is given in section  [ sec : proof - theorem - reft2 ] . for the upward deviations we use a variant of cramr s theorem for heavy - tailed random variables\\n; see e.g.  @xcite . for the downward deviations we use a connection to self - normalized large deviations ; see @xcite .\\nthis connection was pointed out to us by alain rouault and nina gantert .\\nsince the rate function for downward deviations is hard to treat analytically we provide in theorem  [ t3 ] a simple lower bound .\\nthe proof of that bound is given in section  [ sec : proof - theorem3 ] .\\nthe kingman coalescent can be seen as a discrete graph , more precisely a discrete tree with infinitely many leaves .\\nlet @xmath22 be independent exponentially distributed variables with mean @xmath23 .\\nthen the kingman coalescent tree can be constructed from the root to the leaves as follows .    1 .\\nstart the tree with two lines from the root .\\n2 .   for @xmath24\\nthe tree stays with @xmath7 lines for the amount of time @xmath25 .\\nafter that time one of the @xmath7 lines is randomly chosen .\\nthis line splits in two so that the number of lines jumps from @xmath7 to @xmath26 .\\n3 .   stop upon reaching infinitely many lines , which happens after ( the almost surely finite ) time @xmath27 .\\nthe random variable @xmath28 is the total tree height .\\nalternatively , @xmath28 is the time to the most recent common ancestor ( mrca ) of the infinite population ( of leaves ) . counted from the top of the tree at time @xmath29 a random number @xmath12 of active lines in the kingman tree is present , i.e.@xmath30 at time @xmath0 every leaf belongs to one of @xmath1 disjoint families and all members of each such family stem from the same line at time @xmath0 .\\nlet us denote the frequencies of these families ( which exist due to exchangeability by definetti s theorem ) by @xmath16 .\\nthe following results are well known ( see @xcite for   and and @xcite for ; proofs can also be found in @xcite . )     + let [ p:11 ] @xmath31 , @xmath32 and @xmath33 be as above .\\nthen @xmath34    we [ rem : interllnfe ] note that the left hand side of has the interpretation of a _\\nhomozygosity by descent _ in the following sense : when picking two leaves from the tree at time @xmath35 , the probability that both share a common ancestor at time @xmath0 is @xmath36 .\\nthen , the law of large number states that the homozygosity by descent at time @xmath0 is approximately @xmath15 for large @xmath1 .    in the present paper\\nwe are interested in large deviations results corresponding to the statements of proposition  [ p:11 ] .\\nwe start with large deviations connected with .\\nfirst we introduce some notation . for @xmath37 let @xmath38 denote the distribution of @xmath19 ,\\ni.e.  @xmath39 .\\nfurthermore we denote by @xmath40 the borel @xmath41-algebra on @xmath42 and for @xmath43 we denote by @xmath44 the _ interior _ and by @xmath45 the _ closure _ of @xmath46 . for @xmath47 ,\\nlet @xmath48 be the unique solution of the equation @xmath49 , where the continuous and increasing function @xmath50 is defined by ( see figure  [ fig : t1 ] for a plot ) @xmath51      2 & : \\\\ ; t=0 , \\\\\\\\[2ex ]      \\\\displaystyle\\\\frac{2}{\\\\sqrt{|t|}}\\\\arctan\\\\sqrt{|t| } & : \\\\ ; t < 0 .\\n\\\\end{cases}\\\\end{aligned}\\\\ ] ] the proof of the following theorem is given in section  [ sec : proof - theorem - reft1 ] .    the sequence [ t1 ] @xmath52 satisfies a large deviation principle with scale @xmath1 and good rate function @xmath53 given by @xmath54        \\\\infty & : \\\\\\n; x\\\\leq 0 .\\n\\\\end{cases }    \\\\end{aligned}\\\\ ] ] in other words , for any @xmath55 we have @xmath56     and @xmath53 from and , respectively.,title=\\\"fig:\\\",width=226 ]   and @xmath53 from and , respectively.,title=\\\"fig:\\\",width=226 ]    both , the function @xmath57 from and @xmath53 from are plotted in figure  [ fig : t1 ] .\\nthe minimum of the rate function is attained at @xmath58 .\\nthis fact is clear from the law of large numbers , .\\nin addition , @xmath59 for @xmath60 because @xmath61 almost surely .\\nlet us now have a closer look at the behaviour of @xmath62 for @xmath63 near @xmath35 and for large @xmath63 .\\nsince @xmath64 , we have that @xmath65 , and hence , @xmath66 . in this case , @xmath67 where the last equality follows from @xmath68 .\\nto understand the behaviour for large @xmath63 , note that since @xmath69 for @xmath70 we have @xmath71 and in particular @xmath72 .\\nit follows @xmath73    note that and are equivalent .\\nindeed , @xmath74 ( this also holds with @xmath75 replaced by @xmath76 ) by construction , and @xmath77 as @xmath78 and @xmath79 as @xmath80 .\\nhence , theorem  [ t1 ] translates into a large deviation principle for @xmath20 . in the following\\nwe denote by @xmath81 the distribution of @xmath82 , i.e.  @xmath83 .\\nthe proof of the next result is given in section  [ sec : proof - coroll - refc ] ; see figure  [ fig : cor1 ] for a plot of the rate function @xmath84 .    for @xmath85\\nthe family @xmath86 [ cor : tnt ] satisfies a large deviation principle with scale @xmath87 and good rate function @xmath84 given by @xmath88 \\\\displaystyle        \\\\frac{\\\\pi^2}{2 } & : \\\\ ,   x=0 , \\\\\\\\[1.5ex ]        \\\\infty & : \\\\ , x<0 ,      \\\\end{cases }    \\\\end{aligned}\\\\ ] ] with @xmath53 from  .\\nin particular , for @xmath89 we have @xmath90     from corollary  [ cor : tnt ] .\\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\\\"fig:\\\",width=226 ]   from corollary  [ cor : tnt ] .\\nthe figure on the right is a comparison of @xmath84 with the lower bound obtained from @xcite.,title=\\\"fig:\\\",width=226 ]    the distributions @xmath91 ( as well as @xmath92 ) have been described explicitely in the literature .\\n@xcite , section 6 , gives @xmath93 in principle , this formula must also give the large deviations for the measures @xmath81 , but this does not seem straight - forward .    although [ rem : angel ] the main goal of  @xcite was the analysis of spatial @xmath94-coalescents , they also provide some large deviations bounds on kingman s coalescent .\\nthese bounds are mainly based on markov inequality .\\nprecisely , in lemma 2.2 in @xcite it is shown that for @xmath95 @xmath96 and therefore @xmath97 in the neighbourhood of @xmath98 the last inequality translates easily into a bound for the rate function @xmath84 from ; see figure  [ fig : cor1 ] .\\nnamely , for @xmath99 we have @xmath100    next , we state some large deviations results connected to  . for @xmath101 we know from   that @xmath102 holds almost surely .\\nthe proof of this result is based on the well - known fact ( see e.g.  section  5 in @xcite ) that the distribution of @xmath103 can be derived using uniform order statistics : let @xmath104 be independent and uniformly distributed on @xmath105 $ ] , and @xmath106 be their order statistics .\\nadditionally , let @xmath107 be independent exponentially distributed random variables with mean @xmath23 . then , @xmath108 here the second equality in distribution is one of the well known representations of uniform spacings ; see e.g.  section  4.1 in @xcite .\\nit follows @xmath109 we will use this representation to obtain large deviations results for @xmath103 . in particular\\nwe show that upwards large deviations of @xmath103 are on the scale @xmath6 while downwards large deviations are on the scale @xmath1 . the proof is given in section  [ sec : proof - theorem - reft2 ] .    for [ t2 ]\\neach @xmath110 , we have @xmath111 furthermore @xmath112 and for each @xmath113 , we have @xmath114 the function @xmath115 is positive for @xmath116 and is given by @xmath117 here @xmath118 is a function of the form @xmath119 with @xmath120 where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution .\\nthough the rate function in   is exact it is hard to treat analytically . for this reason we provide in theorem  [ t3 ] a much simpler lower bound for downwards large deviations of @xmath103 . for the proof we use the following lemma which provides another representation of @xmath103 in terms of exponential random variables ( see section  [ sec : proofs2 ] for proofs ) .\\nlet [ l : wn ] @xmath122 be independent exponentially distributed random variables with mean @xmath23 .\\nthen , @xmath123    for [ t3 ] @xmath124 we have @xmath125    the main point in the proof of lemma  [ l : wn ] is that @xmath103 does not depend on the order of the @xmath126 and hence we can as well order them according to their size .\\nlet us briefly explain how we will use in the proof of in . since @xmath103 is minimal if @xmath127 ( whence @xmath128 ) , we have to look for possibilities that all @xmath126 s are of about the same size in order to obtain a large deviations result for @xmath103 .\\nlet @xmath129 denote the above exponential random variables ordered in increasing order , i.e.  @xmath130 is the @xmath4th smallest value .\\nusing `` competing exponential clocks '' arguments ( see also the proof of the lemma ) one can see that @xmath131 is exponentially distributed with mean @xmath132 . hence , one way of obtaining similar values for all @xmath126 s arises if @xmath133 is particularly large , which then leads to a large deviations result for @xmath103 .     from in theorem  [ t2 ] and the lower bound from in theorem  [ t3].,width=226 ]    \\\\1 .\\nlet us give some heuristics about the rates arising in theorem  [ t2 ] . for , we have to ask ourselves about the easiest way @xmath103\\nbecomes too large . from\\n, we see that this is the case if one of the @xmath126 s is too large , making this kind of deviations a local property in the sense that only a single of the @xmath126 s has to show some untypical behavior .\\nthis is different when looking at , i.e.  too small values of @xmath103 .\\nfirst , observe that @xmath103 is small only if all ( or many ) families have about equal sizes ( extreme case @xmath134 gives the minimal value @xmath128 ) .\\nhence , such downward deviations require to study a global property of the random variable @xmath103 , which is significantly harder .\\nfor the proof of we will interpret @xmath103 as a self - normalised sum and use from @xcite a result on large deviations result for such sums .    \\\\2 . from\\n, we see that in fact @xmath103 is a function of uniform order statistics , which , for instance , have been studied in detail ( although no large deviations results were given ) in @xcite .\\nhence , theorem  [ t2 ] may as well be interpreted as a large deviations result for uniform order statistics .    \\\\3 .\\nas stated in remark  [ rem : interllnfe ] , @xmath135 can be interpreted as homozygosity at time @xmath0 . using a poisson process along the tree with intensity @xmath136 , we can ask for the probability of picking two leaves from the tree which are not separated by a poisson mark , denoted by _ homozygosity in state _ , abbreviated by @xmath137 . this quantity is closely related to the poisson - dirichlet distribution and some large deviations ( in the limit of large @xmath138 )\\nwere derived in @xcite .\\nit is shown there in theorem  5.1 that @xmath139 and that @xmath140 for @xmath141 . however , a large deviation principle for the quantity @xmath142 ( noting that @xmath143 ) , which corresponds to the results from theorem  [ t2 ] , could not be obtained by @xcite . at least , it was shown that its scale can not be larger than @xmath144 .\\nthe proof of theorem  [ t1 ] is an application of the grtner - ellis theorem ; see for instance section  2.3 in @xcite .\\nlet @xmath145 $ ] and @xmath146 . to show that the sequence @xmath147 satisfies a large deviation principle with scale @xmath1 and a good rate function we need to check the following three conditions .    1\\n.   @xmath148 exists for all @xmath149 as a limit in @xmath150 .\\nfurthermore @xmath151 is lower - semicontinuous , @xmath152 , where @xmath153 .\\n@xmath94 is differentiable on @xmath154 .\\n3 .   @xmath94 is _ steep _ , i.e.  @xmath155 whenever @xmath156 and @xmath157 .    then the good rate function is given by @xmath158    we proceed in three steps .\\nfirst , we compute @xmath159 .\\nsecond , we check the further assumptions of the grtner - ellis theorem and obtain @xmath53 as the fenchel - legendre transform of @xmath94 . in the third step , for the rate function @xmath53 from\\nwe obtain its simplified form given in theorem  [ t1 ] .\\nthe limit of @xmath160 : * we will show that @xmath161 for this , recall from that @xmath162 where @xmath163 is exponentially distributed with rate @xmath164 as well as independent of @xmath165 for all @xmath166 .\\nfurthermore recall that the moment generating function of an exponentially distributed random variable @xmath167 with rate @xmath168 is given by @xmath169 =    \\\\begin{cases }      \\\\frac{\\\\lambda}{\\\\lambda - t } , & \\\\text{if $ t<\\\\lambda$},\\\\\\\\ \\\\infty ,      & \\\\text{if $ t\\\\geq \\\\lambda$. }    \\\\end{cases}\\\\end{aligned}\\\\ ] ] hence , for each @xmath170 and @xmath171 we obtain by the monotone convergence theorem @xmath172    = \\\\mathbf{e}\\\\left[e^{t n^2 \\\\sum_{k = n+1}^\\\\infty s_k/\\\\binom k2}\\\\right ]    = \\\\prod_{k = n+1}^\\\\infty \\\\mathbf{e}\\\\left[e^{tn^2 s_k/\\\\binom k 2}\\\\right].\\\\ ] ] we have to consider two cases @xmath173 and @xmath174 separately .\\nfirst suppose that @xmath175 . then there exists @xmath176 so that for all @xmath177 we have @xmath178 consequently , using , we obtain @xmath179 = \\\\infty$ ] for each @xmath177 .\\nhence , @xmath180 and @xmath181 for @xmath1 large enough .\\nthus , we have @xmath182 now suppose that @xmath183 . for @xmath184 and @xmath185\\nwe have @xmath186 . furthermore using and\\nwe can write @xmath187 using this we can rewrite @xmath188 for @xmath189 as @xmath190 and by the dominated convergence theorem we obtain @xmath191 hence , ge1 is shown with @xmath94 as in .\\nmoreover , we have @xmath192 $ ] , @xmath193 and @xmath94 is lower - semi - continuous .    * step 2 .\\nfurther assumptions of the grtner - ellis theorem : * we proceed by checking the assumptions ge2 and ge3 . for differentiability of @xmath94 for @xmath194\\nconsider for @xmath195 the function @xmath196 we have @xmath197 for @xmath198 and the derivative @xmath199 exists for each @xmath200 and is continuous in @xmath149 .\\nhence , we can interchange differentiation and integration and obtain @xmath201 furthermore , for a sequence @xmath202 with @xmath203 we obtain @xmath204 i.e.  condition ge3 is also satisfied .    * step 3 .\\nproperties of @xmath205 : * applying the grtner - ellis theorem reveals that the sequence of distributions of @xmath206 satisfies a large deviation principle with good rate function @xmath207= \\\\sup_{t \\\\leq      1 } \\\\left [ \\\\frac t2 x + \\\\int_1^\\\\infty      \\\\log\\\\left(1-\\\\frac{t}{y^2}\\\\right ) \\\\,\\\\emph dy \\\\right].\\\\end{aligned}\\\\ ] ] in order to compute that supremum , we write for @xmath208 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 - t}dy \\\\\\\\ & = x +    \\\\frac{1}{\\\\sqrt{t}}\\\\int_1^\\\\infty \\\\frac{1}{y+\\\\sqrt{t } } -    \\\\frac{1}{y-\\\\sqrt{t } } dy \\\\\\\\ & = x - \\\\frac{1}{\\\\sqrt{t } } \\\\log    \\\\frac{1+\\\\sqrt{t}}{1-\\\\sqrt{t}}\\\\end{aligned}\\\\ ] ] while for @xmath210 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 + |t|}dy \\\\\\\\ & = x -    \\\\frac{2}{\\\\sqrt{|t|}}\\\\arctan\\\\sqrt{|t|}.\\\\end{aligned}\\\\ ] ] it is easy to see that the second derivative is negative throughout , such that the supremum is attained at @xmath211 given by the solution of @xmath212 for @xmath57 as in  .\\nfinally we note that for @xmath213 the range of @xmath214 is @xmath215 and for @xmath216 $ ] the range of @xmath217 is @xmath218 $ ] .\\nhence , the scale function @xmath53 is of the form given in  .      the proof is based on the fact that @xmath219 .\\nthus , for @xmath220 we have @xmath221 and for @xmath222 @xmath223 the value @xmath224 follows from  . since the rate function @xmath53 attains its minimum at @xmath58 , is decreasing below and increasing above @xmath98 , the result follows .\\nwhen looking at , note that @xmath103 does not depend on the order of the @xmath126 s .\\ntherefore , it is possible to order them according to their size . precisely , let @xmath225 be their order statistics .\\nthen it is well - known that @xmath226 indeed , the smallest of @xmath1 independent exponentially distributed mean @xmath23 random variables is exponentially distributed with mean @xmath227 ( as does @xmath228 ) , and the second smallest then has the same distribution as @xmath229 etc .\\nnow , we obtain as follows @xmath230      we start by proving  .\\nlet @xmath110 and let @xmath231 be independent exponential random variables with mean @xmath23 . in what follows we set @xmath232 according to , it suffices to show that @xmath233 to this end we will show that for all @xmath234 , @xmath235 as well as @xmath236 and obtain by letting @xmath237 .\\nfor   we have @xmath238 we consider the two terms on the right hand side of the last display separately and start with the first one .\\nobserve that @xmath239 = \\\\infty$ ] for @xmath168 , @xmath240 = 2 $ ] and @xmath241 for @xmath242 .\\nwe use a variant of cramr s theorem for heavy - tailed random variables from @xcite .\\nin particular , we refer to the statement around equation ( 1.2 ) there ( the assumption there is fulfilled with @xmath243 replaced by @xmath244 and @xmath245 , @xmath246 and @xmath247 ) .\\nwe obtain @xmath248 for the second term on the right hand side of by the ( classical ) cramr theorem we obtain @xmath249 where @xmath250 is the fenchel - legendre transform of the function @xmath251 $ ] . now , using , and we obtain @xmath252 which shows . for the proof of\\nwe write @xmath253 again we consider both terms in the last line separately . for the first term , as in\\nwe obtain @xmath254 for the second term , we use the same argument as for and get @xmath255 combining   and   with   now gives   which proves  .    since the minimum of @xmath103 is @xmath23 ( when @xmath256 for all @xmath7 ) the assertion @xmath257 is clear .\\nit remains to prove , show that the rate function is of the form   and justify the positivity of @xmath115 for @xmath258 .    for @xmath259\\nusing we obtain @xmath260 furthermore , for @xmath258 we have @xmath261/\\\\sqrt{\\\\mathbf e[r_1 ^ 2]}$ ] .\\nthus , we can use theorem  1.1 from @xcite and obtain @xmath262.\\\\end{aligned}\\\\ ] ] now we have @xmath263 & = \\\\int_0^\\\\infty \\\\exp\\\\bigl(-y + t(c    y - \\\\frac1{2\\\\sqrt x}(y^2+c^2))\\\\bigr ) \\\\ , dy \\\\\\\\ \\\\intertext{and elementary integration yields } & = \\\\frac{\\\\sqrt{2\\\\pi}x^{1/4}}{\\\\sqrt{t } }      \\\\exp\\\\left(\\\\frac{(tc-1)^2x - t^2c^2}{2t\\\\sqrt{x}}\\\\right )      \\\\phi\\\\left(\\\\frac{(tc-1)x^{1/4}}{\\\\sqrt t}\\\\right),\\\\end{aligned}\\\\ ] ] where @xmath121 denotes the distribution function of the one dimensional standard gaussian distribution . taking @xmath264 of the last term we obtain .\\nnow we fix @xmath258 and show that @xmath115 is positive . in the sequel we write\\n@xmath265 we have @xmath266 \\\\\\\\ & \\\\ge   \\\\mathbf    e\\\\left [ \\\\inf_{t \\\\ge 0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] \\\\\\\\    & = \\\\mathbf e\\\\left[\\\\mathbbm 1_{\\\\{h(r_1,c ) < 0\\\\ } } \\\\inf_{t \\\\ge        0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] +    \\\\mathbf e\\\\left [ \\\\mathbbm 1_{\\\\{h(r_1,c ) \\\\ge 0\\\\ } }   \\\\inf_{t \\\\ge        0}\\\\exp\\\\bigl(t h(r_1,c ) \\\\bigr)\\\\right ] \\\\\\\\    & = \\\\mathbf p \\\\bigl(h(r_1,c ) \\\\ge 0\\\\bigr).\\\\end{aligned}\\\\ ] ] the function @xmath267 is non - negative on the interval @xmath268 $ ] where @xmath269 are the zeros of the function .\\nit follows @xmath270 =    \\\\mathbf p \\\\left ( r_1 \\\\le r_1 \\\\le r_2 \\\\right ) =    e^{-c(\\\\sqrt{x}-\\\\sqrt{x-1 } ) } - e^{-c(\\\\sqrt{x}+\\\\sqrt{x-1})}.\\\\end{aligned}\\\\ ] ] finally , by elementary calculation we obtain @xmath271 this expression ( and therefore also @xmath115 ) is positive for @xmath258 .\\nthus , the proof of theorem  [ t2 ] is concluded .\\nwe prove the inequality using lemma  [ l : wn ] .\\nlet @xmath272 and set @xmath273 . for @xmath11\\nwe have @xmath274 now @xmath275 , and conditioning in the second factor in the curly braces can be removed by using the fact that conditioned on @xmath276 the exponential random variable @xmath277 has the same distribution as @xmath278 .\\nafter some elementary calculations we see that the last line of the above display equals @xmath279 from the strong law of large numbers and with lemma  [ l : wn ] we know that @xmath280{n\\\\to\\\\infty } 2 \\\\quad \\\\text{almost surely.}\\\\end{aligned}\\\\ ] ] it follows that almost surely @xmath281{n\\\\to\\\\infty } \\\\frac{2 + 2y+y^2}{1 + 2y+y^2 } = x.\\\\end{aligned}\\\\ ] ] thus , @xmath282 the rest follows by letting @xmath283 .\\nwe thank shui feng for pointing out connections to @xcite and nina gantert and alain rouault for pointing out the reference @xcite and fruitful email discussion that led to the exact rate function in .\\nthis research was supported by the dfg through grants pf-672/6 - 1 to ad and pp .\\nevans , s. ( 2000 ) .\\nkingman s coalescent as a random metric space . in _\\nstochastic models : proceedings of the international conference on stochastic models in honour of professor donald a. dawson , ottawa , canada , june 10 - 13 , 1998 ( l.g gorostiza and b.g .\\nivanoff eds . )\\n_ , canad .\",\n          \"it is believed that the direct detection of gravitational waves ( gws ) will bring the era of gravitational wave astronomy .\\nthe interferometer detectors are now under operation and awaiting the first signal of gws  @xcite .\\nit is also known that pulsar timing arrays ( ptas ) can be used as a detector for gws @xcite .\\nthese detectors are used to search for very low frequency ( @xmath0 ) gravitational waves , where the lower limit of the observable frequencies is determined by the inverse of total observation time @xmath1 .\\nindeed , the total observation time has a crucial role in ptas , because ptas are most sensitive near the lower edge of observable frequencies @xcite . taking into account its sensitivity ,\\nthe first direct detection of the gravitational waves might be achieved by ptas .\\nthe main target of ptas is the stochastic gravitational wave background ( sgwb ) generated by a large number of unresolved sources with the astrophysical origin or the cosmological origin in the early universe .\\nthe promising sources are super massive black hole binaries  @xcite , cosmic ( super)string  @xcite , and inflation  @xcite .\\nprevious studies have assumed that the sgwb is isotropic and unpolarized  @xcite .\\nthese assumptions are reasonable for the primary detection of the sgwb , but the deviation from the isotropy and the polarizations should have rich information of sources of gravitational waves .\\nrecently , the cross - correlation formalism has been generalized to deal with anisotropy in the sgwb @xcite .\\nresult of this work enables us to consider arbitrary levels of anisotropy , and a bayesian approach was performed by using this formalism @xcite . on the other hand , for the anisotropy of the sgwb , the cross - correlation formalism has been also developed in the case of interferometer detectors  @xcite .\\nas to the polarization , there are works including the ones motivated by the modified gravity  @xcite\\n. we can envisage supermassive black hole binaries emit circularly polarized sgwb due to the chern - simons term  @xcite .\\nthere may also exist cosmological sgwb with circular polarization in the presence of parity violating term in gravity sector  @xcite .    in this paper\\n, we investigate the detectability of circular polarization in the sgwb by ptas .\\nwe characterize sgwb by the so called stokes @xmath2 parameter  @xcite and calculate generalized overlap reduction functions ( orfs ) so that we can probe the circular polarization of the sgwb .\\nwe also discuss a method to separate the intensity ( @xmath3 mode ) and circular polarization ( @xmath2 mode ) of the sgwb .\\nthe paper is organized as follows . in section [ sec :\\nstokes parameters for a plane gravitational wave ] , we introduce the stokes parameters for monochromatic plane gravitational waves , and clarify the physical meaning of the stokes parameters @xmath3 and @xmath2 . in section [ sec : formulation ] , we formulate the cross - correlation formalism for anisotropic circularly polarized sgwb with ptas .\\nthe basic framework is essentially a combination of the formalism of @xcite , and the polarization decomposition formula of the sgwb derived in @xcite . in section [ sec : the generalized overlap reduction function for circular polarization ] , we calculate the generalized orfs for the @xmath2 mode .\\nthe results for @xmath3 mode are consistent with the previous work  @xcite . in section [ sec : separation method ] , we give a method for separation between the @xmath3 mode and @xmath2 mode of the sgwb .\\nthe final section is devoted to the conclusion . in appendixes , we present analytic results for the generalized overlap reduction functions . in this paper\\n, we will use the gravitational units @xmath4 .\\nlet us consider the stokes parameters for plane waves traveling in the direction @xmath5 , which can be described by @xmath6 \\\\\\n, \\\\\\\\ & & h_{xy}(t , z)=h_{yx}(t , z)={\\\\rm re}[b_{\\\\times}\\\\mathrm{e}^{-iw(t - z ) } ] \\\\ .\\\\end{aligned}\\\\ ] ] for an idealized monochromatic plane wave , complex amplitudes @xmath7 and @xmath8 are constants .\\npolarization of the plane gws is characterized by the tensor , ( see @xcite and also electromagnetic case @xcite ) @xmath9 where @xmath10 take @xmath11 .\\nany @xmath12 hermitian matrix can be expanded by the pauli and the unit matrices with real coefficients .\\nhence , the @xmath13 hermitian matrix @xmath14 can be written as @xmath15 where @xmath16 by analogy with electromagnetic cases , @xmath17 and @xmath2 are called stokes parameters . comparing with , we can read off the stokes parameters as @xmath18= b_{+}^{\\\\ast}b_{\\\\times}+ b_{\\\\times}^{\\\\ast}b_{+},\\\\\\\\ v&=&-2{\\\\rm i m } [ b_{+}^{\\\\ast}b_{\\\\times}]=i ( b_{+}^{\\\\ast}b_{\\\\times}- b_{\\\\times}^{\\\\ast}b_{+}).\\\\label{stv}\\\\end{aligned}\\\\ ] ] apparently , the real parameter @xmath3 is the intensity of gws . in order to reveal the physical meaning of the real parameter @xmath2 , we define the circular polarization bases @xcite @xmath19 from the relation @xmath20 we see @xmath21\\nthus , we can rewrite the stokes parameters - as @xmath22 from the above expression , we see that the real parameter @xmath2 characterizes the asymmetry of circular polarization amplitudes .\\nthe other parameters @xmath23 and @xmath24 have additional information about linear polarizations by analogy with the electromagnetic cases .\\nalternatively , we can also define the tensor @xmath25 in circular polarization bases @xmath26 where @xmath27 .\\nnote that the stokes parameters satisfy a relation @xmath28    next , we consider the transformation of the stokes parameters under rotations around the @xmath5 axis . the rotation around the @xmath5 axis is given by @xmath29 where @xmath30 is the angle of the rotation .\\nthe gws traveling in the direction @xmath5 @xmath31 transform as @xmath32 where we took the transverse traceless gauge @xmath33 after a short calculation , we obtain @xmath34 using and , the four stokes parameters ( [ sti])-([stv ] ) transform as @xmath35 as you can see , the parameters @xmath23 and @xmath24 depend on the rotation angle @xmath30 .\\nthis reflects the fact that @xmath23 and @xmath24 parameters characterize linear polarizations .\\nnote that this transformation is similar to the transformation of electromagnetic case except for the angle @xmath36 and can be rewritten as @xmath37\\nin this section , we study anisotropic distribution of sgwb and focus on the detectability of circular polarizations with pulsar timing arrays .\\nwe combine the analysis of @xcite and that of @xcite . in sec.[subsec : the spectral ] , we derive the power spectral density for anisotropic circularly polarized sgwb @xmath38 .\\nthen we also derive the dimensionless density parameter @xmath39 which is expressed by the frequency spectrum of intensity @xmath40  @xcite . in sec.[subsec : the signal ] , we extend the generalized orfs to cases with circular polarizations characterized by the parameter @xmath2 . for simplicity ,\\nwe consider specific anisotropic patterns with @xmath41 expressed by the spherical harmonics @xmath42 .      in the transverse traceless gauge , metric perturbations @xmath43 with a given propagation direction @xmath44\\ncan be expanded as @xcite @xmath45 where the fourier amplitude satisfies @xmath46 as a consequence of the reality of @xmath43 , @xmath47 , @xmath48 is the frequency of the gws , @xmath49 are spatial indices , @xmath50 label polarizations .\\nnote that the fourier amplitude @xmath51 satisfies the relation @xmath52 where @xmath53 was defined by .\\nthe polarized tensors @xmath54 are defined by @xmath55 where @xmath56 and @xmath57 are unit orthogonal vectors perpendicular to @xmath58 .\\nthe polarization tensors satisfy @xmath59 with polar coordinates , the direction @xmath44 can be represented by @xmath60 and the polarization basis vectors read @xmath61    we assume the fourier amplitudes @xmath62 are random variables , which is stationary and gaussian .\\nhowever , they are not isotropic and unpolarized .\\nthe ensemble average of fourier amplitudes can be written as @xcite @xmath63 where @xmath64 here , the bracket @xmath65 represents an ensemble average , and @xmath66 is the dirac delta function on the two - sphere .\\nthe gw power spectral density @xmath38 is a hermitian matrix , and satisfies @xmath67 because of the relation @xmath46 .\\ntherefore , we have the relations @xmath68 note that the stokes parameters are not exactly the same as the expression of , but they have the relation and characterize the same polarization .\\nwe further assume that the sgwbs satisfy @xmath69 we also assume the directional dependence of the sgwb is frequency independent @xcite .\\nthis implies the gw power spectral density is factorized into two parts , one of which depends on the direction while the other depends on the frequency .\\nbecause of the transformations - , the parameters @xmath3 and @xmath2 have spin 0 and the parameters @xmath70 have spin @xmath71  @xcite . to analyze the sgwb on the sky , it is convenient to expand the stokes parameters by spherical harmonics @xmath72\\n. however , since @xmath70 parameters have spin @xmath71 , they have to be expanded by the spin - weighted harmonics @xmath73 @xcite .\\nthus , we obtain @xmath74 in this paper , we study specific anisotropic patterns with @xmath41 for simplicity .\\ntherefore , we can neglect @xmath23 and @xmath24 from now on .\\nthus , the gw power spectral density becomes @xmath75 where @xmath76 so , we focus on the parameters @xmath3 and @xmath2 . in what follows , we will use the following shorthand notation @xmath77    next , we consider the dimensionless density parameter  @xcite @xmath78 where @xmath79 is the critical density , @xmath80 is the present value of the hubble parameter , @xmath81 is the energy density of gravitational waves , and @xmath82 is the energy density in the frequency range @xmath48 to @xmath83 .\\nthe bracket @xmath65 represents the ensemble average .\\nhowever , actually , we take a spatial average over the wave lengths @xmath84 of gws or a temporal average over the periods @xmath85 of gws . here\\n, we assumed the ergodicity , namely , the ensemble average can be replaced by the temporal average .\\nusing , , , as well as @xmath46 and @xmath86 , we get @xmath87 then we define @xmath88 hence , the dimensionless quantity @xmath39 in is given by @xmath89 where the spherical harmonics are orthogonal and normalized as @xmath90 using @xmath91 , we obtain @xmath92 without loss of generality , we normalize the monopole moment as @xmath93 so , becomes @xmath94      the time of arrival of radio pulses from the pulsar is affected by gws .\\nconsider a pulsar with frequency @xmath95 located in the direction @xmath96 . to detect the sgwb ,\\nlet us consider the redshift of the pulse from a pulsar @xcite @xmath97 where @xmath98 is a frequency detected at the earth and @xmath96 is the direction to the pulsar .\\nthe unit vector @xmath44 represents the direction of propagation of gravitational plane waves .\\nwe also defined the difference between the metric perturbations at the pulsar @xmath99 and at the earth @xmath100 as @xmath101 the gravitational plane waves at each point is defined as @xmath102 for the sgwb , the redshift have to be integrated over the direction of propagation of the gravitational waves @xmath44 : @xmath103 we choose a coordinate system @xmath104 and assume that the amplitudes of the metric perturbation at the pulsar and the earth are the same .\\nthen becomes @xmath105 and therefore , reads @xmath106 where we have defined the pattern functions for pulsars @xmath107 note that our convention for the fourier transformation is @xmath108 therefore , the fourier transformation of can be written as @xmath109    in the actual signals from a pulsar , there exist noises .\\nhence , we need to use the correlation analysis .\\nwe consider the signals from two pulsars @xmath110 where @xmath111 labels the pulsar . here\\n, @xmath112 denotes the signal from the pulsar and @xmath113 denotes the noise intrinsic to the measurement .\\nwe assume the noises are stationary , gaussian and are not correlated between the two pulsars .\\nto correlate the signals of two measurements , we define @xmath114 where @xmath1 is the total observation time and @xmath115 is a real filter function which should be optimal to maximize signal - to - noise ratio . in the case of interferometer\\n, the optimal filter function falls to zero for large @xmath116 compered to the travel time of the light between the detecters .\\nsince the signals of two detectors are expected to correlate due to the same effect of the gravitational waves , the optimal filter function should behave this way .\\nthen , typically one of the detectors is very close to the other compared to the total observation time @xmath1 .\\ntherefore , the total observation time @xmath1 can be extended to @xmath117 @xcite .\\nin contrast , in the case of pta , it is invalid that @xmath1 is very large compered to the travel time of the light between the pulsars .\\nnevertheless , we can assume that one of the two @xmath1 can be expanded to @xmath117 , because in situations @xmath118 and @xmath119 it is known that we can ignore the effect of the distance @xmath120 of pulsars .\\nin this case , it is clear that any locations of the pulsars are optimal and optimal filter function should behave like as the interferometer case @xcite .    using these assumptions @xmath118 and @xmath119 , we can rewrite as @xmath121 where @xmath122 note that @xmath123 satisfies @xmath124 , because @xmath125 is real .\\nmoreover , to deal with the unphysical region @xmath126 we require @xmath127 .\\nthus , @xmath123 becomes real .\\ntaking the ensemble average , using @xmath128 , @xmath118 , and assuming the noises in the two measurements are not correlated , we get @xmath129\\\\ , \\\\label{s2}\\\\end{aligned}\\\\ ] ] where we have defined @xmath130 the functions @xmath131 and @xmath132 are called the generalized orfs , which describe the angular sensitivity of the pulsars for the sgwb . note that , as we already mentioned , we consider the cases of @xmath41 for simplicity\\n. then we have assumed @xmath118 and @xmath119 , this assumption implies that approximately becomes @xmath133 due to the rapid oscillation of the phase factor .\\ntherefore , the distance @xmath120 of the pulsars does not appear in the generalized orfs , and hence the generalized orfs do not depend on the frequency .    as you can see from ,\\nthe correlation of the two measurements involve both the total intensity and the circular polarization .\\nhowever , the degeneracy can be disentangled by using separation method , which will be discussed in the section [ sec : separation method ] .\\nin this section , we consider the generalized orfs for circular polarizations : @xmath134 where we defined @xmath135 in the above , we have used and the fact that the generalized orfs do not depend on frequency . for computation of the generalized orfs for circular polarizations ,\\nit is convenient to use the computational frame @xcite defined by @xmath136 where @xmath137 is the angular separation between the two pulsars . using - , , and\\n, one can easily show that @xmath138 we therefore get @xmath139 the explicit form of the spherical harmonics reads @xmath140 where @xmath141 is the normalization factor .\\nthe associated legendre functions are given by @xmath142 and @xmath143 with the legendre functions @xmath144\\\\ .\\\\label{pl}\\\\end{aligned}\\\\ ] ] using the spherical harmonics , becomes @xmath145 where we have used the fact that the function of @xmath146 is odd parity in the case of @xmath147 and is even parity in the case of @xmath148 .\\nnote that the generalized orfs for circular polarizations are real functions . in the case of @xmath149 and/or @xmath150 ,\\nthe integrand in vanishes .\\ntherefore , we can not detect circular polarizations for these cases .\\nthis fact for @xmath151 implies that we do not need to consider auto - correlation for a single pulsar .\\nthis is the reason why we neglected auto - correlation term in .    integrating ,\\nwe get the following form for @xmath152 : @xmath153 for @xmath154 , we have obtained @xmath155 \\\\ , \\\\\\\\ \\\\gamma^{v}_{1 - 1}&=&\\\\gamma^{v}_{11 } \\\\ , \\\\end{aligned}\\\\ ] ] recall that @xmath156 .\\nthe derivation of this formula for @xmath154 can be found in appendix [ sec : angular integral of the generalized overlap reduction function for dipole circular polarization ] .    for @xmath157 , we derived the following : @xmath158\\\\ , \\\\\\\\ \\\\gamma^{v}_{2 - 1}&=&\\\\gamma^{v}_{21}\\\\ , \\\\\\\\\\n\\\\gamma^{v}_{22}&=&-\\\\frac{\\\\sqrt{30\\\\pi}}{6}(1-\\\\cos\\\\xi)\\\\left[2-\\\\cos\\\\xi+6\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{2 - 2}&=&-\\\\gamma^{v}_{22}\\\\ , \\\\end{aligned}\\\\ ] ] for @xmath159 , the results are @xmath160\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 1}&=&\\\\gamma^{v}_{31}\\\\ , \\\\\\\\ \\\\gamma^{v}_{32}&=&\\\\frac{\\\\sqrt{210\\\\pi}}{24}(1-\\\\cos\\\\xi)\\\\left[8 - 5\\\\cos\\\\xi-\\\\cos^2\\\\xi+24\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 2}&=&-\\\\gamma^{v}_{3 - 2}\\\\ , \\\\\\\\ \\\\gamma^{v}_{33}&=&-\\\\frac{\\\\sqrt{35\\\\pi}}{16}\\\\sin\\\\xi\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\left[11 - 6\\\\cos\\\\xi-\\\\cos^2\\\\xi+32\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{v}_{3 - 3}&=&\\\\gamma^{v}_{33}\\\\ .\\\\end{aligned}\\\\ ] ] in fig .\\n[ gv ] , we plotted these generalized orfs as a function of the angular separation between the two pulsars @xmath137 .\\nit is apparent that considering the @xmath2 mode does not make sense when we only consider the isotropic ( @xmath152 ) orf . on the other hand ,\\nwhen we consider anisotropic ( @xmath161 ) orfs , it is worth taking into account polarizations .\\nthe polarizations of the sgwb would give us rich information both of super massive black hole binaries and of inflation in the early universe .\\nas a function of the angular separation between the two pulsars @xmath137 . in fig .\\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . in fig . [ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 . in fig .\\n[ gv](a ) , we find the orf for the monopole ( l=0 ) is trivial . in fig .\\n[ gv](b ) , the orfs for the dipole ( l=1 ) are shown . in fig .\\n[ gv](c ) , the orfs for the quadrupole ( l=2 ) are depicted . in fig .\\n[ gv](d ) , the orfs for the octupole ( l=3 ) are plotted .\\nthe black solid curve , the blue dashed curve , the red dotted curve , the dark - red space - dotted curve , and the green long - dashed curve represent @xmath149 , @xmath162 , @xmath163 , @xmath164 , @xmath165 , respectively.,title=\\\"fig:\\\",width=340 ] ( d ) @xmath159    using the same procedure described in the above to derive the generalized orfs for circular polarizations , we can also derive the generalized orfs for the intensity @xmath166 where @xmath167 the angular integral in this case was performed in @xcite .\\nthe results are summarized in appendix [ sec : the generalized overlap reduction function for intensity ] .\\nin this section , we separate the @xmath3 mode and @xmath2 mode of the sgwb with correlation analysis @xcite . to this aim ,\\nwe use four pulsars ( actually we need at least three pulsars ) , and define correlations of @xmath168 @xmath169 where @xmath170 label the pulsars . comparing with , we obtain @xmath171 \\\\ ,\\n\\\\label{1c12}\\\\\\\\ & & c_{34}(f)=\\\\sum_{lm}^{l=3}\\\\left[c_{lm}^{i}i(f)\\\\gamma_{lm,34}^{i}+c_{lm}^{v}v(f)\\\\gamma_{lm,34}^{v}\\\\right ] \\\\ .\\\\label{1c34}\\\\end{aligned}\\\\ ] ] if the @xmath3 mode and @xmath2 mode of the sgwb are dominated by a certain @xmath172 and @xmath173 , and become @xmath174 \\\\ , \\\\label{2c12 } \\\\\\\\ & & c_{34}(f)=\\\\left[c _ { l m}^{i}i(f)\\\\gamma _ { l m,34}^{i}+c _ { l ' m'}^{v}v(f)\\\\gamma _ { l ' m',34}^{v}\\\\right ] \\\\ .\\\\label{2c34}\\\\end{aligned}\\\\ ] ] to separate the intensity and the circular polarization , we take the following linear combinations @xmath175 where we defined coefficients @xmath176 as you can see , @xmath177 contains only @xmath40 , and @xmath178 contains only @xmath179 .\\nfor the signal @xmath180 , the formulas corresponding to and are given by @xmath181 \\\\ , \\\\label{sp}\\\\end{aligned}\\\\ ] ] where @xmath182 denotes @xmath3 and @xmath2 .\\nwe assume @xmath183 and that the noise in the four pulsars are not correlated .\\nwe also assume that the ensemble average of fourier amplitudes of the noises @xmath184 is of the form @xmath185 where @xmath186 is the noise power spectral density .\\nthe reality of @xmath187 gives rise to @xmath188 and therefore we obtain @xmath189 . without loss of generality\\n, we can assume @xmath190 then we obtain corresponding noises @xmath191 : @xmath192\\\\ , \\\\label{np}\\\\end{aligned}\\\\ ] ] where @xmath193^{1/2 } \\\\label{sn12 } \\\\ , \\\\quad s_{n,34}(f ) \\\\equiv [ s_{n,3}(f)s_{n,4}(f)]^{1/2 } \\\\label{sn34 } \\\\ .\\\\end{aligned}\\\\ ] ] using the inner product @xmath194 \\\\ , \\\\end{aligned}\\\\ ] ] we can rewrite , as @xmath195 therefore , the optimal filter function can be chosen as @xmath196 using , we get optimal signal - to - noise ratio @xmath197^{1/2}\\\\ .\\\\label{snr}\\\\end{aligned}\\\\ ] ] plugging , , and into , we obtain @xmath198^{1/2}\\\\ , \\\\\\\\\\n{ \\\\rm snr}_{v}&=&\\\\left[t\\\\int_{-\\\\infty}^{\\\\infty}df\\\\,\\\\,\\\\frac{\\\\left(c^{v}_{{l}'{m}'}\\\\right)^{2}v^{2}(f)\\\\left(\\\\gamma_{{l}'{m}',34}^{v}\\\\gamma^{i}_{{l}{m},12}-\\\\gamma_{{l}'{m}',12}^{v}\\\\gamma^{i}_{{l}{m},34}\\\\right)^2}{\\\\left(\\\\gamma^{i}_{{l}{m},12}\\\\right)^2s^{2}_{n,34}(f)+\\\\left(\\\\gamma^{i}_{{l}{m},34}\\\\right)^2s^{2}_{n,12}(f)}\\\\right]^{1/2}\\\\ .\\\\end{aligned}\\\\ ] ] if we assume all of the noise power spectral densities are the same , becomes @xmath199 thus , the compiled orfs can be defined as @xmath200^{1/2}}\\\\ , \\\\\\\\ \\\\gamma_{12:34}^{v}&\\\\equiv&\\\\frac{\\\\gamma_{{l}'{m}',34}^{v}\\\\gamma^{i}_{{l}{m},12}-\\\\gamma_{{l}'{m}',12}^{v}\\\\gamma^{i}_{{l}{m},34}}{\\\\left[\\\\left(\\\\gamma^{i}_{{l}{m},12}\\\\right)^2+\\\\left(\\\\gamma^{i}_{{l}{m},34}\\\\right)^2\\\\right]^{1/2}}\\\\ .\\\\end{aligned}\\\\ ] ] this compiled orfs @xmath201 and @xmath202 describe the angular sensitivity of the four pulsars for the pure @xmath3 and @xmath2 mode of the sgwb , respectively .\\nnote that , to do this separation , we must know a priori the coefficients @xmath203 and @xmath204 .\\nif we do not assume , the generalized orfs depend on the frequency . in this case\\n, it seems difficult to calculate these coefficients .\\nwe next consider the case that @xmath3 mode and/or @xmath2 mode dominant in two or more @xmath205 . in this case , if we have a priori knowledge of the values of @xmath206 in each of @xmath205 for coefficients\\n@xmath203 and @xmath204 , we can separate @xmath3 mode and @xmath2 mode . for example , assume that @xmath3 mode is dominated by @xmath207 , while @xmath2 mode is dominated by @xmath208 , then and become @xmath209\\\\ , \\\\label{3c12}\\\\\\\\ & & c_{34}(f)=\\\\left[c^{i}_{00}i(f)\\\\left(\\\\gamma_{00,34}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)+c_{11}^{v}v(f)\\\\gamma_{11,34}^{v}\\\\right]\\\\ .\\\\label{3c34}\\\\end{aligned}\\\\ ] ] thus , we can separate @xmath3 mode and @xmath2 mode by using linear combinations @xmath210\\\\ , \\\\\\\\\\nd_{v}&\\\\equiv&a_{v}c_{34}(f)+b_{v}c_{12}(f ) \\\\nonumber\\\\\\\\ & = & c_{11}^{v}v(f)\\\\left[\\\\gamma_{11,34}^{v}\\\\left(\\\\gamma_{00,12}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)-\\\\gamma_{11,12}^{v}\\\\left(\\\\gamma_{00,34}^{i}+\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)\\\\right]\\\\ , \\\\end{aligned}\\\\ ] ] where @xmath211 as in the previous calculations , we can get the compiled orfs @xmath212^{1/2}}\\\\ , \\\\label{gi1234}\\\\\\\\ \\\\gamma_{12:34}^{v}&\\\\equiv&\\\\frac{\\\\gamma_{11,34}^{v}\\\\left(\\\\gamma_{00,12}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)-\\\\gamma_{11,12}^{v}\\\\left(\\\\gamma_{00,34}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)}{\\\\left[\\\\left(\\\\gamma_{00,12}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,12}^{i}\\\\right)^2+\\\\left(\\\\gamma_{00,34}^{i}+\\\\displaystyle\\\\frac{c^{i}_{11}}{c^{i}_{00}}\\\\gamma_{11,34}^{i}\\\\right)^2\\\\right]^{1/2}}\\\\ .\\\\label{gv1234}\\\\end{aligned}\\\\ ] ]    [ cols=\\\"^,^ \\\" , ]     in fig .\\n[ cg ] we show some compiled orfs @xmath213 ( left panels ) and @xmath214 ( right panels ) as a function of the two angular separations @xmath137 and @xmath215 for two pulsar pairs , respectively .\\nwe used the expressions of @xmath2 mode and @xmath3 mode ( see appendix [ sec : the generalized overlap reduction function for intensity ] ) , and we assumed @xmath216 for simplicity . in fig .\\n[ cg](a ) and [ cg](b ) , the @xmath3 mode is dominated by @xmath217 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](c ) and [ cg](d ) , the @xmath3 mode is dominated by @xmath219 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath207 and @xmath2 mode is dominated by @xmath218 . in fig .\\n[ cg](e ) and [ cg](f ) , the @xmath3 mode is dominated by @xmath220 and @xmath2 mode is dominated by @xmath218 . by definition , in the case of @xmath221 ,\\nthe compiled orfs are zero .\\nwe have studied the detectability of the stochastic gravitational waves with ptas . in most of the previous works ,\\nthe isotropy of sgwb has been assumed for the analysis .\\nrecently , however , a stochastic gravitational wave background with anisotropy have been considered .\\nthe information of the anisotropic pattern of the distribution should contain important information of the sources such as supermassive black hole binaries and the sources in the early universe .\\nit is also intriguing to take into account the polarization of sgwb in the pta analysis .\\ntherefore , we extended the correlation analysis to circularly polarized sgwb and calculated generalized overlap reduction functions for them .\\nit turned out that the circular polarization can not be detected for an isotropic background .\\nhowever , when the distribution has anisotropy , we have shown that there is a chance to observe circular polarizations in the sgwb .\\nwe also discussed how to separate polarized modes from unpolarized modes of gravitational waves .\\nif we have a priori knowledge of the abundance ratio for each mode in each of @xmath205 , we can separate @xmath3 mode and @xmath2 mode in general .\\nthis would be possible if we start from fundamental theory and calculate the spectrum of sgwb .\\nin particular , in the case that the signal of lowest @xmath222 is dominant , we performed the separation of @xmath3 mode and @xmath2 mode explicitly .\\nthis work was supported by grants - in - aid for scientific research ( c ) no.25400251 and \\\" mext grant - in - aid for scientific research on innovative areas no.26104708 and `` cosmic acceleration''(no.15h05895 ) .\\nin this appendix , we perform angular integration of the generalized orf for dipole ( @xmath154 ) circular polarization ( see @xcite ) : @xmath223 where we have defined @xmath224 .\\nit is obvious that in the case of @xmath225 , integrand of the generalized orf is zero , because of @xmath226 , then we obtain @xmath227 then , using - , we calculate @xmath228 and we find @xmath229    therefore we only have to consider the dipole generalized orf in the case of @xmath154 , @xmath230 : @xmath231 where @xmath232 first , to calculate @xmath233 , we use contour integral in the complex plane . defining @xmath234 and substituting @xmath235 into , we can rewrite @xmath233 as @xmath236 } \\\\ , \\\\end{aligned}\\\\ ] ] where @xmath237 denotes a unit circle .\\nwe can factorize the denominator of the integrand and get @xmath238 where @xmath239 hereafter , the upper sign applies when @xmath240 and the lower one applies when @xmath241 .\\nnote that we only consider the region @xmath242 , so we have used the relation @xmath243 in above expression . in the region\\n@xmath244 , @xmath245 is inside the unit circle @xmath237 except for @xmath246 and @xmath247 is outside the unit circle @xmath237 .\\nnow , we can perform the integral using the residue theorem @xmath248 where @xmath249 the residues inside the unit circle @xmath237 can be evaluated as @xmath250\\\\right\\\\ }             = \\\\frac{i(z_{+}+z_{-})}{2\\\\sqrt{1-x^2}\\\\sin\\\\xi } \\\\ , \\\\end{aligned}\\\\ ] ] @xmath251 thus , we obtain @xmath252 next , we consider @xmath253 defined in\\n. using , we can calculate @xmath253 as @xmath254    similarly , we can evaluate @xmath255 given in . to calculate @xmath255 in the complex plane , we again substitute into and obtain @xmath256 we use the residue theorem @xmath257 where @xmath258 the residues inside the unit circle @xmath237 can be calculated as @xmath259\\\\right\\\\ }        = \\\\frac{i(z_{+}^2+z_{-}^2)}{4\\\\sqrt{1-x^2}\\\\sin\\\\xi } \\\\ , \\\\end{aligned}\\\\ ] ] @xmath260 therefore , @xmath255 becomes @xmath261 substituting to , we can calculate @xmath262 : @xmath263    finally , substituting and into , we get the generalized orf for @xmath264 @xmath265\\\\ .\\\\end{aligned}\\\\ ] ]     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( a ) @xmath152     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( b ) @xmath154     as a function of the angular separation between the two pulsars @xmath137 . fig . [ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) .\\nthe black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( c ) @xmath157     as a function of the angular separation between the two pulsars @xmath137 .\\n[ gi](a ) shows monopole ( l=0 ) , fig .\\n[ gi](b ) shows dipole ( l=1 ) , fig .\\n[ gi](c ) shows quadrupole ( l=2 ) and fig .\\n[ gi](d ) shows octupole ( l=3 ) . the black solid curve , the blue dashed curve , the dark - blue dash - dotted curve , the red dotted curve , the green long - dashed curve , the dark - green space - dashed curve represent @xmath149 , @xmath266 , @xmath267 , @xmath268 , @xmath269 , @xmath270 , respectively.,title=\\\"fig:\\\",width=340 ] ( d ) @xmath159\\nin this appendix , we show orfs for the intensity @xcite .\\nthe following form for @xmath152 was derived in @xcite , and our expressions are identical to their expressions : @xmath271\\\\ , \\\\end{aligned}\\\\ ] ] for , @xmath154 , we calculated as @xmath272\\\\ , \\\\\\\\ \\\\gamma^{i}_{11}&=&\\\\frac{\\\\sqrt{6\\\\pi}}{12}\\\\sin\\\\xi\\\\left[1 + 3(1-\\\\cos\\\\xi)\\\\left\\\\{1+\\\\frac{4}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right\\\\}\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{1 - 1}&=&-\\\\gamma^{i}_{11}\\\\ , \\\\end{aligned}\\\\ ] ] for @xmath157 , we obtain @xmath273\\\\ , \\\\\\\\ \\\\gamma^{i}_{21}&=&-\\\\frac{\\\\sqrt{30\\\\pi}}{60}\\\\sin\\\\xi\\\\left[21 - 15\\\\cos\\\\xi-5\\\\cos^2\\\\xi+60\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 1}&=&-\\\\gamma^{i}_{2 - 1}\\\\ , \\\\\\\\ \\\\gamma^{i}_{22}&=&\\\\frac{\\\\sqrt{30\\\\pi}}{24}(1-\\\\cos\\\\xi)\\\\left[9 - 4\\\\cos\\\\xi-\\\\cos^2\\\\xi+24\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 2}&=&\\\\gamma^{i}_{22}\\\\ ,\\n\\\\end{aligned}\\\\ ] ] for @xmath159 , it is straightforward to reach the following @xmath274\\\\ , \\\\\\\\ \\\\gamma^{i}_{31}&=&\\\\frac{\\\\sqrt{21\\\\pi}}{48}\\\\sin\\\\xi(1-\\\\cos\\\\xi)\\\\left[34 + 15\\\\cos\\\\xi+5\\\\cos^2\\\\xi+\\\\frac{96}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 1}&=&-\\\\gamma^{i}_{31}\\\\ , \\\\\\\\ \\\\gamma^{i}_{32}&=&-\\\\frac{\\\\sqrt{210\\\\pi}}{48}(1-\\\\cos\\\\xi)\\\\left[17 - 9\\\\cos\\\\xi-3\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+48\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 2}&=&\\\\gamma^{i}_{32}\\\\ , \\\\\\\\ \\\\gamma^{i}_{33}&=&\\\\frac{\\\\sqrt{35\\\\pi}}{48}\\\\frac{(1-\\\\cos\\\\xi)^2}{\\\\sin\\\\xi}\\\\left[34 - 17\\\\cos\\\\xi-4\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+96\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 3}&=&-\\\\gamma^{i}_{33}\\\\ .\\\\end{aligned}\\\\ ] ] these are plotted in fig .\\nthe generalized orfs of total intensity are different from that of circular polarization in that the value for @xmath149 is non - trivial .\\nthen the @xmath3 mode orfs for @xmath275 have value even in the case of @xmath151 .\\nthis implies that we can consider auto - correlation for a single pulsar .\\n99 j.  aasi _ et al .\\n_ [ ligo scientific collaboration ] , class .\\ngrav .   * 32 * , 074001 ( 2015 ) doi:10.1088/0264 - 9381/32/7/074001 [ arxiv:1411.4547 [ gr - qc ] ] .\\nf.  acernese _ et al . _\\n[ virgo collaboration ] , class .\\ngrav .   * 32 * , no . 2 , 024001 ( 2015 ) doi:10.1088/0264 - 9381/32/2/024001 [ arxiv:1408.3978 [ gr - qc ] ] . k.  somiya [ kagra collaboration ] , class .\\n* 29 * , 124007 ( 2012 ) doi:10.1088/0264 - 9381/29/12/124007 [ arxiv:1111.7185 [ gr - qc ] ] .\\ns.  l.  detweiler , astrophys .\\nj.   * 234 * , 1100 ( 1979 ) .\\ndoi:10.1086/157593 romani , r. w. ( 1989 ) .\\ntiming a millisecond pulsar array . timing neutron stars , 113 - 117 .\\nl.  lentati _ et al .\\n_ , mon .  not .\\nsoc .   * 453 * , 2576 ( 2015 ) [ arxiv:1504.03692 [ astro-ph.co ] ] .\\nz.  arzoumanian _ et al .\\n_ [ nanograv collaboration ] , arxiv:1508.03024 [ astro-ph.ga ] . e.  s.  phinney , astro - ph/0108028 . a.  vilenkin , phys .\\nrept .   * 121 * , 263 ( 1985 ) .\\ns.  kuroyanagi , k.  miyamoto , t.  sekiguchi , k.  takahashi and j.  silk , phys .\\nd * 87 * , no . 2 , 023522 ( 2013 ) [ phys .\\nd * 87 * , no .\\n6 , 069903 ( 2013 ) ] [ arxiv:1210.2829 [ astro-ph.co ] ] .\\nm.  maggiore , gr - qc/0008027 .\\nl.  p.  grishchuk , phys .\\n* 48 * , 1235 ( 2005 ) doi:10.1070/pu2005v048n12abeh005795 [ gr - qc/0504018 ] .\\nb.  allen and j.  d.  romano , phys .\\nd * 59 * , 102001 ( 1999 ) [ gr - qc/9710117 ] .\\nc.  m.  f.  mingarelli , t.  sidery , i.  mandel and a.  vecchio , phys .\\nd * 88 * , no . 6 , 062005 ( 2013 ) [ arxiv:1306.5394 [ astro-ph.he ] ] .\\ns.  r.  taylor and j.  r.  gair , phys .\\nd * 88 * , 084001 ( 2013 ) [ arxiv:1306.5395 [ gr - qc ] ] .\\nn.  seto and a.  taruya , phys .\\nlett .   * 99 * , 121101 ( 2007 ) doi:10.1103/physrevlett.99.121101 [ arxiv:0707.0535 [ astro - ph ] ] . n.  seto and a.  taruya , phys .  rev .\\nd * 77 * , 103001 ( 2008 ) [ arxiv:0801.4185 [ astro - ph ] ] . s.  j.  chamberlin and x.  siemens , phys .\\nd * 85 * , 082001 ( 2012 ) doi:10.1103/physrevd.85.082001 [ arxiv:1111.5661 [ astro-ph.he ] ] . j.  r.  gair , j.  d.  romano and s.  r.  taylor , phys .  rev .\\nd * 92 * , no .\\n10 , 102003 ( 2015 ) doi:10.1103/physrevd.92.102003 [ arxiv:1506.08668 [ gr - qc ] ] .\\nr.  jackiw and s.  y.  pi , phys .\\nd * 68 * , 104012 ( 2003 ) doi:10.1103/physrevd.68.104012 [ gr - qc/0308071 ] . m.  satoh , s.  kanno and j.  soda , phys .\\nd * 77 * , 023526 ( 2008 ) doi:10.1103/physrevd.77.023526 [ arxiv:0706.3585 [ astro - ph ] ] . c.  r.  contaldi , j.  magueijo and l.  smolin , phys .\\n* 101 * ( 2008 ) 141101 doi:10.1103/physrevlett.101.141101 [ arxiv:0806.3082 [ astro - ph ] ] .\\nt.  takahashi and j.  soda , phys .\\nlett .   * 102 * , 231301 ( 2009 ) doi:10.1103/physrevlett.102.231301 [ arxiv:0904.0554 [ hep - th ] ] .\\nj.  l.  cook and l.  sorbo , phys .\\nd * 85 * , 023534 ( 2012 ) [ phys .\\nd * 86 * , 069901 ( 2012 ) ] doi:10.1103/physrevd.86.069901 , 10.1103/physrevd.85.023534 [ arxiv:1109.0022 [ astro-ph.co ] ] .\\ni.  obata , t.  miura and j.  soda , phys .\\nd * 92 * , no .\\n6 , 063516 ( 2015 ) doi:10.1103/physrevd.92.063516 [ arxiv:1412.7620 [ hep - ph ] ] .\\na. p. lightman , w. h. press , r. h. price , and s. a. teukolski , problem book in relativity and gravitation , 2nd ed .\\n( princeton university press , 1979 ) .\\nm. maggiore , gravitational waves , vol . 1 : theory and experiments ( oxford university press , 2008 )\\n. g. b. rybicki , a. p. lightman , radiative processes in astrophysics ( wiley - interscience , 1979 ) .\\nl. d. landau and e. m. lifshitz , the classical theory ( pergamon press , 1975 ) . c. misner , k. thorne and j. wheeler , gravitation , ( freeman 1973 ) .\\nb.  allen and a.  c.  ottewill , phys .\\nd * 56 * , 545 ( 1997 ) doi:10.1103/physrevd.56.545 [ gr - qc/9607068 ] .\\nu.  seljak and m.  zaldarriaga , phys .\\nlett .   * 78 * , 2054 ( 1997 ) doi:10.1103/physrevlett.78.2054 [ astro - ph/9609169 ] .\\nj. n. goldberg et al .\\n, journal of mathematical physics * 8 * , 2155 , 1967 . m.  anholm , s.  ballmer , j.  d.  e.  creighton , l.  r.  price and x.  siemens , phys .\\nd * 79 * , 084030 ( 2009 ) doi:10.1103/physrevd.79.084030 [ arxiv:0809.0701 [ gr - qc ] ] . l.  g.  book and e.  e.  flanagan , phys .\\nd * 83 * , 024024 ( 2011 ) doi:10.1103/physrevd.83.024024 [ arxiv:1009.4192 [ astro-ph.co ] ] . f.  a.  jenet and j.  d.  romano , am .\\nj.  phys .\\n* 83 * , 635 ( 2015 ) doi:10.1119/1.4916358 [ arxiv:1412.1142 [ gr - qc ] ] .\\nr.  w.  hellings and g.  s.  downs , astrophys .\\nj.   * 265 * , l39 ( 1983 ) . doi:10.1086/183954\",\n          \"one of the main goals of the search for periodic isolated sources of gravitational waves ( g.w . ) is to perform all sky surveys , based on `` blind searches '' , where the source parameters are unknown . in this case\\nhierarchical procedures are applied , based on a sequence of increasing resolution steps . in this paper\\nwe study in details the problem of sensitivity loss due to discretization of parameters and to the needs to limit the computing cost , with hough procedures .\\nin particular , we propose and study the characteristics of a frequency hough procedure , designed mainly to reduce the discretization problem , and we compare it with the sky hough procedure , which is actually used in the virgo collaboration .\\n+ the paper is organized as follows : in sect .\\n2 we present the basic scheme of the rome hierarchical procedure , based on the main idea of coincidences among subsets of data ; in sect .\\n3 we discuss the limits due to digitization of the sky hough procedure ; in sects . 4 , 5 we present the new frequency hough procedure , discussing details its implementation and its basic characteristics ; in sect .\\n6 we present the study of amplitude losses due to digitization , and thus efficiencies , for both the procedures .\\nconclusions and comments are given in sect .\\nhierarchical procedures , based on hough transform algorithms , are applied by various groups in the g.w . community .\\nsee , for example , references @xcite .\\nthere are various ways of implementing the hierarchical procedure and the hough transform .\\nthe hough transform is a linear transform that is used to recognize the parameters of the analytical description of a curve from the position of some points on it .\\nit operates on an `` image '' of points , in our case the peakmap in the time - frequency plane . for each peak of this map\\nwe increase a set of bins of a multi - dimensional histogram ( in our case a two - dimensional histogram ) defined on the parameters space , called the hough map . in the old procedure ,\\nthe parameter space was the position of the source , i.e. the celestial sphere , and we fixed the spin down value for each hough map . in the new one ,\\nthe parameter space is the plane @xmath0 , and for each hough map , we fix the position of the source . the mapping ( i.e. which points of the hough map must be increased for a certain point in the peakmap ) can be done in different ways : we use always what we call the `` biunivocal mapping '' , i.e. a mapping in which every point in the hough map derive from a single point of the peakmap at a given time .\\nit is easy to demonstrate that in this case the mapping is also uniform , i.e. in the case of uniformly distributed random dots in the peakmap , the expected value of the hough map @xmath1 is a constant ( for all parameter value ) .\\nthis value , depending on the number n of the spectra of the peakmap and on the mapping , defines the `` noise '' of the map .\\nit is binomially distributed with parameters n and @xmath2 .\\nwe will refer here to the rome scheme , presently used in virgo data .\\n[ fig : schema ] shows the basic scheme of the rome hierarchical procedure .\\ndetails on the main aspects of the procedure are given in references @xcite .\\nafter data cleaning ( short time domain disturbances removal ) and `` short ffts data base '' ( sfdb ) creation , peakmaps are computed , using a very refined auto - regressive algorithm to equalize the spectral data by an appropriate follow - up of the noise .\\npeakmaps are frequency vs time maps , obtained from equalized spectra by selecting all the local maxima above a chosen threshold .\\nan accurate cleaning of peakmaps , by removing known noise lines and the more persistent lines , is needed and its implementation is critical for the next step analysis . on the cleaned peakmaps ,\\nmethods of peaks detection are applied .\\nthat is , transformation from the input plane to the hough plane , thresholding and first order candidates selection .\\ncandidate parameters are defined by source frequency , celestial coordinates , first spin - down parameter .\\nthe need for coincidences among candidates obtained in different subsets of data ( two in the scheme of fig .\\n[ fig : schema ] ) has been discussed in references @xcite .\\nthis method is very efficient to reduce the number of spurious candidates at a fixed threshold .\\nthus , for a given false alarm probability , we can lower the threshold -with respect to the choice of not doing coincidences- gaining in detection efficiency .\\nthe method has a better efficiency when the data sets have similar sensitivities .\\nafter the coincidence , the survived candidates are analyzed coherently with longer ffts on corrected data .\\nthen the spectral filtering is used to take into account the spread of the power in five bands , as explained in reference @xcite .\\nfinally , second order candidates are produced .\\nas stated before , the sky hough method shows amplitude losses , and thus loss of sensitivity , which are due to digitization of parameters .\\nthis effect shows up mainly for the complexity of the transform together with the need of reducing the computing cost :    * the method is based on a transform between the time - frequency peakmap and the celestial sphere .\\nit is not simple for the non linearity of the mapping ; * to reduce the computational effort , we need to use `` look - up tables '' which introduce further digitization errors ; * to reduce the computational effort , fast algorithms have been developed , which require the use of a rectangular grid to map the sky . compared to the `` optimal '' ( see later ) grid , the rectangular one has over - resolution in some regions of the sky .\\nthis leads also to a higher number of candidates .\\n* the use of the celestial map as the space to spot the candidates is very prone to artifacts , see @xcite : some regions are always `` privileged '' , that is they have a higher candidates number with respect to the expectation . the problem arises because each hough map is constructed over the whole sky .    hence , it seemed important the study of alternative procedures .\\ngiven the observation that most of the problems are related to the complexity of the transformation , we exploit the possibility of the use of a different but simpler transformation . a part the simplicity of the transformation we obviously need to study a procedure which is less , or equivalently , computationally expensive .\\ntherefore we studied a procedure which has a better , or equivalent , sensitivity , at the same computational cost of the sky hough .\\nthe transformation we propose transforms the * time - observed frequency * plane into the * source frequency - spin down * plane . let\\ns go into details . if @xmath3 is the frequency ( doppler corrected for a given sky direction ) , @xmath4 the source intrinsic frequency , @xmath5 the first spin - down parameter , @xmath6 the time at the detector and @xmath7 a reference time , we have that @xmath8 a straight line in the hough plane .\\nwe then get the following : @xmath9 each point in the input plane @xmath10 , that is a peak in the doppler shifted peakmap , is transformed into a straight line in the hough @xmath11 plane , with slope @xmath12 .\\nthe slope depends on the choice of the reference time .\\nif we choose @xmath7 equal to the beginning time of the data we analyze , then the slope is always negative and inversely proportional to the time gap .\\n+ this is the choice we have done here . in addition , considering the width @xmath13 of the frequency bins in the input plane we notice that each peak is transformed into a stripe among two parallel straight lines    @xmath14    it is a linear transformation .\\nnow the input plane is obtained from the original peakmap by correcting it for the doppler shift due to the earth revolution and rotation , for each point in the sky grid we need to analyze .\\nthus `` time '' is the time at the detector and `` frequency '' the observed frequency , after the doppler correction .\\nbut , as each sfdb is short enough to not be affected by a time - varying doppler shift , then the doppler effect removal from the original peakmap , obtained from the collection of all the sfdb data , reduces to a very simple `` shifting '' procedure of the peakmap bins . in the analysis scheme , this bins shift is part of the hough procedure . + in the following , we give details on the construction of the map .\\nthe frequency hough map is constructed using the `` direct differential method '' , as is done with the sky hough . with this method , instead of building directly the hough map , one builds a map that , if `` integrated '' ( i.e. summed over bins from left to right ) , gives the hough map .\\nthis is important to minimize the number of floating point operations .\\nas already explained , for each sky position , the input peakmap is got from the original one by shifting bins to correct for the doppler effect .\\nthe sky is sampled with a non uniform covering grid , which will be later discussed . here\\nwe explain in detail the technique , by giving the sequence of operations :    * for each point in the sky grid , for each coordinate in the input plane @xmath10 and for each spin - down value @xmath15 ,    the map is incremented by 1 in the point @xmath16 and decremented by 1 in the point @xmath17 .    hence ,\\nfor each sky position , a differential map is constructed .\\nthe sum of the bins along the frequency direction is then performed to construct the final integral map .\\nthis two dimensional histogram is the frequency hough map . in the algorithm implementation\\nwe plan to divide the input peakmap into 10 hz bands , thus constructing , for each position in the sky , a different hough map every 10 hz .\\n+ in case there is the need to exploit higher order one spin down parameters , one ( or more ) loop(s ) has ( have ) to be added to the sequence of operations , to scan the discrete set of values of the new parameter(s ) .\\nthis clearly influences the computing cost , but does not change the basics of the method .\\nlet s first discuss two peculiar aspects of this new method , which are the basis of its appeal .      from the given analysis scheme , it is easy to see that the frequency resolution for the estimation of the source frequency @xmath4 can be enhanced , with respect to the binning frequency @xmath13 , without relevantly affecting the computational effort .\\nin fact , the use of a resolution @xmath18 with @xmath19 , affects only the size of the hough map .\\nthis has a computational cost only when summing over the bins to construct the integral map from the differential one .\\nbut we notice that the total cost of the construction of the hough map is due to the construction of the differential map , dominated by the number of peaks in the peakmap and to the construction of the integral map , dominated by the number of bins .\\nthe former , in all practical cases , is the one which dominates .\\n+ the possibility to enhance the frequency resolution results to be , as will be shown in the next sections , a very important peculiarity of the new method .\\nit which enhances considerably the efficiency , by reducing the digitalization effect .\\nthe same in the sky hough procedure would have a relevant computational cost .\\nregarding the increasing of the spin down resolution , it would cost for both the procedures : the better the resolution in the spin down estimation the higher is the number of loops of the procedures .      here\\nwe describe how we construct the grid on the sky .\\nsuppose two sources , at the same frequency @xmath4 and same latitude @xmath20 .\\ntheir angular delay @xmath21 with respect to the detector rotation produces a time delay @xmath22 .\\nthe two sources will then have the same frequency variation at the detector , which is the classical equation due to the doppler effect , @xmath23 but with time delay @xmath24 .\\nthe observed frequency difference has thus a maximum value which is given by @xmath25 thus the angular resolution is , in radians : @xmath26 where @xmath27 is the number of points in the doppler band for a signal of max frequency @xmath4 : @xmath28 and @xmath29 .\\n+ we now repeat the same reasoning , supposing the two sources , at the same frequency @xmath4 and same longitude @xmath30 .\\nthe two sources will have the same frequency variation at the detector , now given by @xmath31 , but with an angular delay @xmath32 .\\nthe observed frequency difference has a maximum value which is : @xmath33 we obtain for the angular resolution , in radians : @xmath34 using eqs .\\n[ gammalong ] and [ gammalat ] we get : @xmath35 @xmath36 using these equations we construct the grid on the sky , which we call the `` optimal '' grid .\\nthe points of the grid are not uniformly distributed . with a simulation\\n, we have estimated the the number of points in the grid @xmath37 , which is , in the high frequency limit : @xmath38 @xmath39 is an extra resolution factor , which can be greater than 1 , to enhance the efficiency , but even less than 1 , to save computing cost , obviously worsening the efficiency .\\nfig.[fig : gridsim1 ] shows the optimal sky grid , for @xmath40 ( which corresponds to a source frequency @xmath41 hz ) .\\nas already said , the grid used in the sky hough method , is not optimal , but rectangular , to use fastest computing algorithms .\\nthe number of points in this rectangular grid is : @xmath42 which is , asymptotically , a factor @xmath43 higher then the number of points of the optimal grid . in fact\\nthis grid has to be over resolved to maintain the same sensitivity of the corresponding optimal grid .\\nfurther , we note that this over resolution produces a higher number of candidates from certain sky positions .    ,\\nx - axis : ecliptical longitude , degrees , from 0 to 400 ; y - axis : ecliptical latitude , degrees , from -100 to 100 ; the number of points in the map is @xmath37=2902.,width=453 ]          the sensitivity of the sky hough procedure is affected by artifacts , i.e. an excess of candidates in some places of the sky map , which are due to local spectral disturbances . the effect ca nt be eliminated because each map is constructed over the whole sky , and hence the threshold for candidate selection has to be the same for the whole sky . using the frequency hough procedure\\nthis effect disappears because each map is constructed for only one position in the sky .\\nso , because of the adaptivity of the threshold , if a sky region gives an excess of candidates , the threshold is raised and then there is a loss in sensitivity only for that sky region .\\nwe are now ready to enter into details by studying the efficiency of both the methods , by the use of simulations .\\nfigure [ fig : gridsim2 ] is an example of how a frequency hough map looks like , having injected into white noise three signals , at different frequencies and spin - down .      to study the efficiency of the methods , as a function of the frequency over resolution factor\\n, we have simulated a signal in the absence of noise .\\nthe reason for this is that we were interested in studying only the losses due to the discretization errors .\\nthe parameters chosen for the simulation are similar to actual situations ( detector parameters , source expected parameters ) .\\nthe parameters of the simulation are shown in table [ tab : par ] .\\n[ fig : freqloss ] shows the amplitude loss versus the frequency over resolution factor @xmath45 .\\nthe loss was calculated as the average value of all the peaks found in the 500 spectra ( it is important to remember that our procedure considers peaks only the maxima above threshold ) .\\nthe result is clear : using @xmath46 the amplitude loss is 3.6 @xmath47 ( the efficiency @xmath48 ) , while with @xmath49 , which is the only practically possible choice of the sky hough , the amplitude loss is 11.6 @xmath47 ( the efficiency @xmath50 ) . from the figure ,\\nwe notice that there is no further gain of increasing the over resolution factor over 10 .\\nthus , we fixed to 10 the over resolution factor for the frequency hough .\\nin next simulations , results with @xmath46 are thus for the frequency hough , results with @xmath49 are for the sky hough .\\nonce we have fixed the frequency over resolution factor we wanted to quantify how the increasing of the spin down resolution from the nominal one would affect the sensitivity .\\nthe results are in fig .\\n[ fig : freqloss1 ] , which shows the loss in amplitude vs the spin down over resolution factor , for both the cases @xmath49 , sky hough , and @xmath46,frequency hough .\\nit can be noticed that , in the case of the frequency hough , even for the worst analyzed situation , which corresponds to the nominal spin down step @xmath51 the loss is quite small .\\nis is 3.6 @xmath47 ( the efficiency @xmath48 ) .\\nthe situation is worst for the sky hough , where the loss in amplitude at the nominal spin down step is 11.6 @xmath47 ( the efficiency @xmath50 ) .\\nthe improvement obtained by a better spin down resolution is not so important , as can be seen from the figure .\\nit seems reasonable , given the observation that increasing the spin down resolution has a computational cost for both the methods , to use the nominal @xmath52 resolution ( x - axis equal to 1 in the figure ) .      to study the loss due to the sky grid resolution\\n, we have simulated 50 signals , randomly distributed over the sky .\\nwe have then looked for results using the optimal grid , again registering the average value of all the detected peaks . in what follows ,\\nwe suppose to use the optimal grid for both the procedures , sky and frequency hough .\\nfig.[fig : loss_spinres ] shows the amplitude losses , as a function of the over resolution sky map factor @xmath39 , in the two cases of @xmath46 ( left ) , frequency hough , and @xmath49 ( right ) , sky hough .\\nthe amplitude loss , for @xmath44 , is @xmath53 for the frequency hough , and @xmath54 , for the sky hough .\\nagain , a better efficiency for the new procedure .\\nwe notice that the use of an over resolution for the sky map , would have an impact on the computing cost , with both the procedures .    .\\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\\\"fig:\\\",width=302 ] .\\nthe figures compare the loss when @xmath46 ( left ) , frequency hough , and when @xmath55 ( right ) , sky hough.,title=\\\"fig:\\\",width=302 ]        + we see that the ratio of the amplitude efficiencies is @xmath57 which in power is 1.317 . from this\\n, we can compute the gain in computing cost for the same sensitivity .\\nlet us firstly recall that the @xmath58 sensitivity in the hierarchical search is proportional to @xmath59 , and the computing cost to @xmath60 .\\nthus , the `` equivalent fft '' length factor is @xmath61=1.734 and the gain in computing cost is @xmath62=5.2 ( that is , the ratio of computing costs needed to have the same @xmath58 sensitivity ) .      * the * adaptivity * , that is the weight of peaks to consider the noise level and the gain due to the antenna pattern toward a direction , is , with this approach , immediate and very simple , as each hough map is done for a single sky position .\\nit has been shown , with the sky hough , that the adaptivity of the procedure is a very important task for the analysis ; * this new procedure is appropriate also for all those situations in which the * source position * is known and we should estimate only source frequency and spin down ; * with a proper choice of parameters , it is also possible to detect and hence remove * spurious signals * , with a constant or linearly varying frequency .    on the latter point , we are now working to study the efficiency of this method in terms of rejection of spurious lines in the peakmap . we know that this is a very critical task for the analysis , since the presence of spurious lines highly affects the sensitivity of the search .\\nwe expect this new method to be much more insensitive to the presence of spurious lines , since in the chosen hough plane spurious lines and g.w .\\nsignals should have a very different and well separable behavior .\\nb. krisnan , a. sintes , m. a. papa , b .\\nf. schutz , s. frasca , c. palomba , _\\nphys.rev.d70:082001_ , 2004 .\\n`` the hough transform search for continuous gravitational waves '' a. sintes , b. krisnan , _\\nphys.conf.ser.32:206-211_ , 2006 .\\n`` improved hough search for gravitational wave pulsars ''\\np. astone , s. frasca , c. palomba,_cqg 22:s1197-s1210_,2005 `` the short fft database and the peakmap for the hierarchical search of periodic sources '' s. frasca , p. astone , c. palomba,_cqg 22:s1013-s1019 _ , 2005 `` evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources '' c. palomba , p. astone , s. frasca , _\\ncqg 22:s1255-s1264_,2005 `` adaptive hough transform for the search of periodic sources '' f. acernese et al ( virgo coll . ) _ cqg 24:s491-s499 _ , 2007 `` coincidence analysis between periodic source candidates in c6 and c7 virgo data '' f. acernese et al ( virgo coll . ) _ proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin , 2006 ) edited by h. kleinert , r.t .\\njantzen and r. ruffini , world scientific , singapore _ , 2008 `` first coincidence search among periodic gravitational wave source candidates using virgo data '' p. astone , s. frasca , c. palomba_proceedings of the eleventh marcel grossmann meeting on general relativity ( berlin 2006 ) edited by h. kleinert , r.t . jantzen and r. ruffini , world scientific , singapore _ , 2008 `` incoherent strategies for the network detection of periodic gravitational waves '' c. palomba , s. frasca , _\\ncqg 21:s1645-s1654 _ , 2004 `` spectral filtering for hierarchical search of periodic sources ''\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" kingman s coalescent is a random tree that arises from classical population genetic models such as the moran model . \\n the individuals alive in these models correspond to the leaves in the tree and the following two laws of large numbers concerning the structure of the tree - top are well - known : ( i ) the ( shortest ) distance , denoted by @xmath0 , from the tree - top to the level when there are @xmath1 lines in the tree satisfies @xmath2 almost surely ; ( ii ) at time @xmath0 , the population is naturally partitioned in exactly @xmath1 families where individuals belong to the same family if they have a common ancestor at time @xmath0 in the past . if @xmath3 denotes the size of the @xmath4th family , then @xmath5 almost surely . for both laws of large numbers \\n we prove corresponding large deviations results . for ( i ) , the rate of the large deviations is @xmath1 and we can give the rate function explicitly . for ( ii ) , the rate is @xmath1 for downwards deviations and @xmath6 for upwards deviations . for both cases \\n we give the exact rate function .    \\n =     =    =     = \",\n          \" we study the detectability of circular polarization in a stochastic gravitational wave background from various sources such as supermassive black hole binaries , cosmic strings , and inflation in the early universe with pulsar timing arrays . \\n we calculate generalized overlap reduction functions for the circularly polarized stochastic gravitational wave background . \\n we find that the circular polarization can not be detected for an isotropic background . however , there is a chance to observe the circular polarization for an anisotropic gravitational wave background . \\n we also show how to separate polarized gravitational waves from unpolarized gravitational waves . \",\n          \" in the hierarchical search for periodic sources of gravitational waves , the candidate selection , in the incoherent step , can be performed with hough transform procedures . in this paper \\n we analyze the problem of sensitivity loss due to discretization of the parameters space vs computing cost , comparing the properties of the sky hough procedure with those of a new frequency hough , which is based on a transformation from the _ time - observed frequency _ plane to the _ source frequency - spin down _ plane . \\n results on simulated peakmaps suggest various advantages in favor of the use of the frequency hough . the ones which show up to really make the difference are 1 ) the possibility to enhance the frequency resolution without relevantly affecting the computing cost . \\n this reduces the digitization effects ; 2 ) the excess of candidates due to local disturbances in some places of the sky map . \\n they do not affect the new analysis because each map is constructed for only one position in the sky . \\n + pacs . \\n numbers : 04.80nn,07.05kf,97.60jd \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"properties of @xmath205 : * applying the grtner - ellis theorem reveals that the sequence of distributions of @xmath206 satisfies a large deviation principle with good rate function @xmath207= \\\\sup_{t \\\\leq      1 } \\\\left [ \\\\frac t2 x + \\\\int_1^\\\\infty      \\\\log\\\\left(1-\\\\frac{t}{y^2}\\\\right ) \\\\,\\\\emph dy \\\\right].\\\\end{aligned}\\\\ ] ] in order to compute that supremum , we write for @xmath208 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 - t}dy \\\\\\\\ & = x +    \\\\frac{1}{\\\\sqrt{t}}\\\\int_1^\\\\infty \\\\frac{1}{y+\\\\sqrt{t } } -    \\\\frac{1}{y-\\\\sqrt{t } } dy \\\\\\\\ & = x - \\\\frac{1}{\\\\sqrt{t } } \\\\log    \\\\frac{1+\\\\sqrt{t}}{1-\\\\sqrt{t}}\\\\end{aligned}\\\\ ] ] while for @xmath210 @xmath209 & = x -    2\\\\int_1^\\\\infty \\\\frac{1}{y^2 + |t|}dy \\\\\\\\ & = x -    \\\\frac{2}{\\\\sqrt{|t|}}\\\\arctan\\\\sqrt{|t|}.\\\\end{aligned}\\\\ ] ] it is easy to see that the second derivative is negative throughout , such that the supremum is attained at @xmath211 given by the solution of @xmath212 for @xmath57 as in  .\",\n          \"the following form for @xmath152 was derived in @xcite , and our expressions are identical to their expressions : @xmath271\\\\ , \\\\end{aligned}\\\\ ] ] for , @xmath154 , we calculated as @xmath272\\\\ , \\\\\\\\ \\\\gamma^{i}_{11}&=&\\\\frac{\\\\sqrt{6\\\\pi}}{12}\\\\sin\\\\xi\\\\left[1 + 3(1-\\\\cos\\\\xi)\\\\left\\\\{1+\\\\frac{4}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right\\\\}\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{1 - 1}&=&-\\\\gamma^{i}_{11}\\\\ , \\\\end{aligned}\\\\ ] ] for @xmath157 , we obtain @xmath273\\\\ , \\\\\\\\ \\\\gamma^{i}_{21}&=&-\\\\frac{\\\\sqrt{30\\\\pi}}{60}\\\\sin\\\\xi\\\\left[21 - 15\\\\cos\\\\xi-5\\\\cos^2\\\\xi+60\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 1}&=&-\\\\gamma^{i}_{2 - 1}\\\\ , \\\\\\\\ \\\\gamma^{i}_{22}&=&\\\\frac{\\\\sqrt{30\\\\pi}}{24}(1-\\\\cos\\\\xi)\\\\left[9 - 4\\\\cos\\\\xi-\\\\cos^2\\\\xi+24\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{2 - 2}&=&\\\\gamma^{i}_{22}\\\\ ,\\n\\\\end{aligned}\\\\ ] ] for @xmath159 , it is straightforward to reach the following @xmath274\\\\ , \\\\\\\\ \\\\gamma^{i}_{31}&=&\\\\frac{\\\\sqrt{21\\\\pi}}{48}\\\\sin\\\\xi(1-\\\\cos\\\\xi)\\\\left[34 + 15\\\\cos\\\\xi+5\\\\cos^2\\\\xi+\\\\frac{96}{1+\\\\cos\\\\xi}\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 1}&=&-\\\\gamma^{i}_{31}\\\\ , \\\\\\\\ \\\\gamma^{i}_{32}&=&-\\\\frac{\\\\sqrt{210\\\\pi}}{48}(1-\\\\cos\\\\xi)\\\\left[17 - 9\\\\cos\\\\xi-3\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+48\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 2}&=&\\\\gamma^{i}_{32}\\\\ , \\\\\\\\ \\\\gamma^{i}_{33}&=&\\\\frac{\\\\sqrt{35\\\\pi}}{48}\\\\frac{(1-\\\\cos\\\\xi)^2}{\\\\sin\\\\xi}\\\\left[34 - 17\\\\cos\\\\xi-4\\\\cos^2\\\\xi-\\\\cos^3\\\\xi+96\\\\left(\\\\frac{1-\\\\cos\\\\xi}{1+\\\\cos\\\\xi}\\\\right)\\\\log\\\\left(\\\\sin\\\\frac{\\\\xi}{2}\\\\right)\\\\right]\\\\ , \\\\\\\\ \\\\gamma^{i}_{3 - 3}&=&-\\\\gamma^{i}_{33}\\\\ .\\\\end{aligned}\\\\ ] ] these are plotted in fig .\",\n          \"fig. fig. community . `` improved hough search for gravitational wave pulsars ''\\np. astone , s. frasca , c. palomba,_cqg 22:s1197-s1210_,2005 `` the short fft database and the peakmap for the hierarchical search of periodic sources '' s. frasca , p. astone , c. palomba,_cqg 22:s1013-s1019 _ , 2005 `` evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources '' c. palomba , p. astone , s. frasca , _\\ncqg 22:s1255-s1264_,2005 `` adaptive hough transform for the search of periodic sources '' f. acernese et al ( virgo coll . ) let\\ns go into details .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-1 F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05822195288187351,\n        \"min\": 0.09333332846133359,\n        \"max\": 0.28571428078925454,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.23157894238836577,\n          0.14285713785714302,\n          0.18072288721948043\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-2 F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.026059363019646065,\n        \"min\": 0.0,\n        \"max\": 0.0641399371958966,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.007042248630483461,\n          0.011111106141360247,\n          0.05761316436518857\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROUGE-L F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04935836617351176,\n        \"min\": 0.06666666179466703,\n        \"max\": 0.22448979099333624,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.1999999950199447,\n          0.12698412198412717,\n          0.1686746944483961\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06639834117801022,\n        \"min\": 0.04597701149425287,\n        \"max\": 0.24383903133903137,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.15631287337109603,\n          0.09338351606392843,\n          0.21230446702144815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03324099119028174,\n        \"min\": 0.06349206349206349,\n        \"max\": 0.1686091686091686,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.13735852112818644,\n          0.09396315420411805,\n          0.09968713685527845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1 Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0421457945093701,\n        \"min\": 0.05333333333333333,\n        \"max\": 0.18968674584517614,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.14622401447141076,\n          0.0936724384530919,\n          0.1356704744356924\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Find the Average of the scores\n","averages = []\n","for metric in metrics:\n","    average = test_df[metric].mean()\n","    averages.append(average)\n","\n","# Print average scores\n","for i in range(len(metrics)):\n","    print(f\"Average {metrics[i]}: {averages[i]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8o8eG6bIVcH","outputId":"4a1a62cd-5a02-4f19-cf17-9076a72b8621"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average ROUGE-1 F1: 0.18930382165564172\n","Average ROUGE-2 F1: 0.03115493741079501\n","Average ROUGE-L F1: 0.15138394389902204\n","Average Precision: 0.1409994773982921\n","Average Recall: 0.11628596300560232\n","Average F1 Score: 0.12397838789926185\n"]}]},{"cell_type":"code","source":["text =\"It has been shown that approximately 90% of subjects who die through suicide are diagnosed with a psychiatric disorder prior to their death [1]. Suicide is particularly worrisome in Bipolar Disorder (BD), given the high prevalence of this disorder and the strong association between suicide and depressive symptoms [2]. In addition, a large cohort study found that among men, the absolute risk of suicide was higher in BD (7.8%) compared to any other psychiatric condition. Among women, BD was associated with the second highest risk, at 4.8%, just below schizophrenia at 4.9% [3]. Furthermore, patients with BD showed twice the rate of suicide risk than patients with Major Depressive Disorder and about 20 to 30 times greater risk than in the general population [4].It is known that at least 90% of suicide cases occur in people with a psychiatric disorder, with mood disorders being the most prevalent condition in this scenario [1]. In addition, many of the individuals are untreated or inadequately treated [5]. Suicide prediction tools may aid health professionals to identify subjects at-risk for suicidal behavior, thus enabling not only early intervention and personalized care, but also the development of new strategies for suicide prevention. As there are already interventions available that show anti-suicidal effects, such as lithium for mood disorders [6] and clozapine for schizophrenia [7], adequate detection and treatment of these conditions may help reduce suicide rates.Virginia Woolf was a British novelist who biographers suggest suffered from BD [8]. From 1910 to 1913, Woolf was ill on several occasions [9]. During her life, she made at least three suicide attempts. She received the habitual treatments of the time, such as rest cure therapy at home, which consisted of gaining weight, sleeping, and the resting of the intellect, which also meant a recommendation not to write [10]. Virginia endured several depressive and manic episodes until she took her life [11] on March 28, 1941 during a depressive episode [10].Virginia Woolf presented several known risk factors associated with suicide in patients with BD [12] such as early traumatic experiences (sexual abuse), psychotic symptoms, family history of suicide, and a higher number of depressive episodes. Nevertheless, a meta-analysis of 365 studies showed that traditional suicide risk factors are poor predictors of a future suicide attempt [13]. A possible explanation for this finding is that complex patterns of interaction between risk factors are not considered in traditional statistics [14,15]. Moreover, the risk factors identified so far come from group-level results, and do not wield satisfactory predictive results at an individual level [13]. Thus, it is paramount to develop better models to predict suicidal behavior that include these interactions and explore different levels of information. Machine learning, a field of artificial intelligence that focuses on algorithms that can learn from data and then extract patterns to make new assumptions from unseen information, are increasingly being used in behavioral sciences to provide predictive models for clinical practice [16]. Machine learning can handle an enormous amount of data, such as text data, and combine them in nonlinear and highly interactive ways [17]. One important question is whether suicidal behavior is associated with an identifiable writing pattern. Virginia Woolf left a vast written repertoire contained in her diaries, where she wrote freely about her feelings, providing a living record of her past mood states.Machine-learning studies already published include the use of natural processing language to detect emotions present in suicide notes [18] and classify them [19], to detect suicidality in Twitter activity [20], and to extract a particular emotion in a suicide note sentence [21,22]. Similarly, it appears that electronic health records may also be of value to predict suicidal behavior [13,22]. Besides text classification, previous studies used machine-learning algorithms to predict suicide. For instance, a study reported a clinical signature by using a relevance vector machine to identify suicidality in patients with mood disorders [2]. The most relevant predictor variables in distinguishing attempters from non-attempters were previous hospitalizations for depression, lifetime history of psychosis, cocaine dependence, and post-traumatic stress disorder comorbidity [2]. Another study that used machine-learning algorithms showed that individual unrest, personal satisfaction, and reasons for living are the variables most associated with suicidality [23]. They concluded that these variables could be used to create an actionable assessment tool that may identify individual risk and protective factors [23]The present study aims to analyze whether text classification coupled with machine-learning algorithms can predict unfavorable outcomes, such as suicide, using the written records of a single individual. In order to test this hypothesis, we used the content of Virginia Woolfs diaries and letters to assess whether there is a text signature in her writings prior to her suicide.MethodsThis is a text classification study with a machine-learning approach. We used a Nave Bayes algorithm. It is worth mentioning that Nave Bayes is a Bayesian method that estimates the probability of an events occurrence [17]. Although Nave Bayes is not the only machine-learning method that utilizes Bayesian statistics, it is one of the most common. This is particularly true for text classification, where it has become the de facto standard [17]. For instance, this algorithm is commonly used to classify e-mails in spam or ham messages [17]. This algorithm was selected because 1) it requires relatively few examples for training, but also works well with very large numbers of examples; 2) it provides the estimated probability for a prediction; and 3) it is very effective and performs well with noisy data. Therefore, by using Nave Bayes, we compared Virginia Woolfs texts written over the 60 days before her death versus texts written outside this period to identify a signature associated with suicide. We included letters and diaries written by Virginia Woolf. We excluded books, novels, short stories, and article fragments.\"\n"],"metadata":{"id":"knxjbekqiYmU"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}